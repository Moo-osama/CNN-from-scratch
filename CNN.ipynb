{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PMLD_HW_2 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhmfDYTH9KWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3558669-774f-42dc-bf91-5d2ba2aa1d7d"
      },
      "source": [
        "!wget -c http://download.tensorflow.org/example_images/flower_photos.tgz -O - | tar -xz\n",
        "#!tar -xzvf flower_photos.tgz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-03 14:52:41--  http://download.tensorflow.org/example_images/flower_photos.tgz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.204.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.204.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228813984 (218M) [application/x-compressed-tar]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 218.21M  88.7MB/s    in 2.5s    \n",
            "\n",
            "2020-12-03 14:52:44 (88.7 MB/s) - written to stdout [228813984/228813984]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a81Px5xTX5v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2424c94-227c-40a8-ee21-3a2208c62441"
      },
      "source": [
        "import cupy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os.path\n",
        "\n",
        "np.random.seed(50)\n",
        "\n",
        "CATEGORIES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "IMG_SIZE = 32\n",
        "\n",
        "def get_data(DATADIR, raw_training_data, raw_testing_data):\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(DATADIR,category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "\n",
        "        num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for img in sorted(tqdm(os.listdir(path))):\n",
        "            try:\n",
        "\n",
        "                img_array = cv2.imread(os.path.join(path,img))\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                count+=1\n",
        "                if count < num_files-99:\n",
        "                    raw_training_data.append([new_array, class_num])\n",
        "                else:\n",
        "                    raw_testing_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "raw_training_data = []\n",
        "raw_testing_data = []\n",
        "\n",
        "DATADIR = \"flower_photos\"\n",
        "\n",
        "get_data(DATADIR, raw_training_data, raw_testing_data)\n",
        "\n",
        "\n",
        "print(len(raw_training_data), len(raw_testing_data))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [00:00<00:00, 197309.34it/s]\n",
            "100%|██████████| 898/898 [00:00<00:00, 804632.56it/s]\n",
            "100%|██████████| 641/641 [00:00<00:00, 452465.31it/s]\n",
            "100%|██████████| 699/699 [00:00<00:00, 378983.78it/s]\n",
            "100%|██████████| 799/799 [00:00<00:00, 772355.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3170 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t31uwkro9iKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ec009c-b25f-41d1-928f-499b6939e713"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from typing import Tuple\n",
        "\n",
        "X_TRAIN = []\n",
        "Y_TRAIN = []\n",
        "\n",
        "X_TEST = []\n",
        "Y_TEST = []\n",
        "\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "\n",
        "\n",
        "for features,label in raw_training_data:\n",
        "    X_TRAIN.append(features)\n",
        "    Y_TRAIN.append(label)\n",
        "\n",
        "\n",
        "for features,label in raw_testing_data:\n",
        "    X_TEST.append(features)\n",
        "    Y_TEST.append(label)\n",
        "\n",
        "X_TRAIN = np.array(X_TRAIN).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X_TEST = np.array(X_TEST).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_TRAIN = np.array(Y_TRAIN)\n",
        "X_TRAIN, Y_TRAIN = shuffle(X_TRAIN, Y_TRAIN)\n",
        "\n",
        "X_TRAIN = X_TRAIN.astype(float) / 255.\n",
        "X_TEST = X_TEST.astype(float) / 255.\n",
        "\n",
        "\n",
        "X_TRAIN, X_VAL = X_TRAIN[:-500], X_TRAIN[-500:]\n",
        "Y_TRAIN, Y_VAL = Y_TRAIN[:-500], Y_TRAIN[-500:]\n",
        "\n",
        "\"\"\"\n",
        "np.save('xtest.npy',X_TEST)\n",
        "np.save('ytest.npy',Y_TEST)\n",
        "\"\"\"\n",
        "\n",
        "print (X_TRAIN.shape, X_VAL.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2670, 32, 32, 3) (500, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBcmB64lRhcG"
      },
      "source": [
        "class conv_layer():\n",
        "\n",
        "    def __init__(self, total_filters, filter_shape, lrate = 0.1, padding = 'no_padding', stride = 1, beta1 = 0.9, beta2 = 0.999):\n",
        "        self.filters_ws = np.random.randn(*filter_shape, total_filters) * 0.1\n",
        "        self.filter_bs = np.random.randn(total_filters) * 0.1\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        self.din_dw = None \n",
        "        self.din_db = None\n",
        "        self.input = None\n",
        "        self.mo = 0\n",
        "        self.acc = 0\n",
        "        self.mo_b = 0\n",
        "        self.acc_b = 0\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, input, training):\n",
        "        #print(self.filters_ws)\n",
        "        self.input = np.array(input, copy=True)\n",
        "\n",
        "\n",
        "        ############### getting output dimentions here ###############\n",
        "        n, input_dim_h, input_dim_w, _ = input.shape\n",
        "        filter_dim_h, filter_dim_w, _, filter_dim_n = self.filters_ws.shape\n",
        "        if self.padding == 'keep_img_dim':\n",
        "            output_shape = n, input_dim_h, input_dim_w, filter_dim_n\n",
        "            filter_dim_h, filter_dim_w, _, _ = self.filters_ws.shape\n",
        "            p_value = (filter_dim_h - 1) // 2, (filter_dim_w - 1) // 2\n",
        "        elif self.padding == 'no_padding':\n",
        "            out_dim_h = (input_dim_h - filter_dim_h) // self.stride + 1\n",
        "            out_dim_w = (input_dim_w - filter_dim_w) // self.stride + 1\n",
        "            output_shape = n, out_dim_h, out_dim_w, filter_dim_n\n",
        "            p_value = 0, 0\n",
        "        ############### got output dimentions ###############\n",
        "\n",
        "        out_dim_n, out_dim_h, out_dim_w, out_dim_c = output_shape\n",
        "\n",
        "        input_padded = self.pad(input, p_value)\n",
        "        output = np.zeros(output_shape)\n",
        "\n",
        "        for i in range(out_dim_h):\n",
        "            for j in range(out_dim_w):\n",
        "                start_pix_x = i * self.stride\n",
        "                end_pix_x = start_pix_x + filter_dim_h\n",
        "                start_pix_y = j * self.stride\n",
        "                end_pix_y = start_pix_y + filter_dim_w\n",
        "\n",
        "                output[:, i, j, :] = np.sum(\n",
        "                    input_padded[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :, np.newaxis] *\n",
        "                    self.filters_ws[np.newaxis, :, :, :],\n",
        "                    axis=(1, 2, 3)\n",
        "                )\n",
        "\n",
        "        #print(output)\n",
        "        return output + self.filter_bs\n",
        "\n",
        "    def backward(self, input , grad):\n",
        "        out_dim_n, out_dim_h, out_dim_w, out_dim_c = grad.shape\n",
        "        n, input_dim_h, input_dim_w, input_dim_c = self.input.shape\n",
        "        filter_dim_h, filter_dim_w, _, _ = self.filters_ws.shape\n",
        "\n",
        "\n",
        "        ############### getting p value here ###############\n",
        "        if self.padding == 'keep_img_dim':\n",
        "            p_value = (filter_dim_h - 1) // 2, (filter_dim_w - 1) // 2\n",
        "        elif self.padding == 'no_padding':\n",
        "            p_value = 0, 0\n",
        "        ############### got p value  ###############\n",
        "\n",
        "\n",
        "\n",
        "        input_padded = self.pad(self.input, p_value)\n",
        "        output = np.zeros_like(input_padded)\n",
        "        #print(grad)\n",
        "        self.din_db = grad.sum(axis=(0, 1, 2)) / n\n",
        "        self.din_dw = np.zeros_like(self.filters_ws)\n",
        "\n",
        "        for i in range(out_dim_h):\n",
        "            for j in range(out_dim_w):\n",
        "                start_pix_x = i * self.stride\n",
        "                end_pix_x = start_pix_x + filter_dim_h\n",
        "                start_pix_y = j * self.stride\n",
        "                end_pix_y = start_pix_y + filter_dim_w\n",
        "                output[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :] += np.sum(\n",
        "                    self.filters_ws[np.newaxis, :, :, :, :] *\n",
        "                    grad[:, i:i+1, j:j+1, np.newaxis, :],\n",
        "                    axis=4\n",
        "                )\n",
        "                self.din_dw += np.sum(\n",
        "                    input_padded[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :, np.newaxis] *\n",
        "                    grad[:, i:i+1, j:j+1, np.newaxis, :],\n",
        "                    axis=0\n",
        "                )\n",
        "\n",
        "        self.din_dw /= n\n",
        "\n",
        "        #print(self.din_dw)\n",
        "\n",
        "        ###################### Adam ###############################\n",
        "        self.mo = self.beta1*self.mo + (1-self.beta1)*(self.din_dw) \n",
        "        self.acc = self.beta2*self.acc + (1-self.beta2)*((self.din_dw) *(self.din_dw))\n",
        "        self.filters_ws += -self.lr * self.mo / (np.sqrt(self.acc) + 1e-7)\n",
        "\n",
        "        self.mo_b = self.beta1*self.mo_b + (1-self.beta1)*(self.din_db) \n",
        "        self.acc_b = self.beta2*self.acc_b + (1-self.beta2)*((self.din_db) *(self.din_db))\n",
        "        self.filter_bs += -self.lr * self.mo_b / (np.sqrt(self.acc_b) + 1e-7)        \n",
        "        ###################### Adam ###############################\n",
        "\n",
        "        return output[:, p_value[0]:p_value[0]+input_dim_h, p_value[1]:p_value[1]+input_dim_w, :]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def pad(array, pad):\n",
        "        return np.pad(\n",
        "            array=array,\n",
        "            pad_width=((0, 0), (pad[0], pad[0]), (pad[1], pad[1]), (0, 0)),\n",
        "            mode='constant'\n",
        "        )\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCiDctcqaXoh"
      },
      "source": [
        "class pool_layer():\n",
        "\n",
        "    def __init__(self, input_dim, stride = 2):\n",
        "        self.pool_dim = input_dim\n",
        "        self.stride = stride\n",
        "        self.input = None\n",
        "        self.max_pixels = {}\n",
        "\n",
        "    def forward(self, input, training):\n",
        "        #print(input.shape)\n",
        "        self.input = np.array(input, copy=True)\n",
        "        n, input_dim_h, input_dim_w, c = input.shape\n",
        "        pool_x_dim, pool_y_dim = self.pool_dim\n",
        "        out_dim_h = 1 + (input_dim_h - pool_x_dim) // self.stride\n",
        "        out_dim_w = 1 + (input_dim_w - pool_y_dim) // self.stride\n",
        "        output = np.zeros((n, out_dim_h, out_dim_w, c))\n",
        "\n",
        "        for i in range(out_dim_h):\n",
        "            for j in range(out_dim_w):\n",
        "                start_pix_x = i * self.stride\n",
        "                end_pix_x = start_pix_x + pool_x_dim\n",
        "                start_pix_y = j * self.stride\n",
        "                end_pix_y = start_pix_y + pool_y_dim\n",
        "                focus_area = input[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :]\n",
        "                self.store_max_pixels(focus_area, (i, j))\n",
        "                output[:, i, j, :] = np.max(focus_area, axis=(1, 2))\n",
        "\n",
        "        #print(output)\n",
        "        return output\n",
        "\n",
        "    def backward(self, input,grad):\n",
        "        #print(grad)\n",
        "        output = np.zeros_like(self.input)\n",
        "        n, out_dim_h, out_dim_w, c = grad.shape\n",
        "        pool_x_dim, pool_y_dim = self.pool_dim\n",
        "        for i in range(out_dim_h):\n",
        "            for j in range(out_dim_w):\n",
        "                start_pix_x = i * self.stride\n",
        "                end_pix_x = start_pix_x + pool_x_dim\n",
        "                start_pix_y = j * self.stride\n",
        "                end_pix_y = start_pix_y + pool_y_dim\n",
        "                output[:, start_pix_x:end_pix_x, start_pix_y:end_pix_y, :] += grad[:, i:i + 1, j:j + 1, :] * self.max_pixels[(i, j)]\n",
        "        #print(output)\n",
        "        return output\n",
        "\n",
        "    def store_max_pixels(self, area_pixels, i_j_location):\n",
        "        mark_max = np.zeros_like(area_pixels)\n",
        "        n, h, w, c = area_pixels.shape\n",
        "        area_pixels = area_pixels.reshape(n, h * w, c)\n",
        "        max_locations = np.argmax(area_pixels, axis=1)\n",
        "        n_idx, c_idx = np.indices((n, c))\n",
        "        mark_max.reshape(n, h * w, c)[n_idx, max_locations, c_idx] = 1\n",
        "        self.max_pixels[i_j_location] = mark_max\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QQfoocUcdjs"
      },
      "source": [
        "class reshape_layer():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.input_shape = ()\n",
        "\n",
        "    def forward(self, input, training):\n",
        "        self.input_shape = input.shape\n",
        "        return np.ravel(input).reshape(input.shape[0], -1)\n",
        "\n",
        "    def backward(self,input , grad):\n",
        "        return grad.reshape(self.input_shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRQmJub48Cbl"
      },
      "source": [
        "all_ws = []\n",
        "class weights_layer():\n",
        "    def __init__(self, fan_in, fan_out, lr=0.05, beta1 = 0.9, beta2 = 0.999 , lamdaa = 0.0001):\n",
        "        self.lamdaa = lamdaa\n",
        "        self.lr = lr\n",
        "        self.ws = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in)\n",
        "        self.bs = np.zeros(fan_out)\n",
        "        self.mo = 0\n",
        "        self.acc = 0\n",
        "        self.mo_b = 0\n",
        "        self.acc_b = 0\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        \n",
        "    def forward(self,input, training):\n",
        "        #all_ws.append(self.ws)\n",
        "        #print(input.shape)\n",
        "        #print(np.dot(input,self.ws) + self.bs)\n",
        "        return np.dot(input,self.ws) + self.bs\n",
        "    \n",
        "    def backward(self,input,grad_output):\n",
        "        dout_din = np.dot(grad_output, self.ws.T)\n",
        "        dout_dws = np.dot(input.T, grad_output)\n",
        "        dout_dbs = grad_output.mean(axis=0)*input.shape[0]\n",
        "        \n",
        "        assert dout_dws.shape == self.ws.shape and dout_dbs.shape == self.bs.shape\n",
        "        #print(dout_dws)\n",
        "        ###################### Adam ###############################\n",
        "        self.mo = self.beta1*self.mo + (1-self.beta1)*(dout_dws) \n",
        "        self.acc = self.beta2*self.acc + (1-self.beta2)*((dout_dws) *(dout_dws))\n",
        "        self.ws += -self.lr * self.mo / (np.sqrt(self.acc) + 1e-7)\n",
        "\n",
        "        self.mo_b = self.beta1*self.mo_b + (1-self.beta1)*(dout_dbs) \n",
        "        self.acc_b = self.beta2*self.acc_b + (1-self.beta2)*((dout_dbs) *(dout_dbs))\n",
        "        self.bs += -self.lr * self.mo_b / (np.sqrt(self.acc_b) + 1e-7) \n",
        "        ###################### Adam ###############################\n",
        "        \"\"\"\n",
        "        self.ws = self.ws - self.lr * dout_dws  #+ (self.lamdaa * np.sum(self.ws))/input.shape[0]\n",
        "        self.bs = self.bs - self.lr * dout_dbs  #+ (self.lamdaa * np.sum(self.bs))/input.shape[0]  \n",
        "        \"\"\"\n",
        "        #print(dout_din)\n",
        "        return dout_din"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgrL-8G27wBE"
      },
      "source": [
        "class ReLU():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input, training):\n",
        "        relu_forward = np.maximum(0,input)\n",
        "        return relu_forward\n",
        "    \n",
        "    def backward(self, input, grad_output):\n",
        "        relu_grad = input > 0\n",
        "        return grad_output*relu_grad\n",
        "\n",
        "class tanh():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, input, training):\n",
        "        return np.tanh(input)\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "      return grad_output*(1-np.tanh(input)**2)\n",
        "\n",
        "class sigmoid():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, input, training):\n",
        "        return 1/(1+np.exp(-1* input))\n",
        "    def backward(self, input, grad_output):\n",
        "        return grad_output * (input*(1-input))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hNvNqi_94XB"
      },
      "source": [
        "def NLL(expected_probabilities,actual_labels, m, lamdaa = 0.0001):\n",
        "\n",
        "\n",
        "    correct_prob = expected_probabilities[np.arange(len(expected_probabilities)),actual_labels]\n",
        "\n",
        "    p = np.exp(correct_prob) / np.sum(np.exp(expected_probabilities),axis=-1)\n",
        "\n",
        "    loss = -1 * np.log(p)\n",
        "    \n",
        "    \"\"\"\n",
        "    s_reg = 0\n",
        "    for i in all_ws:\n",
        "      s_reg += np.sum(np.square(i))\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    #print(expected_probabilities)\n",
        "    return loss #+ (lamdaa * s_reg)/m\n",
        "\n",
        "def back_NLL(expected_probabilities,actual_labels):\n",
        "\n",
        "    hotmap = np.zeros_like(expected_probabilities)\n",
        "    hotmap[np.arange(len(expected_probabilities)),actual_labels] = 1\n",
        "    \n",
        "    ratios = np.exp(expected_probabilities) / np.exp(expected_probabilities).sum(axis=-1,keepdims=True)\n",
        "    \n",
        "    \n",
        "    #print((- hotmap + ratios) / expected_probabilities.shape[0]) \n",
        "    return (- hotmap + ratios) / expected_probabilities.shape[0]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMO5Mfao-6Bb"
      },
      "source": [
        "def run_batch(CNN, X, training):\n",
        "    all_layers_outputs = []\n",
        "    received = X\n",
        "    for layer in CNN:\n",
        "        all_layers_outputs.append(layer.forward(received, training))\n",
        "        received = all_layers_outputs[-1]\n",
        "  \n",
        "    all_ws=[]\n",
        "    assert len(all_layers_outputs) == len(CNN)\n",
        "    \n",
        "    return all_layers_outputs\n",
        "\n",
        "def predict(CNN,X, Y, training):\n",
        "    expected_probabilities = run_batch(CNN,X, training)[-1]\n",
        "    losses = NLL(expected_probabilities,Y, X.shape[0])\n",
        "    return (expected_probabilities.argmax(axis=-1) , np.mean(losses))\n",
        "\n",
        "def train(CNN,X,acutal_labels, training):\n",
        "\n",
        "    layers_outputs = run_batch(CNN,X, training)\n",
        "    layers_inputs = [X]+layers_outputs \n",
        "    expected_probs = layers_outputs[-1]\n",
        "    loss = NLL(expected_probs,acutal_labels, X.shape[0])\n",
        "    loss_grad = back_NLL(expected_probs,acutal_labels)\n",
        "\n",
        "    for layer_index in range(len(CNN))[::-1]:\n",
        "        layer = CNN[layer_index]\n",
        "        loss_grad = layer.backward(layers_inputs[layer_index],loss_grad)\n",
        "        \n",
        "    return np.mean(loss)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIZ8Mg7uRBSd"
      },
      "source": [
        "class dropout_layer():\n",
        "\n",
        "    def __init__(self, keep_prob):\n",
        "        self.cutoff_prob = keep_prob\n",
        "        self.zeros_for_dropped = None\n",
        "\n",
        "    def forward(self, input, training):\n",
        "        if training:\n",
        "            self.zeros_for_dropped = (np.random.rand(*input.shape) < self.cutoff_prob)\n",
        "            return self.drop(input, self.zeros_for_dropped)\n",
        "        else:\n",
        "            return input\n",
        "\n",
        "    def backward(self, input, grad):\n",
        "        return self.drop(grad, self.zeros_for_dropped)\n",
        "\n",
        "    def drop(self, input, zeros_for_dropped):\n",
        "        input *= zeros_for_dropped\n",
        "        input /= self.cutoff_prob\n",
        "        #print(input)\n",
        "        return input"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXZrtarROCP"
      },
      "source": [
        "from tqdm import trange\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert len(inputs) == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BejFc2tReKFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7b6152-a6df-4215-e730-a809ef65ec03"
      },
      "source": [
        "max_count = 20\n",
        "learning_rates = []\n",
        "train_log = []\n",
        "val_log = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "n_epochs = 3\n",
        "\n",
        "for count in range(max_count):\n",
        "\n",
        "  lr = 10**np.random.uniform(-0.5,-4) \n",
        "  \n",
        "  CNN = []\n",
        "\n",
        "  CNN.append(conv_layer(8, (3,3,3), lr))\n",
        "  CNN.append(ReLU())\n",
        "  CNN.append(pool_layer((2,2)))\n",
        "\n",
        "  CNN.append(conv_layer(16, (3,3,8) , lr))\n",
        "  CNN.append(ReLU())\n",
        "  CNN.append(pool_layer((2,2)))\n",
        "\n",
        "\n",
        "  CNN.append(conv_layer(32, (3,3,16), lr))\n",
        "  CNN.append(ReLU())\n",
        "  CNN.append(pool_layer((2,2)))\n",
        "\n",
        "\n",
        "  CNN.append(reshape_layer())\n",
        "\n",
        "\n",
        "  CNN.append(weights_layer(128,100,lr))\n",
        "  CNN.append(ReLU())\n",
        "  CNN.append(dropout_layer(0.6))\n",
        "  CNN.append(weights_layer(100,100,lr))\n",
        "  CNN.append(ReLU())\n",
        "  CNN.append(dropout_layer(0.6))\n",
        "  CNN.append(weights_layer(100,5,lr))\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    train(CNN,X_TRAIN,Y_TRAIN, 1)\n",
        "\n",
        "    train_predictions, train_loss = predict(CNN,X_TRAIN, Y_TRAIN, 0)\n",
        "\n",
        "    val_predictions, val_loss = predict(CNN,X_VAL, Y_VAL, 0)\n",
        "\n",
        "    train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
        "\n",
        "    val_log.append(np.mean(val_predictions==Y_VAL))\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    learning_rates.append(lr)\n",
        "\n",
        "    print(\"Trial %d epoch %d got t_acc = %f, v_acc = %f, t_loss = %f, and v_loss = %f at lr = %f\" % (count, epoch, train_log[-1], train_losses[-1],val_losses[-1], val_log[-1], lr))\n",
        "\n",
        "print()\n",
        "print(\"Got highest train accuracy = %f at lr = %f\" % (max(train_log), learning_rates[train_log.index(max(train_log))]))\n",
        "print(\"Got highest val accuracy = %f at lr = %f\" % (max(val_log), learning_rates[val_log.index(max(val_log))]))\n",
        "print(\"Got lowest train loss = %f at lr = %f\" % (min(train_losses), learning_rates[train_losses.index(min(train_losses))]))\n",
        "print(\"Got lowest val loss = %f at lr = %f\" % (min(val_losses), learning_rates[val_losses.index(min(val_losses))]))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 0 epoch 0 got t_acc = 0.171910, v_acc = 1.619114, t_loss = 1.623299, and v_loss = 0.146000 at lr = 0.000132\n",
            "Trial 0 epoch 1 got t_acc = 0.190637, v_acc = 1.614611, t_loss = 1.617759, and v_loss = 0.156000 at lr = 0.000132\n",
            "Trial 0 epoch 2 got t_acc = 0.226217, v_acc = 1.610468, t_loss = 1.612454, and v_loss = 0.162000 at lr = 0.000132\n",
            "Trial 1 epoch 0 got t_acc = 0.246816, v_acc = 4.367752, t_loss = 4.091685, and v_loss = 0.278000 at lr = 0.023338\n",
            "Trial 1 epoch 1 got t_acc = 0.167790, v_acc = 1.721592, t_loss = 1.732194, and v_loss = 0.186000 at lr = 0.023338\n",
            "Trial 1 epoch 2 got t_acc = 0.191011, v_acc = 1.633893, t_loss = 1.644695, and v_loss = 0.178000 at lr = 0.023338\n",
            "Trial 2 epoch 0 got t_acc = 0.246816, v_acc = nan, t_loss = nan, and v_loss = 0.278000 at lr = 0.155307\n",
            "Trial 2 epoch 1 got t_acc = 0.172285, v_acc = nan, t_loss = nan, and v_loss = 0.146000 at lr = 0.155307\n",
            "Trial 2 epoch 2 got t_acc = 0.172285, v_acc = nan, t_loss = nan, and v_loss = 0.146000 at lr = 0.155307\n",
            "Trial 3 epoch 0 got t_acc = 0.247566, v_acc = 1.595922, t_loss = 1.594459, and v_loss = 0.282000 at lr = 0.002141\n",
            "Trial 3 epoch 1 got t_acc = 0.321348, v_acc = 1.586843, t_loss = 1.585719, and v_loss = 0.362000 at lr = 0.002141\n",
            "Trial 3 epoch 2 got t_acc = 0.318352, v_acc = 1.572791, t_loss = 1.565984, and v_loss = 0.348000 at lr = 0.002141\n",
            "Trial 4 epoch 0 got t_acc = 0.222097, v_acc = 5.425754, t_loss = 5.378115, and v_loss = 0.212000 at lr = 0.022059\n",
            "Trial 4 epoch 1 got t_acc = 0.191011, v_acc = 4.377887, t_loss = 4.411030, and v_loss = 0.178000 at lr = 0.022059\n",
            "Trial 4 epoch 2 got t_acc = 0.172285, v_acc = 1.654760, t_loss = 1.655661, and v_loss = 0.146000 at lr = 0.022059\n",
            "Trial 5 epoch 0 got t_acc = 0.223596, v_acc = 1.604525, t_loss = 1.600780, and v_loss = 0.212000 at lr = 0.000131\n",
            "Trial 5 epoch 1 got t_acc = 0.225094, v_acc = 1.602478, t_loss = 1.598444, and v_loss = 0.216000 at lr = 0.000131\n",
            "Trial 5 epoch 2 got t_acc = 0.261423, v_acc = 1.600599, t_loss = 1.596183, and v_loss = 0.260000 at lr = 0.000131\n",
            "Trial 6 epoch 0 got t_acc = 0.258052, v_acc = 1.593621, t_loss = 1.591861, and v_loss = 0.284000 at lr = 0.000715\n",
            "Trial 6 epoch 1 got t_acc = 0.250187, v_acc = 1.584021, t_loss = 1.583195, and v_loss = 0.278000 at lr = 0.000715\n",
            "Trial 6 epoch 2 got t_acc = 0.262547, v_acc = 1.573131, t_loss = 1.575024, and v_loss = 0.278000 at lr = 0.000715\n",
            "Trial 7 epoch 0 got t_acc = 0.246816, v_acc = 8.984700, t_loss = 8.705931, and v_loss = 0.278000 at lr = 0.034351\n",
            "Trial 7 epoch 1 got t_acc = 0.222097, v_acc = 1.626236, t_loss = 1.632166, and v_loss = 0.212000 at lr = 0.034351\n",
            "Trial 7 epoch 2 got t_acc = 0.191011, v_acc = 1.616609, t_loss = 1.623321, and v_loss = 0.178000 at lr = 0.034351\n",
            "Trial 8 epoch 0 got t_acc = 0.246816, v_acc = 1.912179, t_loss = 1.873697, and v_loss = 0.278000 at lr = 0.011476\n",
            "Trial 8 epoch 1 got t_acc = 0.191011, v_acc = 1.607901, t_loss = 1.608350, and v_loss = 0.178000 at lr = 0.011476\n",
            "Trial 8 epoch 2 got t_acc = 0.222097, v_acc = 1.607106, t_loss = 1.613162, and v_loss = 0.212000 at lr = 0.011476\n",
            "Trial 9 epoch 0 got t_acc = 0.246816, v_acc = 1.595635, t_loss = 1.581059, and v_loss = 0.278000 at lr = 0.003800\n",
            "Trial 9 epoch 1 got t_acc = 0.222097, v_acc = 1.601654, t_loss = 1.600937, and v_loss = 0.212000 at lr = 0.003800\n",
            "Trial 9 epoch 2 got t_acc = 0.222097, v_acc = 1.592193, t_loss = 1.590963, and v_loss = 0.212000 at lr = 0.003800\n",
            "Trial 10 epoch 0 got t_acc = 0.222097, v_acc = 1.607962, t_loss = 1.614393, and v_loss = 0.212000 at lr = 0.000343\n",
            "Trial 10 epoch 1 got t_acc = 0.223221, v_acc = 1.602655, t_loss = 1.606114, and v_loss = 0.212000 at lr = 0.000343\n",
            "Trial 10 epoch 2 got t_acc = 0.243820, v_acc = 1.599456, t_loss = 1.600125, and v_loss = 0.220000 at lr = 0.000343\n",
            "Trial 11 epoch 0 got t_acc = 0.246816, v_acc = 149.731562, t_loss = 142.340696, and v_loss = 0.278000 at lr = 0.136378\n",
            "Trial 11 epoch 1 got t_acc = 0.222097, v_acc = inf, t_loss = inf, and v_loss = 0.212000 at lr = 0.136378\n",
            "Trial 11 epoch 2 got t_acc = 0.172285, v_acc = nan, t_loss = nan, and v_loss = 0.146000 at lr = 0.136378\n",
            "Trial 12 epoch 0 got t_acc = 0.246816, v_acc = 1.645457, t_loss = 1.632364, and v_loss = 0.278000 at lr = 0.008933\n",
            "Trial 12 epoch 1 got t_acc = 0.193633, v_acc = 1.609234, t_loss = 1.607437, and v_loss = 0.196000 at lr = 0.008933\n",
            "Trial 12 epoch 2 got t_acc = 0.222097, v_acc = 1.604311, t_loss = 1.601109, and v_loss = 0.212000 at lr = 0.008933\n",
            "Trial 13 epoch 0 got t_acc = 0.247940, v_acc = 1.593471, t_loss = 1.585677, and v_loss = 0.278000 at lr = 0.003775\n",
            "Trial 13 epoch 1 got t_acc = 0.376404, v_acc = 1.581926, t_loss = 1.584623, and v_loss = 0.384000 at lr = 0.003775\n",
            "Trial 13 epoch 2 got t_acc = 0.331086, v_acc = 1.562876, t_loss = 1.548079, and v_loss = 0.364000 at lr = 0.003775\n",
            "Trial 14 epoch 0 got t_acc = 0.246816, v_acc = 1.599867, t_loss = 1.591428, and v_loss = 0.278000 at lr = 0.003409\n",
            "Trial 14 epoch 1 got t_acc = 0.246816, v_acc = 1.595484, t_loss = 1.590725, and v_loss = 0.278000 at lr = 0.003409\n",
            "Trial 14 epoch 2 got t_acc = 0.250187, v_acc = 1.587732, t_loss = 1.585715, and v_loss = 0.278000 at lr = 0.003409\n",
            "Trial 15 epoch 0 got t_acc = 0.259551, v_acc = 1.597643, t_loss = 1.598112, and v_loss = 0.258000 at lr = 0.000863\n",
            "Trial 15 epoch 1 got t_acc = 0.243071, v_acc = 1.589572, t_loss = 1.591848, and v_loss = 0.232000 at lr = 0.000863\n",
            "Trial 15 epoch 2 got t_acc = 0.321348, v_acc = 1.579449, t_loss = 1.582196, and v_loss = 0.336000 at lr = 0.000863\n",
            "Trial 16 epoch 0 got t_acc = 0.246816, v_acc = nan, t_loss = nan, and v_loss = 0.278000 at lr = 0.182858\n",
            "Trial 16 epoch 1 got t_acc = 0.172285, v_acc = nan, t_loss = nan, and v_loss = 0.146000 at lr = 0.182858\n",
            "Trial 16 epoch 2 got t_acc = 0.172285, v_acc = nan, t_loss = nan, and v_loss = 0.146000 at lr = 0.182858\n",
            "Trial 17 epoch 0 got t_acc = 0.246816, v_acc = 1.603518, t_loss = 1.600977, and v_loss = 0.278000 at lr = 0.000492\n",
            "Trial 17 epoch 1 got t_acc = 0.264419, v_acc = 1.596845, t_loss = 1.593113, and v_loss = 0.296000 at lr = 0.000492\n",
            "Trial 17 epoch 2 got t_acc = 0.314981, v_acc = 1.590058, t_loss = 1.585410, and v_loss = 0.332000 at lr = 0.000492\n",
            "Trial 18 epoch 0 got t_acc = 0.246816, v_acc = 1.592409, t_loss = 1.585503, and v_loss = 0.278000 at lr = 0.002592\n",
            "Trial 18 epoch 1 got t_acc = 0.305243, v_acc = 1.566438, t_loss = 1.570720, and v_loss = 0.262000 at lr = 0.002592\n",
            "Trial 18 epoch 2 got t_acc = 0.323970, v_acc = 1.546674, t_loss = 1.552177, and v_loss = 0.322000 at lr = 0.002592\n",
            "Trial 19 epoch 0 got t_acc = 0.225843, v_acc = 1.590989, t_loss = 1.587568, and v_loss = 0.212000 at lr = 0.003706\n",
            "Trial 19 epoch 1 got t_acc = 0.321723, v_acc = 1.570495, t_loss = 1.563965, and v_loss = 0.340000 at lr = 0.003706\n",
            "Trial 19 epoch 2 got t_acc = 0.260300, v_acc = 1.562657, t_loss = 1.555113, and v_loss = 0.254000 at lr = 0.003706\n",
            "\n",
            "Got highest train accuracy = 0.376404 at lr = 0.003775\n",
            "Got highest val accuracy = 0.384000 at lr = 0.003775\n",
            "Got lowest train loss = 1.546674 at lr = 0.002592\n",
            "Got lowest val loss = 1.548079 at lr = 0.003775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u_qfDg0ApDE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4dcc356-1d9a-404c-bd0e-0b75de1e04c9"
      },
      "source": [
        "lr=0.0007\n",
        "\n",
        "train_log = []\n",
        "val_log = []\n",
        "losses = []\n",
        "train_count = []\n",
        "counter = 0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "CNN = []\n",
        "\n",
        "CNN.append(conv_layer(8, (3,3,3), lr))\n",
        "CNN.append(ReLU())\n",
        "CNN.append(pool_layer((2,2)))\n",
        "\n",
        "CNN.append(conv_layer(16, (3,3,8) , lr))\n",
        "CNN.append(ReLU())\n",
        "CNN.append(pool_layer((2,2)))\n",
        "\n",
        "\n",
        "CNN.append(conv_layer(32, (3,3,16), lr))\n",
        "CNN.append(ReLU())\n",
        "CNN.append(pool_layer((2,2)))\n",
        "\n",
        "\n",
        "CNN.append(reshape_layer())\n",
        "\n",
        "\n",
        "CNN.append(weights_layer(128,100,lr))\n",
        "CNN.append(ReLU())\n",
        "CNN.append(dropout_layer(0.5))\n",
        "CNN.append(weights_layer(100,100,lr))\n",
        "CNN.append(ReLU())\n",
        "CNN.append(dropout_layer(0.5))\n",
        "CNN.append(weights_layer(100,5,lr))\n",
        "\n",
        "n_epochs = 150\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    #for x_batch,y_batch in iterate_minibatches(X_TRAIN,Y_TRAIN,batchsize=534,shuffle=True):\n",
        "    #  train(CNN,x_batch,y_batch, 1)\n",
        "\n",
        "    train(CNN,X_TRAIN,Y_TRAIN,1)\n",
        "\n",
        "    train_predictions, train_loss = predict(CNN,X_TRAIN, Y_TRAIN, 0)\n",
        "\n",
        "    val_predictions, val_loss = predict(CNN,X_VAL, Y_VAL, 0)\n",
        "\n",
        "    train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
        "\n",
        "    val_log.append(np.mean(val_predictions==Y_VAL))\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\"Ran epoch %d and got t_acc = %f val_acc = %f, t_loss = %f, v_loss = %f\" % (epoch, train_log[-1], val_log[-1], train_losses[-1], val_losses[-1]))\n",
        "\n",
        "print()\n",
        "plt.plot(train_log,label='train accuracy')\n",
        "plt.plot(val_log,label='val accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_losses, label=\"Train losses\") \n",
        "\n",
        "plt.plot(val_losses, label=\"Val losses\") \n",
        "\n",
        "lowest_train_loss, lowest_val_loss = min(train_losses) , min(val_losses)\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.legend() \n",
        "\n",
        "lowest_x = val_losses.index(lowest_val_loss)\n",
        "\n",
        "plt.show() \n",
        "\n",
        "print()\n",
        "print(\"For Q4:\")\n",
        "print(\"Best train accuracy:\",max(train_log))\n",
        "print(\"Best val accuracy:\",max(val_log))\n",
        "print('Lowest Train Loss is ' + str(lowest_train_loss))\n",
        "print('Lowest Val Loss is ' + str(lowest_val_loss))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 0 and got t_acc = 0.254682 val_acc = 0.232000, t_loss = 1.604817, v_loss = 1.609838\n",
            "Ran epoch 1 and got t_acc = 0.273034 val_acc = 0.234000, t_loss = 1.600084, v_loss = 1.608468\n",
            "Ran epoch 2 and got t_acc = 0.295880 val_acc = 0.248000, t_loss = 1.596331, v_loss = 1.606108\n",
            "Ran epoch 3 and got t_acc = 0.301124 val_acc = 0.248000, t_loss = 1.592504, v_loss = 1.602791\n",
            "Ran epoch 4 and got t_acc = 0.311985 val_acc = 0.264000, t_loss = 1.588075, v_loss = 1.598371\n",
            "Ran epoch 5 and got t_acc = 0.328464 val_acc = 0.286000, t_loss = 1.583304, v_loss = 1.593106\n",
            "Ran epoch 6 and got t_acc = 0.339326 val_acc = 0.300000, t_loss = 1.576450, v_loss = 1.586470\n",
            "Ran epoch 7 and got t_acc = 0.344569 val_acc = 0.302000, t_loss = 1.566671, v_loss = 1.577170\n",
            "Ran epoch 8 and got t_acc = 0.371161 val_acc = 0.310000, t_loss = 1.552419, v_loss = 1.562606\n",
            "Ran epoch 9 and got t_acc = 0.374906 val_acc = 0.338000, t_loss = 1.531569, v_loss = 1.541895\n",
            "Ran epoch 10 and got t_acc = 0.362172 val_acc = 0.352000, t_loss = 1.501939, v_loss = 1.514573\n",
            "Ran epoch 11 and got t_acc = 0.353933 val_acc = 0.342000, t_loss = 1.470620, v_loss = 1.486883\n",
            "Ran epoch 12 and got t_acc = 0.381648 val_acc = 0.378000, t_loss = 1.437862, v_loss = 1.442329\n",
            "Ran epoch 13 and got t_acc = 0.383895 val_acc = 0.376000, t_loss = 1.409262, v_loss = 1.427854\n",
            "Ran epoch 14 and got t_acc = 0.438202 val_acc = 0.432000, t_loss = 1.378747, v_loss = 1.381605\n",
            "Ran epoch 15 and got t_acc = 0.443446 val_acc = 0.432000, t_loss = 1.350207, v_loss = 1.343555\n",
            "Ran epoch 16 and got t_acc = 0.447940 val_acc = 0.432000, t_loss = 1.322282, v_loss = 1.328213\n",
            "Ran epoch 17 and got t_acc = 0.452060 val_acc = 0.448000, t_loss = 1.294991, v_loss = 1.274386\n",
            "Ran epoch 18 and got t_acc = 0.449813 val_acc = 0.452000, t_loss = 1.256892, v_loss = 1.249645\n",
            "Ran epoch 19 and got t_acc = 0.453184 val_acc = 0.454000, t_loss = 1.231282, v_loss = 1.223003\n",
            "Ran epoch 20 and got t_acc = 0.460674 val_acc = 0.442000, t_loss = 1.225148, v_loss = 1.202910\n",
            "Ran epoch 21 and got t_acc = 0.471536 val_acc = 0.472000, t_loss = 1.205430, v_loss = 1.189702\n",
            "Ran epoch 22 and got t_acc = 0.486517 val_acc = 0.504000, t_loss = 1.178541, v_loss = 1.155584\n",
            "Ran epoch 23 and got t_acc = 0.491760 val_acc = 0.502000, t_loss = 1.165853, v_loss = 1.143137\n",
            "Ran epoch 24 and got t_acc = 0.498876 val_acc = 0.516000, t_loss = 1.157927, v_loss = 1.137239\n",
            "Ran epoch 25 and got t_acc = 0.508989 val_acc = 0.512000, t_loss = 1.142783, v_loss = 1.111793\n",
            "Ran epoch 26 and got t_acc = 0.525468 val_acc = 0.518000, t_loss = 1.138710, v_loss = 1.107623\n",
            "Ran epoch 27 and got t_acc = 0.527715 val_acc = 0.548000, t_loss = 1.124066, v_loss = 1.098787\n",
            "Ran epoch 28 and got t_acc = 0.535581 val_acc = 0.552000, t_loss = 1.117890, v_loss = 1.096096\n",
            "Ran epoch 29 and got t_acc = 0.539700 val_acc = 0.542000, t_loss = 1.109357, v_loss = 1.083536\n",
            "Ran epoch 30 and got t_acc = 0.550562 val_acc = 0.538000, t_loss = 1.103102, v_loss = 1.074836\n",
            "Ran epoch 31 and got t_acc = 0.559176 val_acc = 0.552000, t_loss = 1.092296, v_loss = 1.068660\n",
            "Ran epoch 32 and got t_acc = 0.561049 val_acc = 0.560000, t_loss = 1.084385, v_loss = 1.066001\n",
            "Ran epoch 33 and got t_acc = 0.571536 val_acc = 0.560000, t_loss = 1.072953, v_loss = 1.049815\n",
            "Ran epoch 34 and got t_acc = 0.571910 val_acc = 0.556000, t_loss = 1.067089, v_loss = 1.041234\n",
            "Ran epoch 35 and got t_acc = 0.581273 val_acc = 0.570000, t_loss = 1.057301, v_loss = 1.039759\n",
            "Ran epoch 36 and got t_acc = 0.583895 val_acc = 0.568000, t_loss = 1.044239, v_loss = 1.020624\n",
            "Ran epoch 37 and got t_acc = 0.587640 val_acc = 0.566000, t_loss = 1.035283, v_loss = 1.007945\n",
            "Ran epoch 38 and got t_acc = 0.593258 val_acc = 0.580000, t_loss = 1.024964, v_loss = 0.995553\n",
            "Ran epoch 39 and got t_acc = 0.595506 val_acc = 0.596000, t_loss = 1.017036, v_loss = 0.987523\n",
            "Ran epoch 40 and got t_acc = 0.594757 val_acc = 0.584000, t_loss = 1.017024, v_loss = 0.979300\n",
            "Ran epoch 41 and got t_acc = 0.592509 val_acc = 0.596000, t_loss = 1.011979, v_loss = 0.987157\n",
            "Ran epoch 42 and got t_acc = 0.602996 val_acc = 0.606000, t_loss = 0.998222, v_loss = 0.962363\n",
            "Ran epoch 43 and got t_acc = 0.607491 val_acc = 0.606000, t_loss = 0.990865, v_loss = 0.960902\n",
            "Ran epoch 44 and got t_acc = 0.604494 val_acc = 0.592000, t_loss = 0.988917, v_loss = 0.958278\n",
            "Ran epoch 45 and got t_acc = 0.614607 val_acc = 0.602000, t_loss = 0.979715, v_loss = 0.947064\n",
            "Ran epoch 46 and got t_acc = 0.613858 val_acc = 0.608000, t_loss = 0.975750, v_loss = 0.949707\n",
            "Ran epoch 47 and got t_acc = 0.615356 val_acc = 0.620000, t_loss = 0.968794, v_loss = 0.936616\n",
            "Ran epoch 48 and got t_acc = 0.616105 val_acc = 0.604000, t_loss = 0.963172, v_loss = 0.941487\n",
            "Ran epoch 49 and got t_acc = 0.617603 val_acc = 0.616000, t_loss = 0.956617, v_loss = 0.926790\n",
            "Ran epoch 50 and got t_acc = 0.618727 val_acc = 0.604000, t_loss = 0.950706, v_loss = 0.935943\n",
            "Ran epoch 51 and got t_acc = 0.617603 val_acc = 0.610000, t_loss = 0.954006, v_loss = 0.919400\n",
            "Ran epoch 52 and got t_acc = 0.625094 val_acc = 0.614000, t_loss = 0.933049, v_loss = 0.910460\n",
            "Ran epoch 53 and got t_acc = 0.627715 val_acc = 0.622000, t_loss = 0.937009, v_loss = 0.918970\n",
            "Ran epoch 54 and got t_acc = 0.628090 val_acc = 0.630000, t_loss = 0.938352, v_loss = 0.906097\n",
            "Ran epoch 55 and got t_acc = 0.610112 val_acc = 0.588000, t_loss = 0.958026, v_loss = 0.950508\n",
            "Ran epoch 56 and got t_acc = 0.635955 val_acc = 0.636000, t_loss = 0.912888, v_loss = 0.892934\n",
            "Ran epoch 57 and got t_acc = 0.620225 val_acc = 0.620000, t_loss = 0.942739, v_loss = 0.920621\n",
            "Ran epoch 58 and got t_acc = 0.635955 val_acc = 0.620000, t_loss = 0.920633, v_loss = 0.921843\n",
            "Ran epoch 59 and got t_acc = 0.631835 val_acc = 0.632000, t_loss = 0.913732, v_loss = 0.901541\n",
            "Ran epoch 60 and got t_acc = 0.634457 val_acc = 0.642000, t_loss = 0.919619, v_loss = 0.892770\n",
            "Ran epoch 61 and got t_acc = 0.646067 val_acc = 0.650000, t_loss = 0.898412, v_loss = 0.889844\n",
            "Ran epoch 62 and got t_acc = 0.646442 val_acc = 0.646000, t_loss = 0.910564, v_loss = 0.915824\n",
            "Ran epoch 63 and got t_acc = 0.650562 val_acc = 0.644000, t_loss = 0.891331, v_loss = 0.879105\n",
            "Ran epoch 64 and got t_acc = 0.643446 val_acc = 0.648000, t_loss = 0.893379, v_loss = 0.875490\n",
            "Ran epoch 65 and got t_acc = 0.648689 val_acc = 0.652000, t_loss = 0.880495, v_loss = 0.873700\n",
            "Ran epoch 66 and got t_acc = 0.652060 val_acc = 0.652000, t_loss = 0.883603, v_loss = 0.881846\n",
            "Ran epoch 67 and got t_acc = 0.656554 val_acc = 0.644000, t_loss = 0.874081, v_loss = 0.866512\n",
            "Ran epoch 68 and got t_acc = 0.649438 val_acc = 0.644000, t_loss = 0.872291, v_loss = 0.860774\n",
            "Ran epoch 69 and got t_acc = 0.651685 val_acc = 0.642000, t_loss = 0.870569, v_loss = 0.863944\n",
            "Ran epoch 70 and got t_acc = 0.661423 val_acc = 0.652000, t_loss = 0.862343, v_loss = 0.856598\n",
            "Ran epoch 71 and got t_acc = 0.662172 val_acc = 0.652000, t_loss = 0.860862, v_loss = 0.862175\n",
            "Ran epoch 72 and got t_acc = 0.664045 val_acc = 0.650000, t_loss = 0.851735, v_loss = 0.850826\n",
            "Ran epoch 73 and got t_acc = 0.660300 val_acc = 0.644000, t_loss = 0.854763, v_loss = 0.852171\n",
            "Ran epoch 74 and got t_acc = 0.664045 val_acc = 0.664000, t_loss = 0.850360, v_loss = 0.848665\n",
            "Ran epoch 75 and got t_acc = 0.672285 val_acc = 0.656000, t_loss = 0.846924, v_loss = 0.861283\n",
            "Ran epoch 76 and got t_acc = 0.671536 val_acc = 0.658000, t_loss = 0.840971, v_loss = 0.856755\n",
            "Ran epoch 77 and got t_acc = 0.669288 val_acc = 0.658000, t_loss = 0.839881, v_loss = 0.840199\n",
            "Ran epoch 78 and got t_acc = 0.671536 val_acc = 0.650000, t_loss = 0.833256, v_loss = 0.839106\n",
            "Ran epoch 79 and got t_acc = 0.673783 val_acc = 0.660000, t_loss = 0.832460, v_loss = 0.850649\n",
            "Ran epoch 80 and got t_acc = 0.672659 val_acc = 0.672000, t_loss = 0.835223, v_loss = 0.847114\n",
            "Ran epoch 81 and got t_acc = 0.672285 val_acc = 0.658000, t_loss = 0.822390, v_loss = 0.840571\n",
            "Ran epoch 82 and got t_acc = 0.677154 val_acc = 0.656000, t_loss = 0.819376, v_loss = 0.835932\n",
            "Ran epoch 83 and got t_acc = 0.677154 val_acc = 0.672000, t_loss = 0.819756, v_loss = 0.833721\n",
            "Ran epoch 84 and got t_acc = 0.682022 val_acc = 0.664000, t_loss = 0.816233, v_loss = 0.846627\n",
            "Ran epoch 85 and got t_acc = 0.681273 val_acc = 0.662000, t_loss = 0.809070, v_loss = 0.827026\n",
            "Ran epoch 86 and got t_acc = 0.680899 val_acc = 0.666000, t_loss = 0.807232, v_loss = 0.826097\n",
            "Ran epoch 87 and got t_acc = 0.685768 val_acc = 0.660000, t_loss = 0.802839, v_loss = 0.836317\n",
            "Ran epoch 88 and got t_acc = 0.679026 val_acc = 0.684000, t_loss = 0.806163, v_loss = 0.833383\n",
            "Ran epoch 89 and got t_acc = 0.686891 val_acc = 0.664000, t_loss = 0.794693, v_loss = 0.824940\n",
            "Ran epoch 90 and got t_acc = 0.686517 val_acc = 0.660000, t_loss = 0.795675, v_loss = 0.832577\n",
            "Ran epoch 91 and got t_acc = 0.685393 val_acc = 0.676000, t_loss = 0.793494, v_loss = 0.823053\n",
            "Ran epoch 92 and got t_acc = 0.697378 val_acc = 0.670000, t_loss = 0.789181, v_loss = 0.832599\n",
            "Ran epoch 93 and got t_acc = 0.694382 val_acc = 0.668000, t_loss = 0.782634, v_loss = 0.825551\n",
            "Ran epoch 94 and got t_acc = 0.691760 val_acc = 0.676000, t_loss = 0.784158, v_loss = 0.816951\n",
            "Ran epoch 95 and got t_acc = 0.698127 val_acc = 0.668000, t_loss = 0.774316, v_loss = 0.823753\n",
            "Ran epoch 96 and got t_acc = 0.695506 val_acc = 0.678000, t_loss = 0.778334, v_loss = 0.830803\n",
            "Ran epoch 97 and got t_acc = 0.701498 val_acc = 0.672000, t_loss = 0.767573, v_loss = 0.817940\n",
            "Ran epoch 98 and got t_acc = 0.693633 val_acc = 0.664000, t_loss = 0.770550, v_loss = 0.819416\n",
            "Ran epoch 99 and got t_acc = 0.695131 val_acc = 0.686000, t_loss = 0.769927, v_loss = 0.814996\n",
            "Ran epoch 100 and got t_acc = 0.703745 val_acc = 0.666000, t_loss = 0.767537, v_loss = 0.831195\n",
            "Ran epoch 101 and got t_acc = 0.699251 val_acc = 0.676000, t_loss = 0.762483, v_loss = 0.811161\n",
            "Ran epoch 102 and got t_acc = 0.700749 val_acc = 0.668000, t_loss = 0.757701, v_loss = 0.811359\n",
            "Ran epoch 103 and got t_acc = 0.707865 val_acc = 0.676000, t_loss = 0.757906, v_loss = 0.827914\n",
            "Ran epoch 104 and got t_acc = 0.701124 val_acc = 0.682000, t_loss = 0.754094, v_loss = 0.816200\n",
            "Ran epoch 105 and got t_acc = 0.702247 val_acc = 0.684000, t_loss = 0.754726, v_loss = 0.809407\n",
            "Ran epoch 106 and got t_acc = 0.707116 val_acc = 0.668000, t_loss = 0.749502, v_loss = 0.823978\n",
            "Ran epoch 107 and got t_acc = 0.707865 val_acc = 0.684000, t_loss = 0.748017, v_loss = 0.822823\n",
            "Ran epoch 108 and got t_acc = 0.710487 val_acc = 0.680000, t_loss = 0.739820, v_loss = 0.810287\n",
            "Ran epoch 109 and got t_acc = 0.703745 val_acc = 0.672000, t_loss = 0.743643, v_loss = 0.820724\n",
            "Ran epoch 110 and got t_acc = 0.711985 val_acc = 0.684000, t_loss = 0.734655, v_loss = 0.812109\n",
            "Ran epoch 111 and got t_acc = 0.716854 val_acc = 0.680000, t_loss = 0.729231, v_loss = 0.814552\n",
            "Ran epoch 112 and got t_acc = 0.717228 val_acc = 0.670000, t_loss = 0.726243, v_loss = 0.808443\n",
            "Ran epoch 113 and got t_acc = 0.711610 val_acc = 0.690000, t_loss = 0.731179, v_loss = 0.803833\n",
            "Ran epoch 114 and got t_acc = 0.722472 val_acc = 0.682000, t_loss = 0.722792, v_loss = 0.812984\n",
            "Ran epoch 115 and got t_acc = 0.723221 val_acc = 0.680000, t_loss = 0.716784, v_loss = 0.807777\n",
            "Ran epoch 116 and got t_acc = 0.720599 val_acc = 0.684000, t_loss = 0.717960, v_loss = 0.802638\n",
            "Ran epoch 117 and got t_acc = 0.726592 val_acc = 0.676000, t_loss = 0.710182, v_loss = 0.803957\n",
            "Ran epoch 118 and got t_acc = 0.722472 val_acc = 0.688000, t_loss = 0.710061, v_loss = 0.806004\n",
            "Ran epoch 119 and got t_acc = 0.720225 val_acc = 0.694000, t_loss = 0.709159, v_loss = 0.799475\n",
            "Ran epoch 120 and got t_acc = 0.727341 val_acc = 0.680000, t_loss = 0.702688, v_loss = 0.801089\n",
            "Ran epoch 121 and got t_acc = 0.726966 val_acc = 0.670000, t_loss = 0.704733, v_loss = 0.814665\n",
            "Ran epoch 122 and got t_acc = 0.727341 val_acc = 0.678000, t_loss = 0.698878, v_loss = 0.800611\n",
            "Ran epoch 123 and got t_acc = 0.731461 val_acc = 0.688000, t_loss = 0.696925, v_loss = 0.799392\n",
            "Ran epoch 124 and got t_acc = 0.730337 val_acc = 0.694000, t_loss = 0.694150, v_loss = 0.802377\n",
            "Ran epoch 125 and got t_acc = 0.730712 val_acc = 0.680000, t_loss = 0.688465, v_loss = 0.798612\n",
            "Ran epoch 126 and got t_acc = 0.730337 val_acc = 0.682000, t_loss = 0.687912, v_loss = 0.797452\n",
            "Ran epoch 127 and got t_acc = 0.737079 val_acc = 0.688000, t_loss = 0.683329, v_loss = 0.799623\n",
            "Ran epoch 128 and got t_acc = 0.737828 val_acc = 0.696000, t_loss = 0.682351, v_loss = 0.800464\n",
            "Ran epoch 129 and got t_acc = 0.731461 val_acc = 0.684000, t_loss = 0.680056, v_loss = 0.797258\n",
            "Ran epoch 130 and got t_acc = 0.732959 val_acc = 0.676000, t_loss = 0.682552, v_loss = 0.811687\n",
            "Ran epoch 131 and got t_acc = 0.730337 val_acc = 0.682000, t_loss = 0.696176, v_loss = 0.823807\n",
            "Ran epoch 132 and got t_acc = 0.726966 val_acc = 0.682000, t_loss = 0.693232, v_loss = 0.818397\n",
            "Ran epoch 133 and got t_acc = 0.739700 val_acc = 0.690000, t_loss = 0.671316, v_loss = 0.800138\n",
            "Ran epoch 134 and got t_acc = 0.736330 val_acc = 0.682000, t_loss = 0.690038, v_loss = 0.832663\n",
            "Ran epoch 135 and got t_acc = 0.730712 val_acc = 0.686000, t_loss = 0.680128, v_loss = 0.818199\n",
            "Ran epoch 136 and got t_acc = 0.729213 val_acc = 0.678000, t_loss = 0.680357, v_loss = 0.806002\n",
            "Ran epoch 137 and got t_acc = 0.740075 val_acc = 0.698000, t_loss = 0.668972, v_loss = 0.818580\n",
            "Ran epoch 138 and got t_acc = 0.735581 val_acc = 0.692000, t_loss = 0.669008, v_loss = 0.821289\n",
            "Ran epoch 139 and got t_acc = 0.731461 val_acc = 0.670000, t_loss = 0.673199, v_loss = 0.805967\n",
            "Ran epoch 140 and got t_acc = 0.749813 val_acc = 0.692000, t_loss = 0.651816, v_loss = 0.801699\n",
            "Ran epoch 141 and got t_acc = 0.742697 val_acc = 0.678000, t_loss = 0.661173, v_loss = 0.821332\n",
            "Ran epoch 142 and got t_acc = 0.747191 val_acc = 0.684000, t_loss = 0.650841, v_loss = 0.801398\n",
            "Ran epoch 143 and got t_acc = 0.747940 val_acc = 0.690000, t_loss = 0.647201, v_loss = 0.797739\n",
            "Ran epoch 144 and got t_acc = 0.752434 val_acc = 0.700000, t_loss = 0.642142, v_loss = 0.800443\n",
            "Ran epoch 145 and got t_acc = 0.754682 val_acc = 0.704000, t_loss = 0.640848, v_loss = 0.802416\n",
            "Ran epoch 146 and got t_acc = 0.745693 val_acc = 0.678000, t_loss = 0.644854, v_loss = 0.800936\n",
            "Ran epoch 147 and got t_acc = 0.751311 val_acc = 0.696000, t_loss = 0.633658, v_loss = 0.795777\n",
            "Ran epoch 148 and got t_acc = 0.752809 val_acc = 0.696000, t_loss = 0.641483, v_loss = 0.812629\n",
            "Ran epoch 149 and got t_acc = 0.752809 val_acc = 0.698000, t_loss = 0.637198, v_loss = 0.802316\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For Q4:\n",
            "Best train accuracy: 0.7546816479400749\n",
            "Best val accuracy: 0.704\n",
            "Lowest Train Loss is 0.633658310877092\n",
            "Lowest Val Loss is 0.7957766910738746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fx-JPJus9dT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "2ec5048d-d12e-4036-8ace-64765d108932"
      },
      "source": [
        "num_partition = 5\n",
        "x_test_arrays = np.split(X_TEST, num_partition)\n",
        "y_test_arrays = np.split(np.array(Y_TEST), num_partition)\n",
        "n_images = len (x_test_arrays[0])\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "print ('For Q5:')\n",
        "for i in range(num_partition):\n",
        "    class_predictions, class_loss = predict(CNN,x_test_arrays[i], y_test_arrays[i], 0)\n",
        "    accuracy = np.mean(class_predictions==y_test_arrays[i])\n",
        "    print('For Category ' , CATEGORIES[i],' , Got Accuracy' , accuracy)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "y_pos = np.arange(len(CATEGORIES))\n",
        "\n",
        "plt.bar(CATEGORIES, accuracies)\n",
        " \n",
        "plt.xticks(CATEGORIES, CATEGORIES)\n",
        " \n",
        "plt.title(\"CCR\")\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Q5:\n",
            "For Category  daisy  , Got Accuracy 0.75\n",
            "For Category  dandelion  , Got Accuracy 0.9\n",
            "For Category  roses  , Got Accuracy 0.46\n",
            "For Category  sunflowers  , Got Accuracy 0.83\n",
            "For Category  tulips  , Got Accuracy 0.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'CCR')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6OsCVIje2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf5172e-b46c-4e32-855c-e553fcff5e29"
      },
      "source": [
        "predicted_test, test_loss = predict(CNN,X_TEST, Y_TEST, 0)\n",
        "accuracy = np.mean(predicted_test==np.array(Y_TEST))\n",
        "    \n",
        "print(\"َََQ6: ACCR = %f\" % accuracy)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "َََQ6: ACCR = 0.708000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awr4heEBIQAx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}