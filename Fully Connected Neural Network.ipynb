{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PMLD_HW#2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhmfDYTH9KWk",
        "outputId": "2c15fdc6-1b16-4791-d2d3-440a7db89495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -c http://download.tensorflow.org/example_images/flower_photos.tgz -O - | tar -xz\n",
        "!tar -xzvf flower_photos.tgz"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-07 01:44:02--  http://download.tensorflow.org/example_images/flower_photos.tgz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.15.80, 2607:f8b0:4004:810::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.15.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228813984 (218M) [application/x-compressed-tar]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 218.21M  90.2MB/s    in 2.4s    \n",
            "\n",
            "2020-11-07 01:44:05 (90.2 MB/s) - written to stdout [228813984/228813984]\n",
            "\n",
            "tar (child): flower_photos.tgz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a81Px5xTX5v5",
        "outputId": "9f453461-a55e-4ba9-8784-fd9a03b1a7fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cupy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os.path\n",
        "\n",
        "np.random.seed(50)\n",
        "\n",
        "CATEGORIES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "IMG_SIZE = 32\n",
        "\n",
        "def get_data(DATADIR, raw_training_data, raw_testing_data):\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(DATADIR,category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "\n",
        "        num_files = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for img in sorted(tqdm(os.listdir(path))):\n",
        "            try:\n",
        "\n",
        "                img_array = cv2.imread(os.path.join(path,img))\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                count+=1\n",
        "                if count < num_files-99:\n",
        "                    raw_training_data.append([new_array, class_num])\n",
        "                else:\n",
        "                    raw_testing_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "raw_training_data = []\n",
        "raw_testing_data = []\n",
        "\n",
        "DATADIR = \"flower_photos\"\n",
        "\n",
        "get_data(DATADIR, raw_training_data, raw_testing_data)\n",
        "\n",
        "\n",
        "print(len(raw_training_data), len(raw_testing_data))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 633/633 [00:00<00:00, 949229.33it/s]\n",
            "100%|██████████| 898/898 [00:00<00:00, 904318.13it/s]\n",
            "100%|██████████| 641/641 [00:00<00:00, 380598.65it/s]\n",
            "100%|██████████| 699/699 [00:00<00:00, 172897.24it/s]\n",
            "100%|██████████| 799/799 [00:00<00:00, 1296421.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3170 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t31uwkro9iKN",
        "outputId": "204c2cfd-b5c2-4bb3-86fa-a4ea0fe8a1b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from skimage import color\n",
        "from skimage import io\n",
        "from sklearn.utils import shuffle\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X_TRAIN = []\n",
        "Y_TRAIN = []\n",
        "\n",
        "X_TEST = []\n",
        "Y_TEST = []\n",
        "\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "\n",
        "\n",
        "for features,label in raw_training_data:\n",
        "    X_TRAIN.append(features)\n",
        "    Y_TRAIN.append(label)\n",
        "\n",
        "\n",
        "for features,label in raw_testing_data:\n",
        "    X_TEST.append(features)\n",
        "    Y_TEST.append(label)\n",
        "\n",
        "X_TRAIN = np.array(X_TRAIN).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X_TEST = np.array(X_TEST).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_TRAIN = np.array(Y_TRAIN)\n",
        "X_TRAIN, Y_TRAIN = shuffle(X_TRAIN, Y_TRAIN)\n",
        "\n",
        "X_TRAIN = X_TRAIN.astype(float) / 255.\n",
        "X_TEST = X_TEST.astype(float) / 255.\n",
        "\n",
        "\n",
        "X_TRAIN, X_VAL = X_TRAIN[:-500], X_TRAIN[-500:]\n",
        "Y_TRAIN, Y_VAL = Y_TRAIN[:-500], Y_TRAIN[-500:]\n",
        "\n",
        "\n",
        "X_TRAIN = X_TRAIN.reshape([X_TRAIN.shape[0], -1])\n",
        "X_VAL = X_VAL.reshape([X_VAL.shape[0], -1])\n",
        "X_TEST = X_TEST.reshape([X_TEST.shape[0], -1])\n",
        "\n",
        "X_TRAIN -= np.mean(X_TRAIN, axis=0)\n",
        "X_TEST -= np.mean(X_TEST, axis=0)\n",
        "\n",
        "X_TRAIN /= np.std(X_TRAIN, axis=0)\n",
        "X_TEST /= np.std(X_TEST, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print (len(X_TRAIN), len(X_VAL))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2670 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRQmJub48Cbl"
      },
      "source": [
        "all_ws = []\n",
        "class weights_layer():\n",
        "    def __init__(self, fan_in, fan_out, lr=0.05, lamdaa = 0):\n",
        "        self.lamdaa = lamdaa\n",
        "        self.ws = []\n",
        "        self.lr = lr\n",
        "        self.ws = np.random.randn(fan_in, fan_out)/np.sqrt(fan_in)\n",
        "        self.bs = np.zeros(fan_out)\n",
        "        \n",
        "    def forward(self,input):\n",
        "        #all_ws.append(self.ws)\n",
        "        return np.dot(input,self.ws) + self.bs\n",
        "    \n",
        "    def backward(self,input,grad_output):\n",
        "        dout_din = np.dot(grad_output, self.ws.T)\n",
        "        dout_dws = np.dot(input.T, grad_output)\n",
        "        dout_dbs = grad_output.mean(axis=0)*input.shape[0]\n",
        "        \n",
        "        assert dout_dws.shape == self.ws.shape and dout_dbs.shape == self.bs.shape\n",
        "\n",
        "        self.ws = self.ws - self.lr * dout_dws  #+ (self.lamdaa * np.sum(self.ws))/input.shape[0])  )\n",
        "        self.bs = self.bs - self.lr * dout_dbs\n",
        "        \n",
        "        return dout_din"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgrL-8G27wBE"
      },
      "source": [
        "class ReLU():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        relu_forward = np.maximum(0,input)\n",
        "        return relu_forward\n",
        "    \n",
        "    def backward(self, input, grad_output):\n",
        "        relu_grad = input > 0\n",
        "        return grad_output*relu_grad\n",
        "\n",
        "class tanh():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, input):\n",
        "        return np.tanh(input)\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "      return grad_output*(1-np.tanh(input)**2)\n",
        "\n",
        "class sigmoid():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, input):\n",
        "        return 1/(1+np.exp(-1* input))\n",
        "    def backward(self, input, grad_output):\n",
        "        return grad_output * (input*(1-input))\n"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hNvNqi_94XB"
      },
      "source": [
        "\n",
        "def NLL(expected_probabilities,actual_labels, m, lamdaa = 0):\n",
        "\n",
        "    correct_prob = expected_probabilities[np.arange(len(expected_probabilities)),actual_labels]\n",
        "\n",
        "    p = np.exp(correct_prob) / np.sum(np.exp(expected_probabilities),axis=-1)\n",
        "\n",
        "    loss = -1 * np.log(p)\n",
        "    \n",
        "    s_reg = 0\n",
        "    #for i in all_ws:\n",
        "    #  s_reg += np.sum(np.square(i))\n",
        "    \n",
        "    return loss #+ (lamdaa * s_reg)/m\n",
        "\n",
        "def back_NLL(expected_probabilities,actual_labels):\n",
        "\n",
        "    hotmap = np.zeros_like(expected_probabilities)\n",
        "    hotmap[np.arange(len(expected_probabilities)),actual_labels] = 1\n",
        "    \n",
        "    ratios = np.exp(expected_probabilities) / np.exp(expected_probabilities).sum(axis=-1,keepdims=True)\n",
        "    \n",
        "    return (- hotmap + ratios) / expected_probabilities.shape[0]\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMO5Mfao-6Bb"
      },
      "source": [
        "def run_batch(NN, X):\n",
        "    all_layers_outputs = []\n",
        "    received = X\n",
        "    for layer in NN:\n",
        "        all_layers_outputs.append(layer.forward(received))\n",
        "        received = all_layers_outputs[-1]\n",
        "    \n",
        "    all_ws=[]\n",
        "    assert len(all_layers_outputs) == len(NN)\n",
        "    \n",
        "    return all_layers_outputs\n",
        "\n",
        "def predict(NN,X, Y):\n",
        "    expected_probabilities = run_batch(NN,X)[-1]\n",
        "    losses = NLL(expected_probabilities,Y, X.shape[0])\n",
        "    return (expected_probabilities.argmax(axis=-1) , np.mean(losses))\n",
        "\n",
        "def train(NN,X,acutal_labels):\n",
        "\n",
        "    layers_outputs = run_batch(NN,X)\n",
        "    layers_inputs = [X]+layers_outputs \n",
        "    expected_probs = layers_outputs[-1]\n",
        "    loss = NLL(expected_probs,acutal_labels, X.shape[0])\n",
        "    loss_grad = back_NLL(expected_probs,acutal_labels)\n",
        "\n",
        "    for layer_index in range(len(NN))[::-1]:\n",
        "        layer = NN[layer_index]\n",
        "        \n",
        "        loss_grad = layer.backward(layers_inputs[layer_index],loss_grad)\n",
        "        \n",
        "    return np.mean(loss)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXZrtarROCP"
      },
      "source": [
        "from tqdm import trange\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert len(inputs) == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BejFc2tReKFm",
        "outputId": "1d0cd1a0-7305-4e37-f3e7-4f305e010786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_count = 100\n",
        "learning_rates = []\n",
        "train_log = []\n",
        "val_log = []\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "n_epochs = 10\n",
        "\n",
        "for count in range(max_count):\n",
        "\n",
        "  lr = 10**np.random.uniform(-1,-4) \n",
        "  \n",
        "  NN = []\n",
        "  NN.append(weights_layer(X_TRAIN.shape[1],200,lr))\n",
        "  NN.append(ReLU())\n",
        "  NN.append(weights_layer(200,200,lr))\n",
        "  NN.append(ReLU())\n",
        "  NN.append(weights_layer(200,5,lr))\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    train(NN,X_TRAIN,Y_TRAIN)\n",
        "\n",
        "    train_predictions, train_loss = predict(NN,X_TRAIN, Y_TRAIN)\n",
        "\n",
        "    val_predictions, val_loss = predict(NN,X_VAL, Y_VAL)\n",
        "\n",
        "    train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
        "\n",
        "    val_log.append(np.mean(val_predictions==Y_VAL))\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    learning_rates.append(lr)\n",
        "\n",
        "    print(\"Trial %d epoch %d got t_acc = %f, v_acc = %f, t_loss = %f, and v_loss = %f at lr = %f\" % (count, epoch, train_log[-1], train_losses[-1],val_losses[-1], val_log[-1], lr))\n",
        "\n",
        "print()\n",
        "print(\"Got highest train accuracy = %f at lr = %f\" % (max(train_log), learning_rates[train_log.index(max(train_log))]))\n",
        "print(\"Got highest val accuracy = %f at lr = %f\" % (max(val_log), learning_rates[val_log.index(max(val_log))]))\n",
        "print(\"Got lowest train loss = %f at lr = %f\" % (min(train_losses), learning_rates[train_losses.index(min(train_losses))]))\n",
        "print(\"Got lowest val loss = %f at lr = %f\" % (min(val_losses), learning_rates[val_losses.index(min(val_losses))]))\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 0 epoch 0 got t_acc = 0.248315, v_acc = 1.661844, t_loss = 1.628924, and v_loss = 0.192000 at lr = 0.000926\n",
            "Trial 0 epoch 1 got t_acc = 0.250562, v_acc = 1.659515, t_loss = 1.628108, and v_loss = 0.194000 at lr = 0.000926\n",
            "Trial 0 epoch 2 got t_acc = 0.252434, v_acc = 1.657229, t_loss = 1.627304, and v_loss = 0.192000 at lr = 0.000926\n",
            "Trial 0 epoch 3 got t_acc = 0.252809, v_acc = 1.654977, t_loss = 1.626514, and v_loss = 0.194000 at lr = 0.000926\n",
            "Trial 0 epoch 4 got t_acc = 0.255805, v_acc = 1.652760, t_loss = 1.625734, and v_loss = 0.196000 at lr = 0.000926\n",
            "Trial 0 epoch 5 got t_acc = 0.257303, v_acc = 1.650576, t_loss = 1.624967, and v_loss = 0.198000 at lr = 0.000926\n",
            "Trial 0 epoch 6 got t_acc = 0.261049, v_acc = 1.648424, t_loss = 1.624211, and v_loss = 0.194000 at lr = 0.000926\n",
            "Trial 0 epoch 7 got t_acc = 0.263296, v_acc = 1.646300, t_loss = 1.623467, and v_loss = 0.190000 at lr = 0.000926\n",
            "Trial 0 epoch 8 got t_acc = 0.265169, v_acc = 1.644206, t_loss = 1.622735, and v_loss = 0.190000 at lr = 0.000926\n",
            "Trial 0 epoch 9 got t_acc = 0.267416, v_acc = 1.642141, t_loss = 1.622014, and v_loss = 0.190000 at lr = 0.000926\n",
            "Trial 1 epoch 0 got t_acc = 0.256180, v_acc = 1.601700, t_loss = 1.599076, and v_loss = 0.260000 at lr = 0.039301\n",
            "Trial 1 epoch 1 got t_acc = 0.307116, v_acc = 1.542131, t_loss = 1.584003, and v_loss = 0.288000 at lr = 0.039301\n",
            "Trial 1 epoch 2 got t_acc = 0.342322, v_acc = 1.496923, t_loss = 1.571853, and v_loss = 0.316000 at lr = 0.039301\n",
            "Trial 1 epoch 3 got t_acc = 0.367041, v_acc = 1.459865, t_loss = 1.561162, and v_loss = 0.346000 at lr = 0.039301\n",
            "Trial 1 epoch 4 got t_acc = 0.387640, v_acc = 1.428250, t_loss = 1.551967, and v_loss = 0.350000 at lr = 0.039301\n",
            "Trial 1 epoch 5 got t_acc = 0.402247, v_acc = 1.400526, t_loss = 1.544030, and v_loss = 0.352000 at lr = 0.039301\n",
            "Trial 1 epoch 6 got t_acc = 0.421723, v_acc = 1.375961, t_loss = 1.537366, and v_loss = 0.346000 at lr = 0.039301\n",
            "Trial 1 epoch 7 got t_acc = 0.437079, v_acc = 1.353900, t_loss = 1.531648, and v_loss = 0.378000 at lr = 0.039301\n",
            "Trial 1 epoch 8 got t_acc = 0.451311, v_acc = 1.333833, t_loss = 1.526707, and v_loss = 0.384000 at lr = 0.039301\n",
            "Trial 1 epoch 9 got t_acc = 0.461049, v_acc = 1.315359, t_loss = 1.522456, and v_loss = 0.376000 at lr = 0.039301\n",
            "Trial 2 epoch 0 got t_acc = 0.300749, v_acc = 1.555095, t_loss = 1.599850, and v_loss = 0.256000 at lr = 0.057468\n",
            "Trial 2 epoch 1 got t_acc = 0.348689, v_acc = 1.494408, t_loss = 1.581740, and v_loss = 0.276000 at lr = 0.057468\n",
            "Trial 2 epoch 2 got t_acc = 0.386142, v_acc = 1.447639, t_loss = 1.569487, and v_loss = 0.290000 at lr = 0.057468\n",
            "Trial 2 epoch 3 got t_acc = 0.414232, v_acc = 1.408952, t_loss = 1.559076, and v_loss = 0.288000 at lr = 0.057468\n",
            "Trial 2 epoch 4 got t_acc = 0.432584, v_acc = 1.375593, t_loss = 1.550676, and v_loss = 0.298000 at lr = 0.057468\n",
            "Trial 2 epoch 5 got t_acc = 0.449064, v_acc = 1.346053, t_loss = 1.543578, and v_loss = 0.308000 at lr = 0.057468\n",
            "Trial 2 epoch 6 got t_acc = 0.469663, v_acc = 1.319406, t_loss = 1.537471, and v_loss = 0.314000 at lr = 0.057468\n",
            "Trial 2 epoch 7 got t_acc = 0.480150, v_acc = 1.295131, t_loss = 1.532416, and v_loss = 0.316000 at lr = 0.057468\n",
            "Trial 2 epoch 8 got t_acc = 0.493258, v_acc = 1.272853, t_loss = 1.527978, and v_loss = 0.310000 at lr = 0.057468\n",
            "Trial 2 epoch 9 got t_acc = 0.500749, v_acc = 1.252211, t_loss = 1.524170, and v_loss = 0.322000 at lr = 0.057468\n",
            "Trial 3 epoch 0 got t_acc = 0.199251, v_acc = 1.710857, t_loss = 1.618194, and v_loss = 0.178000 at lr = 0.001967\n",
            "Trial 3 epoch 1 got t_acc = 0.200000, v_acc = 1.704242, t_loss = 1.616263, and v_loss = 0.178000 at lr = 0.001967\n",
            "Trial 3 epoch 2 got t_acc = 0.201873, v_acc = 1.697881, t_loss = 1.614434, and v_loss = 0.180000 at lr = 0.001967\n",
            "Trial 3 epoch 3 got t_acc = 0.202247, v_acc = 1.691757, t_loss = 1.612704, and v_loss = 0.178000 at lr = 0.001967\n",
            "Trial 3 epoch 4 got t_acc = 0.203371, v_acc = 1.685854, t_loss = 1.611060, and v_loss = 0.186000 at lr = 0.001967\n",
            "Trial 3 epoch 5 got t_acc = 0.205618, v_acc = 1.680158, t_loss = 1.609496, and v_loss = 0.192000 at lr = 0.001967\n",
            "Trial 3 epoch 6 got t_acc = 0.208240, v_acc = 1.674655, t_loss = 1.608001, and v_loss = 0.196000 at lr = 0.001967\n",
            "Trial 3 epoch 7 got t_acc = 0.212360, v_acc = 1.669331, t_loss = 1.606570, and v_loss = 0.200000 at lr = 0.001967\n",
            "Trial 3 epoch 8 got t_acc = 0.213109, v_acc = 1.664174, t_loss = 1.605199, and v_loss = 0.204000 at lr = 0.001967\n",
            "Trial 3 epoch 9 got t_acc = 0.214232, v_acc = 1.659179, t_loss = 1.603883, and v_loss = 0.204000 at lr = 0.001967\n",
            "Trial 4 epoch 0 got t_acc = 0.222097, v_acc = 1.639191, t_loss = 1.625453, and v_loss = 0.148000 at lr = 0.020709\n",
            "Trial 4 epoch 1 got t_acc = 0.241948, v_acc = 1.606901, t_loss = 1.619062, and v_loss = 0.166000 at lr = 0.020709\n",
            "Trial 4 epoch 2 got t_acc = 0.273408, v_acc = 1.579044, t_loss = 1.613235, and v_loss = 0.190000 at lr = 0.020709\n",
            "Trial 4 epoch 3 got t_acc = 0.297753, v_acc = 1.554173, t_loss = 1.607813, and v_loss = 0.218000 at lr = 0.020709\n",
            "Trial 4 epoch 4 got t_acc = 0.322846, v_acc = 1.531718, t_loss = 1.602803, and v_loss = 0.236000 at lr = 0.020709\n",
            "Trial 4 epoch 5 got t_acc = 0.350936, v_acc = 1.511181, t_loss = 1.598115, and v_loss = 0.256000 at lr = 0.020709\n",
            "Trial 4 epoch 6 got t_acc = 0.364419, v_acc = 1.492147, t_loss = 1.593595, and v_loss = 0.272000 at lr = 0.020709\n",
            "Trial 4 epoch 7 got t_acc = 0.380524, v_acc = 1.474417, t_loss = 1.589312, and v_loss = 0.280000 at lr = 0.020709\n",
            "Trial 4 epoch 8 got t_acc = 0.399251, v_acc = 1.457878, t_loss = 1.585192, and v_loss = 0.280000 at lr = 0.020709\n",
            "Trial 4 epoch 9 got t_acc = 0.409363, v_acc = 1.442381, t_loss = 1.581270, and v_loss = 0.302000 at lr = 0.020709\n",
            "Trial 5 epoch 0 got t_acc = 0.198502, v_acc = 1.704921, t_loss = 1.644778, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 1 got t_acc = 0.199251, v_acc = 1.703692, t_loss = 1.644366, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 2 got t_acc = 0.199251, v_acc = 1.702470, t_loss = 1.643956, and v_loss = 0.232000 at lr = 0.000347\n",
            "Trial 5 epoch 3 got t_acc = 0.199251, v_acc = 1.701258, t_loss = 1.643551, and v_loss = 0.232000 at lr = 0.000347\n",
            "Trial 5 epoch 4 got t_acc = 0.200375, v_acc = 1.700053, t_loss = 1.643149, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 5 got t_acc = 0.200000, v_acc = 1.698856, t_loss = 1.642749, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 6 got t_acc = 0.200375, v_acc = 1.697667, t_loss = 1.642354, and v_loss = 0.236000 at lr = 0.000347\n",
            "Trial 5 epoch 7 got t_acc = 0.201498, v_acc = 1.696486, t_loss = 1.641963, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 8 got t_acc = 0.201498, v_acc = 1.695312, t_loss = 1.641574, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 5 epoch 9 got t_acc = 0.202247, v_acc = 1.694147, t_loss = 1.641189, and v_loss = 0.234000 at lr = 0.000347\n",
            "Trial 6 epoch 0 got t_acc = 0.181273, v_acc = 1.695582, t_loss = 1.626648, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 1 got t_acc = 0.181273, v_acc = 1.695239, t_loss = 1.626523, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 2 got t_acc = 0.181273, v_acc = 1.694896, t_loss = 1.626398, and v_loss = 0.230000 at lr = 0.000137\n",
            "Trial 6 epoch 3 got t_acc = 0.181273, v_acc = 1.694554, t_loss = 1.626274, and v_loss = 0.226000 at lr = 0.000137\n",
            "Trial 6 epoch 4 got t_acc = 0.182022, v_acc = 1.694214, t_loss = 1.626150, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 5 got t_acc = 0.182022, v_acc = 1.693874, t_loss = 1.626027, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 6 got t_acc = 0.183146, v_acc = 1.693534, t_loss = 1.625905, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 7 got t_acc = 0.183146, v_acc = 1.693196, t_loss = 1.625783, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 8 got t_acc = 0.183146, v_acc = 1.692858, t_loss = 1.625662, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 6 epoch 9 got t_acc = 0.183521, v_acc = 1.692522, t_loss = 1.625541, and v_loss = 0.228000 at lr = 0.000137\n",
            "Trial 7 epoch 0 got t_acc = 0.194382, v_acc = 1.741390, t_loss = 1.658413, and v_loss = 0.136000 at lr = 0.003694\n",
            "Trial 7 epoch 1 got t_acc = 0.198876, v_acc = 1.726227, t_loss = 1.654105, and v_loss = 0.138000 at lr = 0.003694\n",
            "Trial 7 epoch 2 got t_acc = 0.202247, v_acc = 1.712025, t_loss = 1.650028, and v_loss = 0.144000 at lr = 0.003694\n",
            "Trial 7 epoch 3 got t_acc = 0.206367, v_acc = 1.698659, t_loss = 1.646145, and v_loss = 0.148000 at lr = 0.003694\n",
            "Trial 7 epoch 4 got t_acc = 0.208240, v_acc = 1.686091, t_loss = 1.642452, and v_loss = 0.156000 at lr = 0.003694\n",
            "Trial 7 epoch 5 got t_acc = 0.213483, v_acc = 1.674248, t_loss = 1.638942, and v_loss = 0.158000 at lr = 0.003694\n",
            "Trial 7 epoch 6 got t_acc = 0.219850, v_acc = 1.663076, t_loss = 1.635594, and v_loss = 0.150000 at lr = 0.003694\n",
            "Trial 7 epoch 7 got t_acc = 0.227715, v_acc = 1.652513, t_loss = 1.632380, and v_loss = 0.168000 at lr = 0.003694\n",
            "Trial 7 epoch 8 got t_acc = 0.231086, v_acc = 1.642528, t_loss = 1.629289, and v_loss = 0.182000 at lr = 0.003694\n",
            "Trial 7 epoch 9 got t_acc = 0.233708, v_acc = 1.633082, t_loss = 1.626332, and v_loss = 0.194000 at lr = 0.003694\n",
            "Trial 8 epoch 0 got t_acc = 0.238951, v_acc = 1.630177, t_loss = 1.618753, and v_loss = 0.188000 at lr = 0.026952\n",
            "Trial 8 epoch 1 got t_acc = 0.270412, v_acc = 1.585838, t_loss = 1.608290, and v_loss = 0.204000 at lr = 0.026952\n",
            "Trial 8 epoch 2 got t_acc = 0.302622, v_acc = 1.549050, t_loss = 1.599146, and v_loss = 0.236000 at lr = 0.026952\n",
            "Trial 8 epoch 3 got t_acc = 0.331086, v_acc = 1.517158, t_loss = 1.590950, and v_loss = 0.264000 at lr = 0.026952\n",
            "Trial 8 epoch 4 got t_acc = 0.351685, v_acc = 1.489333, t_loss = 1.583718, and v_loss = 0.298000 at lr = 0.026952\n",
            "Trial 8 epoch 5 got t_acc = 0.368165, v_acc = 1.464608, t_loss = 1.577206, and v_loss = 0.298000 at lr = 0.026952\n",
            "Trial 8 epoch 6 got t_acc = 0.384644, v_acc = 1.442237, t_loss = 1.570976, and v_loss = 0.306000 at lr = 0.026952\n",
            "Trial 8 epoch 7 got t_acc = 0.400375, v_acc = 1.421786, t_loss = 1.565367, and v_loss = 0.308000 at lr = 0.026952\n",
            "Trial 8 epoch 8 got t_acc = 0.412360, v_acc = 1.403062, t_loss = 1.560141, and v_loss = 0.316000 at lr = 0.026952\n",
            "Trial 8 epoch 9 got t_acc = 0.421348, v_acc = 1.385774, t_loss = 1.555332, and v_loss = 0.316000 at lr = 0.026952\n",
            "Trial 9 epoch 0 got t_acc = 0.216105, v_acc = 1.698256, t_loss = 1.621360, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 1 got t_acc = 0.216479, v_acc = 1.697851, t_loss = 1.621264, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 2 got t_acc = 0.216105, v_acc = 1.697446, t_loss = 1.621168, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 3 got t_acc = 0.216105, v_acc = 1.697042, t_loss = 1.621073, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 4 got t_acc = 0.216479, v_acc = 1.696639, t_loss = 1.620978, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 5 got t_acc = 0.216854, v_acc = 1.696237, t_loss = 1.620883, and v_loss = 0.242000 at lr = 0.000118\n",
            "Trial 9 epoch 6 got t_acc = 0.216854, v_acc = 1.695836, t_loss = 1.620788, and v_loss = 0.244000 at lr = 0.000118\n",
            "Trial 9 epoch 7 got t_acc = 0.216854, v_acc = 1.695435, t_loss = 1.620694, and v_loss = 0.244000 at lr = 0.000118\n",
            "Trial 9 epoch 8 got t_acc = 0.217228, v_acc = 1.695035, t_loss = 1.620600, and v_loss = 0.244000 at lr = 0.000118\n",
            "Trial 9 epoch 9 got t_acc = 0.217603, v_acc = 1.694636, t_loss = 1.620506, and v_loss = 0.244000 at lr = 0.000118\n",
            "Trial 10 epoch 0 got t_acc = 0.282397, v_acc = 1.581391, t_loss = 1.610445, and v_loss = 0.214000 at lr = 0.058421\n",
            "Trial 10 epoch 1 got t_acc = 0.337453, v_acc = 1.498304, t_loss = 1.589973, and v_loss = 0.270000 at lr = 0.058421\n",
            "Trial 10 epoch 2 got t_acc = 0.381273, v_acc = 1.442658, t_loss = 1.575080, and v_loss = 0.300000 at lr = 0.058421\n",
            "Trial 10 epoch 3 got t_acc = 0.410487, v_acc = 1.400104, t_loss = 1.561763, and v_loss = 0.300000 at lr = 0.058421\n",
            "Trial 10 epoch 4 got t_acc = 0.432210, v_acc = 1.365000, t_loss = 1.549761, and v_loss = 0.306000 at lr = 0.058421\n",
            "Trial 10 epoch 5 got t_acc = 0.452809, v_acc = 1.334989, t_loss = 1.539735, and v_loss = 0.320000 at lr = 0.058421\n",
            "Trial 10 epoch 6 got t_acc = 0.468914, v_acc = 1.308605, t_loss = 1.531350, and v_loss = 0.348000 at lr = 0.058421\n",
            "Trial 10 epoch 7 got t_acc = 0.480899, v_acc = 1.284924, t_loss = 1.524279, and v_loss = 0.346000 at lr = 0.058421\n",
            "Trial 10 epoch 8 got t_acc = 0.489888, v_acc = 1.263442, t_loss = 1.518463, and v_loss = 0.348000 at lr = 0.058421\n",
            "Trial 10 epoch 9 got t_acc = 0.504120, v_acc = 1.243637, t_loss = 1.513126, and v_loss = 0.344000 at lr = 0.058421\n",
            "Trial 11 epoch 0 got t_acc = 0.238951, v_acc = 1.691254, t_loss = 1.610982, and v_loss = 0.242000 at lr = 0.001394\n",
            "Trial 11 epoch 1 got t_acc = 0.243071, v_acc = 1.687859, t_loss = 1.610420, and v_loss = 0.242000 at lr = 0.001394\n",
            "Trial 11 epoch 2 got t_acc = 0.245318, v_acc = 1.684518, t_loss = 1.609871, and v_loss = 0.240000 at lr = 0.001394\n",
            "Trial 11 epoch 3 got t_acc = 0.247940, v_acc = 1.681226, t_loss = 1.609333, and v_loss = 0.240000 at lr = 0.001394\n",
            "Trial 11 epoch 4 got t_acc = 0.249813, v_acc = 1.677981, t_loss = 1.608803, and v_loss = 0.244000 at lr = 0.001394\n",
            "Trial 11 epoch 5 got t_acc = 0.250562, v_acc = 1.674781, t_loss = 1.608282, and v_loss = 0.244000 at lr = 0.001394\n",
            "Trial 11 epoch 6 got t_acc = 0.252434, v_acc = 1.671623, t_loss = 1.607768, and v_loss = 0.248000 at lr = 0.001394\n",
            "Trial 11 epoch 7 got t_acc = 0.253933, v_acc = 1.668500, t_loss = 1.607265, and v_loss = 0.248000 at lr = 0.001394\n",
            "Trial 11 epoch 8 got t_acc = 0.255805, v_acc = 1.665422, t_loss = 1.606770, and v_loss = 0.250000 at lr = 0.001394\n",
            "Trial 11 epoch 9 got t_acc = 0.256554, v_acc = 1.662385, t_loss = 1.606283, and v_loss = 0.250000 at lr = 0.001394\n",
            "Trial 12 epoch 0 got t_acc = 0.293633, v_acc = 1.567300, t_loss = 1.618669, and v_loss = 0.170000 at lr = 0.073914\n",
            "Trial 12 epoch 1 got t_acc = 0.368165, v_acc = 1.482768, t_loss = 1.588373, and v_loss = 0.266000 at lr = 0.073914\n",
            "Trial 12 epoch 2 got t_acc = 0.404869, v_acc = 1.425867, t_loss = 1.575391, and v_loss = 0.312000 at lr = 0.073914\n",
            "Trial 12 epoch 3 got t_acc = 0.434831, v_acc = 1.380902, t_loss = 1.562703, and v_loss = 0.336000 at lr = 0.073914\n",
            "Trial 12 epoch 4 got t_acc = 0.455431, v_acc = 1.343175, t_loss = 1.551918, and v_loss = 0.338000 at lr = 0.073914\n",
            "Trial 12 epoch 5 got t_acc = 0.471910, v_acc = 1.310694, t_loss = 1.542439, and v_loss = 0.352000 at lr = 0.073914\n",
            "Trial 12 epoch 6 got t_acc = 0.487640, v_acc = 1.281944, t_loss = 1.534185, and v_loss = 0.354000 at lr = 0.073914\n",
            "Trial 12 epoch 7 got t_acc = 0.505618, v_acc = 1.256048, t_loss = 1.526960, and v_loss = 0.364000 at lr = 0.073914\n",
            "Trial 12 epoch 8 got t_acc = 0.520225, v_acc = 1.232389, t_loss = 1.520813, and v_loss = 0.356000 at lr = 0.073914\n",
            "Trial 12 epoch 9 got t_acc = 0.526592, v_acc = 1.210585, t_loss = 1.515486, and v_loss = 0.370000 at lr = 0.073914\n",
            "Trial 13 epoch 0 got t_acc = 0.184644, v_acc = 1.681316, t_loss = 1.622077, and v_loss = 0.202000 at lr = 0.000593\n",
            "Trial 13 epoch 1 got t_acc = 0.186142, v_acc = 1.679782, t_loss = 1.621751, and v_loss = 0.200000 at lr = 0.000593\n",
            "Trial 13 epoch 2 got t_acc = 0.187266, v_acc = 1.678259, t_loss = 1.621428, and v_loss = 0.200000 at lr = 0.000593\n",
            "Trial 13 epoch 3 got t_acc = 0.188015, v_acc = 1.676746, t_loss = 1.621107, and v_loss = 0.200000 at lr = 0.000593\n",
            "Trial 13 epoch 4 got t_acc = 0.188390, v_acc = 1.675241, t_loss = 1.620787, and v_loss = 0.200000 at lr = 0.000593\n",
            "Trial 13 epoch 5 got t_acc = 0.189513, v_acc = 1.673746, t_loss = 1.620469, and v_loss = 0.198000 at lr = 0.000593\n",
            "Trial 13 epoch 6 got t_acc = 0.190262, v_acc = 1.672263, t_loss = 1.620153, and v_loss = 0.200000 at lr = 0.000593\n",
            "Trial 13 epoch 7 got t_acc = 0.191011, v_acc = 1.670790, t_loss = 1.619839, and v_loss = 0.198000 at lr = 0.000593\n",
            "Trial 13 epoch 8 got t_acc = 0.192135, v_acc = 1.669327, t_loss = 1.619528, and v_loss = 0.198000 at lr = 0.000593\n",
            "Trial 13 epoch 9 got t_acc = 0.192509, v_acc = 1.667874, t_loss = 1.619218, and v_loss = 0.196000 at lr = 0.000593\n",
            "Trial 14 epoch 0 got t_acc = 0.191011, v_acc = 1.673529, t_loss = 1.624601, and v_loss = 0.164000 at lr = 0.000424\n",
            "Trial 14 epoch 1 got t_acc = 0.190637, v_acc = 1.672558, t_loss = 1.624214, and v_loss = 0.166000 at lr = 0.000424\n",
            "Trial 14 epoch 2 got t_acc = 0.190637, v_acc = 1.671592, t_loss = 1.623831, and v_loss = 0.166000 at lr = 0.000424\n",
            "Trial 14 epoch 3 got t_acc = 0.192135, v_acc = 1.670630, t_loss = 1.623451, and v_loss = 0.164000 at lr = 0.000424\n",
            "Trial 14 epoch 4 got t_acc = 0.192135, v_acc = 1.669673, t_loss = 1.623072, and v_loss = 0.164000 at lr = 0.000424\n",
            "Trial 14 epoch 5 got t_acc = 0.192509, v_acc = 1.668721, t_loss = 1.622697, and v_loss = 0.166000 at lr = 0.000424\n",
            "Trial 14 epoch 6 got t_acc = 0.193633, v_acc = 1.667773, t_loss = 1.622325, and v_loss = 0.166000 at lr = 0.000424\n",
            "Trial 14 epoch 7 got t_acc = 0.194007, v_acc = 1.666831, t_loss = 1.621955, and v_loss = 0.166000 at lr = 0.000424\n",
            "Trial 14 epoch 8 got t_acc = 0.194382, v_acc = 1.665892, t_loss = 1.621588, and v_loss = 0.168000 at lr = 0.000424\n",
            "Trial 14 epoch 9 got t_acc = 0.195131, v_acc = 1.664959, t_loss = 1.621224, and v_loss = 0.168000 at lr = 0.000424\n",
            "Trial 15 epoch 0 got t_acc = 0.207116, v_acc = 1.685783, t_loss = 1.619393, and v_loss = 0.212000 at lr = 0.009946\n",
            "Trial 15 epoch 1 got t_acc = 0.216105, v_acc = 1.661216, t_loss = 1.612500, and v_loss = 0.246000 at lr = 0.009946\n",
            "Trial 15 epoch 2 got t_acc = 0.231835, v_acc = 1.639269, t_loss = 1.606515, and v_loss = 0.266000 at lr = 0.009946\n",
            "Trial 15 epoch 3 got t_acc = 0.243071, v_acc = 1.619470, t_loss = 1.601234, and v_loss = 0.276000 at lr = 0.009946\n",
            "Trial 15 epoch 4 got t_acc = 0.255805, v_acc = 1.601478, t_loss = 1.596612, and v_loss = 0.280000 at lr = 0.009946\n",
            "Trial 15 epoch 5 got t_acc = 0.273408, v_acc = 1.585059, t_loss = 1.592568, and v_loss = 0.284000 at lr = 0.009946\n",
            "Trial 15 epoch 6 got t_acc = 0.283521, v_acc = 1.570013, t_loss = 1.588974, and v_loss = 0.296000 at lr = 0.009946\n",
            "Trial 15 epoch 7 got t_acc = 0.301124, v_acc = 1.556075, t_loss = 1.585712, and v_loss = 0.302000 at lr = 0.009946\n",
            "Trial 15 epoch 8 got t_acc = 0.313109, v_acc = 1.543118, t_loss = 1.582816, and v_loss = 0.302000 at lr = 0.009946\n",
            "Trial 15 epoch 9 got t_acc = 0.324719, v_acc = 1.530996, t_loss = 1.580145, and v_loss = 0.306000 at lr = 0.009946\n",
            "Trial 16 epoch 0 got t_acc = 0.188764, v_acc = 1.696408, t_loss = 1.635189, and v_loss = 0.192000 at lr = 0.003915\n",
            "Trial 16 epoch 1 got t_acc = 0.195506, v_acc = 1.684336, t_loss = 1.631867, and v_loss = 0.190000 at lr = 0.003915\n",
            "Trial 16 epoch 2 got t_acc = 0.200749, v_acc = 1.672947, t_loss = 1.628835, and v_loss = 0.192000 at lr = 0.003915\n",
            "Trial 16 epoch 3 got t_acc = 0.205993, v_acc = 1.662215, t_loss = 1.626024, and v_loss = 0.190000 at lr = 0.003915\n",
            "Trial 16 epoch 4 got t_acc = 0.211236, v_acc = 1.652114, t_loss = 1.623454, and v_loss = 0.190000 at lr = 0.003915\n",
            "Trial 16 epoch 5 got t_acc = 0.217228, v_acc = 1.642530, t_loss = 1.621047, and v_loss = 0.182000 at lr = 0.003915\n",
            "Trial 16 epoch 6 got t_acc = 0.229213, v_acc = 1.633448, t_loss = 1.618803, and v_loss = 0.186000 at lr = 0.003915\n",
            "Trial 16 epoch 7 got t_acc = 0.236704, v_acc = 1.624837, t_loss = 1.616705, and v_loss = 0.184000 at lr = 0.003915\n",
            "Trial 16 epoch 8 got t_acc = 0.243820, v_acc = 1.616630, t_loss = 1.614727, and v_loss = 0.188000 at lr = 0.003915\n",
            "Trial 16 epoch 9 got t_acc = 0.256554, v_acc = 1.608821, t_loss = 1.612858, and v_loss = 0.194000 at lr = 0.003915\n",
            "Trial 17 epoch 0 got t_acc = 0.196629, v_acc = 1.708083, t_loss = 1.616585, and v_loss = 0.196000 at lr = 0.005197\n",
            "Trial 17 epoch 1 got t_acc = 0.203371, v_acc = 1.687397, t_loss = 1.613393, and v_loss = 0.202000 at lr = 0.005197\n",
            "Trial 17 epoch 2 got t_acc = 0.206367, v_acc = 1.668977, t_loss = 1.610330, and v_loss = 0.198000 at lr = 0.005197\n",
            "Trial 17 epoch 3 got t_acc = 0.211236, v_acc = 1.652429, t_loss = 1.607381, and v_loss = 0.204000 at lr = 0.005197\n",
            "Trial 17 epoch 4 got t_acc = 0.218352, v_acc = 1.637437, t_loss = 1.604516, and v_loss = 0.206000 at lr = 0.005197\n",
            "Trial 17 epoch 5 got t_acc = 0.224719, v_acc = 1.623761, t_loss = 1.601793, and v_loss = 0.204000 at lr = 0.005197\n",
            "Trial 17 epoch 6 got t_acc = 0.228090, v_acc = 1.611207, t_loss = 1.599176, and v_loss = 0.214000 at lr = 0.005197\n",
            "Trial 17 epoch 7 got t_acc = 0.234457, v_acc = 1.599591, t_loss = 1.596655, and v_loss = 0.224000 at lr = 0.005197\n",
            "Trial 17 epoch 8 got t_acc = 0.242322, v_acc = 1.588794, t_loss = 1.594234, and v_loss = 0.226000 at lr = 0.005197\n",
            "Trial 17 epoch 9 got t_acc = 0.252060, v_acc = 1.578689, t_loss = 1.591886, and v_loss = 0.226000 at lr = 0.005197\n",
            "Trial 18 epoch 0 got t_acc = 0.147940, v_acc = 1.821428, t_loss = 1.725895, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 1 got t_acc = 0.148689, v_acc = 1.817627, t_loss = 1.722997, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 2 got t_acc = 0.150187, v_acc = 1.813896, t_loss = 1.720183, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 3 got t_acc = 0.150187, v_acc = 1.810235, t_loss = 1.717452, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 4 got t_acc = 0.150936, v_acc = 1.806640, t_loss = 1.714800, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 5 got t_acc = 0.151311, v_acc = 1.803117, t_loss = 1.712228, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 6 got t_acc = 0.152060, v_acc = 1.799657, t_loss = 1.709726, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 7 got t_acc = 0.152060, v_acc = 1.796260, t_loss = 1.707295, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 8 got t_acc = 0.152434, v_acc = 1.792925, t_loss = 1.704932, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 18 epoch 9 got t_acc = 0.152060, v_acc = 1.789651, t_loss = 1.702632, and v_loss = 0.156000 at lr = 0.000609\n",
            "Trial 19 epoch 0 got t_acc = 0.229588, v_acc = 1.645961, t_loss = 1.630568, and v_loss = 0.146000 at lr = 0.002982\n",
            "Trial 19 epoch 1 got t_acc = 0.231835, v_acc = 1.637175, t_loss = 1.625323, and v_loss = 0.150000 at lr = 0.002982\n",
            "Trial 19 epoch 2 got t_acc = 0.232959, v_acc = 1.628897, t_loss = 1.620589, and v_loss = 0.168000 at lr = 0.002982\n",
            "Trial 19 epoch 3 got t_acc = 0.237828, v_acc = 1.621105, t_loss = 1.616319, and v_loss = 0.180000 at lr = 0.002982\n",
            "Trial 19 epoch 4 got t_acc = 0.240075, v_acc = 1.613748, t_loss = 1.612473, and v_loss = 0.180000 at lr = 0.002982\n",
            "Trial 19 epoch 5 got t_acc = 0.244195, v_acc = 1.606768, t_loss = 1.608970, and v_loss = 0.192000 at lr = 0.002982\n",
            "Trial 19 epoch 6 got t_acc = 0.249438, v_acc = 1.600121, t_loss = 1.605753, and v_loss = 0.206000 at lr = 0.002982\n",
            "Trial 19 epoch 7 got t_acc = 0.252060, v_acc = 1.593772, t_loss = 1.602796, and v_loss = 0.218000 at lr = 0.002982\n",
            "Trial 19 epoch 8 got t_acc = 0.255431, v_acc = 1.587685, t_loss = 1.600059, and v_loss = 0.222000 at lr = 0.002982\n",
            "Trial 19 epoch 9 got t_acc = 0.263296, v_acc = 1.581850, t_loss = 1.597540, and v_loss = 0.228000 at lr = 0.002982\n",
            "Trial 20 epoch 0 got t_acc = 0.182022, v_acc = 1.726064, t_loss = 1.656573, and v_loss = 0.198000 at lr = 0.000880\n",
            "Trial 20 epoch 1 got t_acc = 0.183146, v_acc = 1.723235, t_loss = 1.655510, and v_loss = 0.198000 at lr = 0.000880\n",
            "Trial 20 epoch 2 got t_acc = 0.185019, v_acc = 1.720446, t_loss = 1.654460, and v_loss = 0.200000 at lr = 0.000880\n",
            "Trial 20 epoch 3 got t_acc = 0.185393, v_acc = 1.717692, t_loss = 1.653425, and v_loss = 0.200000 at lr = 0.000880\n",
            "Trial 20 epoch 4 got t_acc = 0.189139, v_acc = 1.714974, t_loss = 1.652402, and v_loss = 0.200000 at lr = 0.000880\n",
            "Trial 20 epoch 5 got t_acc = 0.189513, v_acc = 1.712290, t_loss = 1.651393, and v_loss = 0.202000 at lr = 0.000880\n",
            "Trial 20 epoch 6 got t_acc = 0.192509, v_acc = 1.709642, t_loss = 1.650401, and v_loss = 0.202000 at lr = 0.000880\n",
            "Trial 20 epoch 7 got t_acc = 0.192884, v_acc = 1.707029, t_loss = 1.649422, and v_loss = 0.204000 at lr = 0.000880\n",
            "Trial 20 epoch 8 got t_acc = 0.194382, v_acc = 1.704451, t_loss = 1.648457, and v_loss = 0.206000 at lr = 0.000880\n",
            "Trial 20 epoch 9 got t_acc = 0.195131, v_acc = 1.701908, t_loss = 1.647502, and v_loss = 0.206000 at lr = 0.000880\n",
            "Trial 21 epoch 0 got t_acc = 0.217603, v_acc = 1.674643, t_loss = 1.633765, and v_loss = 0.198000 at lr = 0.003230\n",
            "Trial 21 epoch 1 got t_acc = 0.218352, v_acc = 1.665850, t_loss = 1.630312, and v_loss = 0.206000 at lr = 0.003230\n",
            "Trial 21 epoch 2 got t_acc = 0.219850, v_acc = 1.657528, t_loss = 1.627099, and v_loss = 0.202000 at lr = 0.003230\n",
            "Trial 21 epoch 3 got t_acc = 0.222846, v_acc = 1.649618, t_loss = 1.624096, and v_loss = 0.202000 at lr = 0.003230\n",
            "Trial 21 epoch 4 got t_acc = 0.223596, v_acc = 1.642061, t_loss = 1.621282, and v_loss = 0.196000 at lr = 0.003230\n",
            "Trial 21 epoch 5 got t_acc = 0.225468, v_acc = 1.634843, t_loss = 1.618629, and v_loss = 0.196000 at lr = 0.003230\n",
            "Trial 21 epoch 6 got t_acc = 0.228839, v_acc = 1.627937, t_loss = 1.616130, and v_loss = 0.196000 at lr = 0.003230\n",
            "Trial 21 epoch 7 got t_acc = 0.234831, v_acc = 1.621321, t_loss = 1.613759, and v_loss = 0.194000 at lr = 0.003230\n",
            "Trial 21 epoch 8 got t_acc = 0.240449, v_acc = 1.614973, t_loss = 1.611524, and v_loss = 0.198000 at lr = 0.003230\n",
            "Trial 21 epoch 9 got t_acc = 0.242697, v_acc = 1.608863, t_loss = 1.609379, and v_loss = 0.198000 at lr = 0.003230\n",
            "Trial 22 epoch 0 got t_acc = 0.294382, v_acc = 1.548802, t_loss = 1.620408, and v_loss = 0.220000 at lr = 0.072962\n",
            "Trial 22 epoch 1 got t_acc = 0.363296, v_acc = 1.478075, t_loss = 1.603350, and v_loss = 0.232000 at lr = 0.072962\n",
            "Trial 22 epoch 2 got t_acc = 0.405618, v_acc = 1.428280, t_loss = 1.584302, and v_loss = 0.298000 at lr = 0.072962\n",
            "Trial 22 epoch 3 got t_acc = 0.436704, v_acc = 1.387540, t_loss = 1.571912, and v_loss = 0.326000 at lr = 0.072962\n",
            "Trial 22 epoch 4 got t_acc = 0.453933, v_acc = 1.352040, t_loss = 1.561184, and v_loss = 0.328000 at lr = 0.072962\n",
            "Trial 22 epoch 5 got t_acc = 0.474532, v_acc = 1.320708, t_loss = 1.552372, and v_loss = 0.330000 at lr = 0.072962\n",
            "Trial 22 epoch 6 got t_acc = 0.487640, v_acc = 1.292400, t_loss = 1.544818, and v_loss = 0.340000 at lr = 0.072962\n",
            "Trial 22 epoch 7 got t_acc = 0.497753, v_acc = 1.266603, t_loss = 1.538834, and v_loss = 0.342000 at lr = 0.072962\n",
            "Trial 22 epoch 8 got t_acc = 0.510861, v_acc = 1.242769, t_loss = 1.533254, and v_loss = 0.342000 at lr = 0.072962\n",
            "Trial 22 epoch 9 got t_acc = 0.523970, v_acc = 1.220531, t_loss = 1.528091, and v_loss = 0.336000 at lr = 0.072962\n",
            "Trial 23 epoch 0 got t_acc = 0.205243, v_acc = 1.733918, t_loss = 1.662281, and v_loss = 0.162000 at lr = 0.002449\n",
            "Trial 23 epoch 1 got t_acc = 0.204869, v_acc = 1.726038, t_loss = 1.659039, and v_loss = 0.170000 at lr = 0.002449\n",
            "Trial 23 epoch 2 got t_acc = 0.208989, v_acc = 1.718451, t_loss = 1.655999, and v_loss = 0.168000 at lr = 0.002449\n",
            "Trial 23 epoch 3 got t_acc = 0.210112, v_acc = 1.711155, t_loss = 1.653157, and v_loss = 0.168000 at lr = 0.002449\n",
            "Trial 23 epoch 4 got t_acc = 0.211236, v_acc = 1.704128, t_loss = 1.650494, and v_loss = 0.174000 at lr = 0.002449\n",
            "Trial 23 epoch 5 got t_acc = 0.214607, v_acc = 1.697340, t_loss = 1.647980, and v_loss = 0.174000 at lr = 0.002449\n",
            "Trial 23 epoch 6 got t_acc = 0.217228, v_acc = 1.690772, t_loss = 1.645597, and v_loss = 0.174000 at lr = 0.002449\n",
            "Trial 23 epoch 7 got t_acc = 0.218727, v_acc = 1.684410, t_loss = 1.643342, and v_loss = 0.178000 at lr = 0.002449\n",
            "Trial 23 epoch 8 got t_acc = 0.221723, v_acc = 1.678243, t_loss = 1.641199, and v_loss = 0.182000 at lr = 0.002449\n",
            "Trial 23 epoch 9 got t_acc = 0.222846, v_acc = 1.672252, t_loss = 1.639150, and v_loss = 0.186000 at lr = 0.002449\n",
            "Trial 24 epoch 0 got t_acc = 0.210861, v_acc = 1.648086, t_loss = 1.635348, and v_loss = 0.170000 at lr = 0.000151\n",
            "Trial 24 epoch 1 got t_acc = 0.211610, v_acc = 1.647779, t_loss = 1.635271, and v_loss = 0.170000 at lr = 0.000151\n",
            "Trial 24 epoch 2 got t_acc = 0.211985, v_acc = 1.647474, t_loss = 1.635194, and v_loss = 0.172000 at lr = 0.000151\n",
            "Trial 24 epoch 3 got t_acc = 0.211985, v_acc = 1.647169, t_loss = 1.635117, and v_loss = 0.170000 at lr = 0.000151\n",
            "Trial 24 epoch 4 got t_acc = 0.212360, v_acc = 1.646865, t_loss = 1.635039, and v_loss = 0.176000 at lr = 0.000151\n",
            "Trial 24 epoch 5 got t_acc = 0.212734, v_acc = 1.646562, t_loss = 1.634963, and v_loss = 0.174000 at lr = 0.000151\n",
            "Trial 24 epoch 6 got t_acc = 0.212360, v_acc = 1.646259, t_loss = 1.634886, and v_loss = 0.176000 at lr = 0.000151\n",
            "Trial 24 epoch 7 got t_acc = 0.212734, v_acc = 1.645956, t_loss = 1.634809, and v_loss = 0.176000 at lr = 0.000151\n",
            "Trial 24 epoch 8 got t_acc = 0.211985, v_acc = 1.645654, t_loss = 1.634733, and v_loss = 0.176000 at lr = 0.000151\n",
            "Trial 24 epoch 9 got t_acc = 0.212360, v_acc = 1.645353, t_loss = 1.634657, and v_loss = 0.176000 at lr = 0.000151\n",
            "Trial 25 epoch 0 got t_acc = 0.221348, v_acc = 1.643233, t_loss = 1.615665, and v_loss = 0.212000 at lr = 0.007180\n",
            "Trial 25 epoch 1 got t_acc = 0.230712, v_acc = 1.630059, t_loss = 1.612760, and v_loss = 0.212000 at lr = 0.007180\n",
            "Trial 25 epoch 2 got t_acc = 0.240075, v_acc = 1.617688, t_loss = 1.610040, and v_loss = 0.222000 at lr = 0.007180\n",
            "Trial 25 epoch 3 got t_acc = 0.250187, v_acc = 1.606109, t_loss = 1.607455, and v_loss = 0.220000 at lr = 0.007180\n",
            "Trial 25 epoch 4 got t_acc = 0.262921, v_acc = 1.595180, t_loss = 1.605018, and v_loss = 0.222000 at lr = 0.007180\n",
            "Trial 25 epoch 5 got t_acc = 0.270037, v_acc = 1.584771, t_loss = 1.602712, and v_loss = 0.234000 at lr = 0.007180\n",
            "Trial 25 epoch 6 got t_acc = 0.279026, v_acc = 1.574863, t_loss = 1.600476, and v_loss = 0.238000 at lr = 0.007180\n",
            "Trial 25 epoch 7 got t_acc = 0.286517, v_acc = 1.565366, t_loss = 1.598320, and v_loss = 0.242000 at lr = 0.007180\n",
            "Trial 25 epoch 8 got t_acc = 0.296255, v_acc = 1.556300, t_loss = 1.596232, and v_loss = 0.244000 at lr = 0.007180\n",
            "Trial 25 epoch 9 got t_acc = 0.304494, v_acc = 1.547591, t_loss = 1.594202, and v_loss = 0.254000 at lr = 0.007180\n",
            "Trial 26 epoch 0 got t_acc = 0.152434, v_acc = 1.725641, t_loss = 1.600340, and v_loss = 0.204000 at lr = 0.001256\n",
            "Trial 26 epoch 1 got t_acc = 0.152434, v_acc = 1.721706, t_loss = 1.599738, and v_loss = 0.208000 at lr = 0.001256\n",
            "Trial 26 epoch 2 got t_acc = 0.151685, v_acc = 1.717839, t_loss = 1.599148, and v_loss = 0.208000 at lr = 0.001256\n",
            "Trial 26 epoch 3 got t_acc = 0.155056, v_acc = 1.714032, t_loss = 1.598574, and v_loss = 0.208000 at lr = 0.001256\n",
            "Trial 26 epoch 4 got t_acc = 0.154307, v_acc = 1.710283, t_loss = 1.598009, and v_loss = 0.208000 at lr = 0.001256\n",
            "Trial 26 epoch 5 got t_acc = 0.155805, v_acc = 1.706596, t_loss = 1.597448, and v_loss = 0.214000 at lr = 0.001256\n",
            "Trial 26 epoch 6 got t_acc = 0.158801, v_acc = 1.702970, t_loss = 1.596899, and v_loss = 0.214000 at lr = 0.001256\n",
            "Trial 26 epoch 7 got t_acc = 0.159551, v_acc = 1.699404, t_loss = 1.596358, and v_loss = 0.216000 at lr = 0.001256\n",
            "Trial 26 epoch 8 got t_acc = 0.161049, v_acc = 1.695892, t_loss = 1.595822, and v_loss = 0.220000 at lr = 0.001256\n",
            "Trial 26 epoch 9 got t_acc = 0.162547, v_acc = 1.692428, t_loss = 1.595293, and v_loss = 0.220000 at lr = 0.001256\n",
            "Trial 27 epoch 0 got t_acc = 0.176404, v_acc = 1.703703, t_loss = 1.653461, and v_loss = 0.172000 at lr = 0.005834\n",
            "Trial 27 epoch 1 got t_acc = 0.184644, v_acc = 1.690099, t_loss = 1.647993, and v_loss = 0.176000 at lr = 0.005834\n",
            "Trial 27 epoch 2 got t_acc = 0.192884, v_acc = 1.677328, t_loss = 1.643037, and v_loss = 0.186000 at lr = 0.005834\n",
            "Trial 27 epoch 3 got t_acc = 0.202247, v_acc = 1.665257, t_loss = 1.638451, and v_loss = 0.190000 at lr = 0.005834\n",
            "Trial 27 epoch 4 got t_acc = 0.211236, v_acc = 1.653831, t_loss = 1.634180, and v_loss = 0.194000 at lr = 0.005834\n",
            "Trial 27 epoch 5 got t_acc = 0.217978, v_acc = 1.642964, t_loss = 1.630228, and v_loss = 0.192000 at lr = 0.005834\n",
            "Trial 27 epoch 6 got t_acc = 0.229213, v_acc = 1.632604, t_loss = 1.626504, and v_loss = 0.192000 at lr = 0.005834\n",
            "Trial 27 epoch 7 got t_acc = 0.237828, v_acc = 1.622749, t_loss = 1.623027, and v_loss = 0.192000 at lr = 0.005834\n",
            "Trial 27 epoch 8 got t_acc = 0.247940, v_acc = 1.613356, t_loss = 1.619765, and v_loss = 0.190000 at lr = 0.005834\n",
            "Trial 27 epoch 9 got t_acc = 0.259551, v_acc = 1.604368, t_loss = 1.616691, and v_loss = 0.186000 at lr = 0.005834\n",
            "Trial 28 epoch 0 got t_acc = 0.320974, v_acc = 1.541689, t_loss = 1.596117, and v_loss = 0.274000 at lr = 0.084133\n",
            "Trial 28 epoch 1 got t_acc = 0.382397, v_acc = 1.463818, t_loss = 1.572016, and v_loss = 0.324000 at lr = 0.084133\n",
            "Trial 28 epoch 2 got t_acc = 0.413109, v_acc = 1.404958, t_loss = 1.558733, and v_loss = 0.354000 at lr = 0.084133\n",
            "Trial 28 epoch 3 got t_acc = 0.450187, v_acc = 1.357438, t_loss = 1.545145, and v_loss = 0.362000 at lr = 0.084133\n",
            "Trial 28 epoch 4 got t_acc = 0.478652, v_acc = 1.317444, t_loss = 1.535704, and v_loss = 0.354000 at lr = 0.084133\n",
            "Trial 28 epoch 5 got t_acc = 0.492884, v_acc = 1.282612, t_loss = 1.526633, and v_loss = 0.362000 at lr = 0.084133\n",
            "Trial 28 epoch 6 got t_acc = 0.510487, v_acc = 1.251768, t_loss = 1.519918, and v_loss = 0.372000 at lr = 0.084133\n",
            "Trial 28 epoch 7 got t_acc = 0.525094, v_acc = 1.224031, t_loss = 1.513065, and v_loss = 0.366000 at lr = 0.084133\n",
            "Trial 28 epoch 8 got t_acc = 0.539326, v_acc = 1.198951, t_loss = 1.506707, and v_loss = 0.354000 at lr = 0.084133\n",
            "Trial 28 epoch 9 got t_acc = 0.549813, v_acc = 1.175930, t_loss = 1.501120, and v_loss = 0.352000 at lr = 0.084133\n",
            "Trial 29 epoch 0 got t_acc = 0.241199, v_acc = 1.630404, t_loss = 1.609984, and v_loss = 0.200000 at lr = 0.026250\n",
            "Trial 29 epoch 1 got t_acc = 0.284644, v_acc = 1.578536, t_loss = 1.594718, and v_loss = 0.232000 at lr = 0.026250\n",
            "Trial 29 epoch 2 got t_acc = 0.323596, v_acc = 1.540473, t_loss = 1.583703, and v_loss = 0.282000 at lr = 0.026250\n",
            "Trial 29 epoch 3 got t_acc = 0.353184, v_acc = 1.509803, t_loss = 1.575118, and v_loss = 0.300000 at lr = 0.026250\n",
            "Trial 29 epoch 4 got t_acc = 0.375281, v_acc = 1.483853, t_loss = 1.568284, and v_loss = 0.312000 at lr = 0.026250\n",
            "Trial 29 epoch 5 got t_acc = 0.393633, v_acc = 1.461032, t_loss = 1.562389, and v_loss = 0.320000 at lr = 0.026250\n",
            "Trial 29 epoch 6 got t_acc = 0.408989, v_acc = 1.440763, t_loss = 1.557251, and v_loss = 0.344000 at lr = 0.026250\n",
            "Trial 29 epoch 7 got t_acc = 0.417228, v_acc = 1.422314, t_loss = 1.552731, and v_loss = 0.346000 at lr = 0.026250\n",
            "Trial 29 epoch 8 got t_acc = 0.425094, v_acc = 1.405233, t_loss = 1.548764, and v_loss = 0.352000 at lr = 0.026250\n",
            "Trial 29 epoch 9 got t_acc = 0.434831, v_acc = 1.389236, t_loss = 1.545100, and v_loss = 0.346000 at lr = 0.026250\n",
            "Trial 30 epoch 0 got t_acc = 0.173408, v_acc = 1.736669, t_loss = 1.626873, and v_loss = 0.194000 at lr = 0.006210\n",
            "Trial 30 epoch 1 got t_acc = 0.180899, v_acc = 1.711194, t_loss = 1.620613, and v_loss = 0.206000 at lr = 0.006210\n",
            "Trial 30 epoch 2 got t_acc = 0.193258, v_acc = 1.689084, t_loss = 1.615611, and v_loss = 0.206000 at lr = 0.006210\n",
            "Trial 30 epoch 3 got t_acc = 0.200749, v_acc = 1.669564, t_loss = 1.611443, and v_loss = 0.212000 at lr = 0.006210\n",
            "Trial 30 epoch 4 got t_acc = 0.211985, v_acc = 1.652131, t_loss = 1.607906, and v_loss = 0.226000 at lr = 0.006210\n",
            "Trial 30 epoch 5 got t_acc = 0.226592, v_acc = 1.636408, t_loss = 1.604869, and v_loss = 0.232000 at lr = 0.006210\n",
            "Trial 30 epoch 6 got t_acc = 0.242697, v_acc = 1.622124, t_loss = 1.602153, and v_loss = 0.236000 at lr = 0.006210\n",
            "Trial 30 epoch 7 got t_acc = 0.249813, v_acc = 1.609022, t_loss = 1.599682, and v_loss = 0.240000 at lr = 0.006210\n",
            "Trial 30 epoch 8 got t_acc = 0.260674, v_acc = 1.596932, t_loss = 1.597421, and v_loss = 0.254000 at lr = 0.006210\n",
            "Trial 30 epoch 9 got t_acc = 0.267790, v_acc = 1.585697, t_loss = 1.595313, and v_loss = 0.258000 at lr = 0.006210\n",
            "Trial 31 epoch 0 got t_acc = 0.207865, v_acc = 1.721611, t_loss = 1.631751, and v_loss = 0.182000 at lr = 0.000418\n",
            "Trial 31 epoch 1 got t_acc = 0.207865, v_acc = 1.720035, t_loss = 1.631459, and v_loss = 0.182000 at lr = 0.000418\n",
            "Trial 31 epoch 2 got t_acc = 0.208240, v_acc = 1.718471, t_loss = 1.631168, and v_loss = 0.182000 at lr = 0.000418\n",
            "Trial 31 epoch 3 got t_acc = 0.208614, v_acc = 1.716915, t_loss = 1.630878, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 4 got t_acc = 0.208989, v_acc = 1.715373, t_loss = 1.630590, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 5 got t_acc = 0.209363, v_acc = 1.713842, t_loss = 1.630304, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 6 got t_acc = 0.209363, v_acc = 1.712325, t_loss = 1.630019, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 7 got t_acc = 0.209738, v_acc = 1.710820, t_loss = 1.629737, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 8 got t_acc = 0.210112, v_acc = 1.709326, t_loss = 1.629457, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 31 epoch 9 got t_acc = 0.209738, v_acc = 1.707844, t_loss = 1.629178, and v_loss = 0.184000 at lr = 0.000418\n",
            "Trial 32 epoch 0 got t_acc = 0.233708, v_acc = 1.709358, t_loss = 1.617585, and v_loss = 0.246000 at lr = 0.006169\n",
            "Trial 32 epoch 1 got t_acc = 0.235581, v_acc = 1.692336, t_loss = 1.614285, and v_loss = 0.248000 at lr = 0.006169\n",
            "Trial 32 epoch 2 got t_acc = 0.239700, v_acc = 1.676729, t_loss = 1.611429, and v_loss = 0.242000 at lr = 0.006169\n",
            "Trial 32 epoch 3 got t_acc = 0.241573, v_acc = 1.662295, t_loss = 1.608892, and v_loss = 0.240000 at lr = 0.006169\n",
            "Trial 32 epoch 4 got t_acc = 0.245318, v_acc = 1.648870, t_loss = 1.606565, and v_loss = 0.238000 at lr = 0.006169\n",
            "Trial 32 epoch 5 got t_acc = 0.249438, v_acc = 1.636294, t_loss = 1.604424, and v_loss = 0.240000 at lr = 0.006169\n",
            "Trial 32 epoch 6 got t_acc = 0.255431, v_acc = 1.624465, t_loss = 1.602457, and v_loss = 0.242000 at lr = 0.006169\n",
            "Trial 32 epoch 7 got t_acc = 0.261423, v_acc = 1.613307, t_loss = 1.600596, and v_loss = 0.242000 at lr = 0.006169\n",
            "Trial 32 epoch 8 got t_acc = 0.265918, v_acc = 1.602756, t_loss = 1.598838, and v_loss = 0.248000 at lr = 0.006169\n",
            "Trial 32 epoch 9 got t_acc = 0.272659, v_acc = 1.592710, t_loss = 1.597141, and v_loss = 0.244000 at lr = 0.006169\n",
            "Trial 33 epoch 0 got t_acc = 0.208614, v_acc = 1.674440, t_loss = 1.622157, and v_loss = 0.182000 at lr = 0.007243\n",
            "Trial 33 epoch 1 got t_acc = 0.214232, v_acc = 1.651681, t_loss = 1.613378, and v_loss = 0.186000 at lr = 0.007243\n",
            "Trial 33 epoch 2 got t_acc = 0.227715, v_acc = 1.632050, t_loss = 1.606226, and v_loss = 0.212000 at lr = 0.007243\n",
            "Trial 33 epoch 3 got t_acc = 0.240449, v_acc = 1.614839, t_loss = 1.600297, and v_loss = 0.230000 at lr = 0.007243\n",
            "Trial 33 epoch 4 got t_acc = 0.253933, v_acc = 1.599545, t_loss = 1.595265, and v_loss = 0.242000 at lr = 0.007243\n",
            "Trial 33 epoch 5 got t_acc = 0.265918, v_acc = 1.585780, t_loss = 1.590934, and v_loss = 0.238000 at lr = 0.007243\n",
            "Trial 33 epoch 6 got t_acc = 0.275655, v_acc = 1.573243, t_loss = 1.587151, and v_loss = 0.244000 at lr = 0.007243\n",
            "Trial 33 epoch 7 got t_acc = 0.286517, v_acc = 1.561716, t_loss = 1.583802, and v_loss = 0.266000 at lr = 0.007243\n",
            "Trial 33 epoch 8 got t_acc = 0.300375, v_acc = 1.551059, t_loss = 1.580803, and v_loss = 0.276000 at lr = 0.007243\n",
            "Trial 33 epoch 9 got t_acc = 0.305993, v_acc = 1.541155, t_loss = 1.578076, and v_loss = 0.286000 at lr = 0.007243\n",
            "Trial 34 epoch 0 got t_acc = 0.145318, v_acc = 1.815150, t_loss = 1.650143, and v_loss = 0.182000 at lr = 0.000593\n",
            "Trial 34 epoch 1 got t_acc = 0.146067, v_acc = 1.812165, t_loss = 1.649009, and v_loss = 0.180000 at lr = 0.000593\n",
            "Trial 34 epoch 2 got t_acc = 0.146442, v_acc = 1.809220, t_loss = 1.647899, and v_loss = 0.178000 at lr = 0.000593\n",
            "Trial 34 epoch 3 got t_acc = 0.146816, v_acc = 1.806311, t_loss = 1.646808, and v_loss = 0.178000 at lr = 0.000593\n",
            "Trial 34 epoch 4 got t_acc = 0.147191, v_acc = 1.803437, t_loss = 1.645737, and v_loss = 0.178000 at lr = 0.000593\n",
            "Trial 34 epoch 5 got t_acc = 0.147191, v_acc = 1.800600, t_loss = 1.644688, and v_loss = 0.182000 at lr = 0.000593\n",
            "Trial 34 epoch 6 got t_acc = 0.148689, v_acc = 1.797799, t_loss = 1.643660, and v_loss = 0.182000 at lr = 0.000593\n",
            "Trial 34 epoch 7 got t_acc = 0.149438, v_acc = 1.795030, t_loss = 1.642653, and v_loss = 0.182000 at lr = 0.000593\n",
            "Trial 34 epoch 8 got t_acc = 0.150562, v_acc = 1.792296, t_loss = 1.641665, and v_loss = 0.184000 at lr = 0.000593\n",
            "Trial 34 epoch 9 got t_acc = 0.150187, v_acc = 1.789595, t_loss = 1.640695, and v_loss = 0.184000 at lr = 0.000593\n",
            "Trial 35 epoch 0 got t_acc = 0.227341, v_acc = 1.634726, t_loss = 1.604627, and v_loss = 0.224000 at lr = 0.012980\n",
            "Trial 35 epoch 1 got t_acc = 0.239700, v_acc = 1.612876, t_loss = 1.599182, and v_loss = 0.234000 at lr = 0.012980\n",
            "Trial 35 epoch 2 got t_acc = 0.256554, v_acc = 1.593914, t_loss = 1.594625, and v_loss = 0.256000 at lr = 0.012980\n",
            "Trial 35 epoch 3 got t_acc = 0.275655, v_acc = 1.577118, t_loss = 1.590793, and v_loss = 0.278000 at lr = 0.012980\n",
            "Trial 35 epoch 4 got t_acc = 0.285393, v_acc = 1.561960, t_loss = 1.587483, and v_loss = 0.282000 at lr = 0.012980\n",
            "Trial 35 epoch 5 got t_acc = 0.302247, v_acc = 1.548059, t_loss = 1.584528, and v_loss = 0.280000 at lr = 0.012980\n",
            "Trial 35 epoch 6 got t_acc = 0.312734, v_acc = 1.535195, t_loss = 1.581856, and v_loss = 0.300000 at lr = 0.012980\n",
            "Trial 35 epoch 7 got t_acc = 0.320974, v_acc = 1.523181, t_loss = 1.579378, and v_loss = 0.308000 at lr = 0.012980\n",
            "Trial 35 epoch 8 got t_acc = 0.329963, v_acc = 1.511861, t_loss = 1.577027, and v_loss = 0.316000 at lr = 0.012980\n",
            "Trial 35 epoch 9 got t_acc = 0.339326, v_acc = 1.501120, t_loss = 1.574779, and v_loss = 0.322000 at lr = 0.012980\n",
            "Trial 36 epoch 0 got t_acc = 0.297378, v_acc = 1.561429, t_loss = 1.588246, and v_loss = 0.264000 at lr = 0.064654\n",
            "Trial 36 epoch 1 got t_acc = 0.371910, v_acc = 1.482387, t_loss = 1.573601, and v_loss = 0.302000 at lr = 0.064654\n",
            "Trial 36 epoch 2 got t_acc = 0.410487, v_acc = 1.425884, t_loss = 1.559261, and v_loss = 0.334000 at lr = 0.064654\n",
            "Trial 36 epoch 3 got t_acc = 0.442697, v_acc = 1.380905, t_loss = 1.546810, and v_loss = 0.344000 at lr = 0.064654\n",
            "Trial 36 epoch 4 got t_acc = 0.462547, v_acc = 1.343159, t_loss = 1.535958, and v_loss = 0.354000 at lr = 0.064654\n",
            "Trial 36 epoch 5 got t_acc = 0.475281, v_acc = 1.310767, t_loss = 1.526113, and v_loss = 0.358000 at lr = 0.064654\n",
            "Trial 36 epoch 6 got t_acc = 0.493258, v_acc = 1.282567, t_loss = 1.518115, and v_loss = 0.366000 at lr = 0.064654\n",
            "Trial 36 epoch 7 got t_acc = 0.510112, v_acc = 1.257340, t_loss = 1.511260, and v_loss = 0.368000 at lr = 0.064654\n",
            "Trial 36 epoch 8 got t_acc = 0.519101, v_acc = 1.234611, t_loss = 1.505142, and v_loss = 0.366000 at lr = 0.064654\n",
            "Trial 36 epoch 9 got t_acc = 0.528839, v_acc = 1.213908, t_loss = 1.499975, and v_loss = 0.362000 at lr = 0.064654\n",
            "Trial 37 epoch 0 got t_acc = 0.222472, v_acc = 1.711864, t_loss = 1.641176, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 1 got t_acc = 0.222472, v_acc = 1.711123, t_loss = 1.640736, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 2 got t_acc = 0.222846, v_acc = 1.710385, t_loss = 1.640298, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 3 got t_acc = 0.222846, v_acc = 1.709650, t_loss = 1.639864, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 4 got t_acc = 0.222846, v_acc = 1.708918, t_loss = 1.639433, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 5 got t_acc = 0.223221, v_acc = 1.708189, t_loss = 1.639005, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 6 got t_acc = 0.223596, v_acc = 1.707462, t_loss = 1.638580, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 7 got t_acc = 0.223596, v_acc = 1.706738, t_loss = 1.638158, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 8 got t_acc = 0.223970, v_acc = 1.706017, t_loss = 1.637737, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 37 epoch 9 got t_acc = 0.224345, v_acc = 1.705298, t_loss = 1.637319, and v_loss = 0.274000 at lr = 0.000279\n",
            "Trial 38 epoch 0 got t_acc = 0.240449, v_acc = 1.732455, t_loss = 1.618676, and v_loss = 0.260000 at lr = 0.000812\n",
            "Trial 38 epoch 1 got t_acc = 0.240449, v_acc = 1.729295, t_loss = 1.617728, and v_loss = 0.260000 at lr = 0.000812\n",
            "Trial 38 epoch 2 got t_acc = 0.240824, v_acc = 1.726205, t_loss = 1.616818, and v_loss = 0.260000 at lr = 0.000812\n",
            "Trial 38 epoch 3 got t_acc = 0.240824, v_acc = 1.723179, t_loss = 1.615943, and v_loss = 0.262000 at lr = 0.000812\n",
            "Trial 38 epoch 4 got t_acc = 0.241199, v_acc = 1.720222, t_loss = 1.615102, and v_loss = 0.260000 at lr = 0.000812\n",
            "Trial 38 epoch 5 got t_acc = 0.241199, v_acc = 1.717330, t_loss = 1.614288, and v_loss = 0.260000 at lr = 0.000812\n",
            "Trial 38 epoch 6 got t_acc = 0.241573, v_acc = 1.714507, t_loss = 1.613503, and v_loss = 0.262000 at lr = 0.000812\n",
            "Trial 38 epoch 7 got t_acc = 0.241948, v_acc = 1.711740, t_loss = 1.612747, and v_loss = 0.268000 at lr = 0.000812\n",
            "Trial 38 epoch 8 got t_acc = 0.242697, v_acc = 1.709030, t_loss = 1.612019, and v_loss = 0.266000 at lr = 0.000812\n",
            "Trial 38 epoch 9 got t_acc = 0.243446, v_acc = 1.706377, t_loss = 1.611318, and v_loss = 0.268000 at lr = 0.000812\n",
            "Trial 39 epoch 0 got t_acc = 0.218352, v_acc = 1.638462, t_loss = 1.638131, and v_loss = 0.154000 at lr = 0.018628\n",
            "Trial 39 epoch 1 got t_acc = 0.250936, v_acc = 1.597208, t_loss = 1.619905, and v_loss = 0.184000 at lr = 0.018628\n",
            "Trial 39 epoch 2 got t_acc = 0.280524, v_acc = 1.564796, t_loss = 1.608049, and v_loss = 0.200000 at lr = 0.018628\n",
            "Trial 39 epoch 3 got t_acc = 0.309363, v_acc = 1.538055, t_loss = 1.598998, and v_loss = 0.270000 at lr = 0.018628\n",
            "Trial 39 epoch 4 got t_acc = 0.331461, v_acc = 1.515164, t_loss = 1.591466, and v_loss = 0.284000 at lr = 0.018628\n",
            "Trial 39 epoch 5 got t_acc = 0.349438, v_acc = 1.495088, t_loss = 1.585083, and v_loss = 0.294000 at lr = 0.018628\n",
            "Trial 39 epoch 6 got t_acc = 0.362547, v_acc = 1.477162, t_loss = 1.579542, and v_loss = 0.298000 at lr = 0.018628\n",
            "Trial 39 epoch 7 got t_acc = 0.374906, v_acc = 1.460828, t_loss = 1.574594, and v_loss = 0.312000 at lr = 0.018628\n",
            "Trial 39 epoch 8 got t_acc = 0.384644, v_acc = 1.445795, t_loss = 1.570177, and v_loss = 0.314000 at lr = 0.018628\n",
            "Trial 39 epoch 9 got t_acc = 0.393633, v_acc = 1.431885, t_loss = 1.566200, and v_loss = 0.320000 at lr = 0.018628\n",
            "Trial 40 epoch 0 got t_acc = 0.216105, v_acc = 1.661881, t_loss = 1.620202, and v_loss = 0.188000 at lr = 0.017924\n",
            "Trial 40 epoch 1 got t_acc = 0.243820, v_acc = 1.626241, t_loss = 1.611731, and v_loss = 0.188000 at lr = 0.017924\n",
            "Trial 40 epoch 2 got t_acc = 0.270787, v_acc = 1.595903, t_loss = 1.604054, and v_loss = 0.196000 at lr = 0.017924\n",
            "Trial 40 epoch 3 got t_acc = 0.295131, v_acc = 1.569591, t_loss = 1.597059, and v_loss = 0.232000 at lr = 0.017924\n",
            "Trial 40 epoch 4 got t_acc = 0.313109, v_acc = 1.546177, t_loss = 1.590694, and v_loss = 0.252000 at lr = 0.017924\n",
            "Trial 40 epoch 5 got t_acc = 0.329213, v_acc = 1.525017, t_loss = 1.584833, and v_loss = 0.282000 at lr = 0.017924\n",
            "Trial 40 epoch 6 got t_acc = 0.340075, v_acc = 1.505709, t_loss = 1.579425, and v_loss = 0.304000 at lr = 0.017924\n",
            "Trial 40 epoch 7 got t_acc = 0.356929, v_acc = 1.487979, t_loss = 1.574384, and v_loss = 0.326000 at lr = 0.017924\n",
            "Trial 40 epoch 8 got t_acc = 0.368914, v_acc = 1.471724, t_loss = 1.569774, and v_loss = 0.334000 at lr = 0.017924\n",
            "Trial 40 epoch 9 got t_acc = 0.379026, v_acc = 1.456690, t_loss = 1.565497, and v_loss = 0.342000 at lr = 0.017924\n",
            "Trial 41 epoch 0 got t_acc = 0.183895, v_acc = 1.748522, t_loss = 1.691767, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 1 got t_acc = 0.183895, v_acc = 1.748133, t_loss = 1.691484, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 2 got t_acc = 0.184270, v_acc = 1.747745, t_loss = 1.691201, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 3 got t_acc = 0.184270, v_acc = 1.747358, t_loss = 1.690920, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 4 got t_acc = 0.184270, v_acc = 1.746971, t_loss = 1.690639, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 5 got t_acc = 0.184270, v_acc = 1.746585, t_loss = 1.690359, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 6 got t_acc = 0.184270, v_acc = 1.746200, t_loss = 1.690079, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 7 got t_acc = 0.184270, v_acc = 1.745816, t_loss = 1.689801, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 8 got t_acc = 0.184644, v_acc = 1.745432, t_loss = 1.689523, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 41 epoch 9 got t_acc = 0.184644, v_acc = 1.745049, t_loss = 1.689246, and v_loss = 0.188000 at lr = 0.000120\n",
            "Trial 42 epoch 0 got t_acc = 0.267416, v_acc = 1.669565, t_loss = 1.613623, and v_loss = 0.236000 at lr = 0.000105\n",
            "Trial 42 epoch 1 got t_acc = 0.267416, v_acc = 1.669286, t_loss = 1.613543, and v_loss = 0.236000 at lr = 0.000105\n",
            "Trial 42 epoch 2 got t_acc = 0.267790, v_acc = 1.669008, t_loss = 1.613465, and v_loss = 0.236000 at lr = 0.000105\n",
            "Trial 42 epoch 3 got t_acc = 0.268914, v_acc = 1.668730, t_loss = 1.613386, and v_loss = 0.236000 at lr = 0.000105\n",
            "Trial 42 epoch 4 got t_acc = 0.268914, v_acc = 1.668452, t_loss = 1.613307, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 42 epoch 5 got t_acc = 0.269288, v_acc = 1.668175, t_loss = 1.613229, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 42 epoch 6 got t_acc = 0.269663, v_acc = 1.667898, t_loss = 1.613151, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 42 epoch 7 got t_acc = 0.269663, v_acc = 1.667622, t_loss = 1.613073, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 42 epoch 8 got t_acc = 0.269663, v_acc = 1.667346, t_loss = 1.612996, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 42 epoch 9 got t_acc = 0.269663, v_acc = 1.667070, t_loss = 1.612918, and v_loss = 0.238000 at lr = 0.000105\n",
            "Trial 43 epoch 0 got t_acc = 0.242697, v_acc = 1.611717, t_loss = 1.614967, and v_loss = 0.176000 at lr = 0.035131\n",
            "Trial 43 epoch 1 got t_acc = 0.305243, v_acc = 1.547569, t_loss = 1.601216, and v_loss = 0.230000 at lr = 0.035131\n",
            "Trial 43 epoch 2 got t_acc = 0.348315, v_acc = 1.502196, t_loss = 1.592178, and v_loss = 0.216000 at lr = 0.035131\n",
            "Trial 43 epoch 3 got t_acc = 0.373034, v_acc = 1.466667, t_loss = 1.584745, and v_loss = 0.216000 at lr = 0.035131\n",
            "Trial 43 epoch 4 got t_acc = 0.391760, v_acc = 1.436904, t_loss = 1.578068, and v_loss = 0.230000 at lr = 0.035131\n",
            "Trial 43 epoch 5 got t_acc = 0.413858, v_acc = 1.411253, t_loss = 1.572255, and v_loss = 0.244000 at lr = 0.035131\n",
            "Trial 43 epoch 6 got t_acc = 0.429963, v_acc = 1.388659, t_loss = 1.567111, and v_loss = 0.252000 at lr = 0.035131\n",
            "Trial 43 epoch 7 got t_acc = 0.443820, v_acc = 1.368207, t_loss = 1.562575, and v_loss = 0.262000 at lr = 0.035131\n",
            "Trial 43 epoch 8 got t_acc = 0.456929, v_acc = 1.349480, t_loss = 1.558464, and v_loss = 0.262000 at lr = 0.035131\n",
            "Trial 43 epoch 9 got t_acc = 0.467790, v_acc = 1.332102, t_loss = 1.554893, and v_loss = 0.262000 at lr = 0.035131\n",
            "Trial 44 epoch 0 got t_acc = 0.205618, v_acc = 1.689739, t_loss = 1.615960, and v_loss = 0.200000 at lr = 0.000206\n",
            "Trial 44 epoch 1 got t_acc = 0.206367, v_acc = 1.689224, t_loss = 1.615841, and v_loss = 0.200000 at lr = 0.000206\n",
            "Trial 44 epoch 2 got t_acc = 0.207116, v_acc = 1.688711, t_loss = 1.615721, and v_loss = 0.202000 at lr = 0.000206\n",
            "Trial 44 epoch 3 got t_acc = 0.207116, v_acc = 1.688198, t_loss = 1.615602, and v_loss = 0.202000 at lr = 0.000206\n",
            "Trial 44 epoch 4 got t_acc = 0.207491, v_acc = 1.687688, t_loss = 1.615484, and v_loss = 0.200000 at lr = 0.000206\n",
            "Trial 44 epoch 5 got t_acc = 0.207865, v_acc = 1.687178, t_loss = 1.615367, and v_loss = 0.200000 at lr = 0.000206\n",
            "Trial 44 epoch 6 got t_acc = 0.208240, v_acc = 1.686671, t_loss = 1.615250, and v_loss = 0.200000 at lr = 0.000206\n",
            "Trial 44 epoch 7 got t_acc = 0.207491, v_acc = 1.686164, t_loss = 1.615133, and v_loss = 0.196000 at lr = 0.000206\n",
            "Trial 44 epoch 8 got t_acc = 0.207865, v_acc = 1.685659, t_loss = 1.615017, and v_loss = 0.196000 at lr = 0.000206\n",
            "Trial 44 epoch 9 got t_acc = 0.207865, v_acc = 1.685155, t_loss = 1.614901, and v_loss = 0.196000 at lr = 0.000206\n",
            "Trial 45 epoch 0 got t_acc = 0.210487, v_acc = 1.672620, t_loss = 1.619303, and v_loss = 0.214000 at lr = 0.001099\n",
            "Trial 45 epoch 1 got t_acc = 0.210112, v_acc = 1.669511, t_loss = 1.618306, and v_loss = 0.214000 at lr = 0.001099\n",
            "Trial 45 epoch 2 got t_acc = 0.210861, v_acc = 1.666446, t_loss = 1.617326, and v_loss = 0.212000 at lr = 0.001099\n",
            "Trial 45 epoch 3 got t_acc = 0.212360, v_acc = 1.663429, t_loss = 1.616366, and v_loss = 0.212000 at lr = 0.001099\n",
            "Trial 45 epoch 4 got t_acc = 0.214607, v_acc = 1.660455, t_loss = 1.615427, and v_loss = 0.212000 at lr = 0.001099\n",
            "Trial 45 epoch 5 got t_acc = 0.215730, v_acc = 1.657527, t_loss = 1.614506, and v_loss = 0.210000 at lr = 0.001099\n",
            "Trial 45 epoch 6 got t_acc = 0.216479, v_acc = 1.654647, t_loss = 1.613605, and v_loss = 0.210000 at lr = 0.001099\n",
            "Trial 45 epoch 7 got t_acc = 0.216105, v_acc = 1.651818, t_loss = 1.612727, and v_loss = 0.206000 at lr = 0.001099\n",
            "Trial 45 epoch 8 got t_acc = 0.215356, v_acc = 1.649030, t_loss = 1.611867, and v_loss = 0.206000 at lr = 0.001099\n",
            "Trial 45 epoch 9 got t_acc = 0.216105, v_acc = 1.646283, t_loss = 1.611021, and v_loss = 0.206000 at lr = 0.001099\n",
            "Trial 46 epoch 0 got t_acc = 0.329213, v_acc = 1.524422, t_loss = 1.599737, and v_loss = 0.206000 at lr = 0.080457\n",
            "Trial 46 epoch 1 got t_acc = 0.402247, v_acc = 1.446581, t_loss = 1.575385, and v_loss = 0.280000 at lr = 0.080457\n",
            "Trial 46 epoch 2 got t_acc = 0.429213, v_acc = 1.389731, t_loss = 1.559400, and v_loss = 0.302000 at lr = 0.080457\n",
            "Trial 46 epoch 3 got t_acc = 0.452809, v_acc = 1.344224, t_loss = 1.547021, and v_loss = 0.318000 at lr = 0.080457\n",
            "Trial 46 epoch 4 got t_acc = 0.474906, v_acc = 1.306183, t_loss = 1.537825, and v_loss = 0.314000 at lr = 0.080457\n",
            "Trial 46 epoch 5 got t_acc = 0.495506, v_acc = 1.273645, t_loss = 1.529925, and v_loss = 0.320000 at lr = 0.080457\n",
            "Trial 46 epoch 6 got t_acc = 0.511610, v_acc = 1.244777, t_loss = 1.523872, and v_loss = 0.332000 at lr = 0.080457\n",
            "Trial 46 epoch 7 got t_acc = 0.524719, v_acc = 1.219087, t_loss = 1.518679, and v_loss = 0.328000 at lr = 0.080457\n",
            "Trial 46 epoch 8 got t_acc = 0.539700, v_acc = 1.195778, t_loss = 1.513962, and v_loss = 0.326000 at lr = 0.080457\n",
            "Trial 46 epoch 9 got t_acc = 0.553184, v_acc = 1.174391, t_loss = 1.509799, and v_loss = 0.320000 at lr = 0.080457\n",
            "Trial 47 epoch 0 got t_acc = 0.233333, v_acc = 1.629074, t_loss = 1.600979, and v_loss = 0.274000 at lr = 0.018219\n",
            "Trial 47 epoch 1 got t_acc = 0.253184, v_acc = 1.601594, t_loss = 1.597294, and v_loss = 0.278000 at lr = 0.018219\n",
            "Trial 47 epoch 2 got t_acc = 0.276404, v_acc = 1.577422, t_loss = 1.593874, and v_loss = 0.272000 at lr = 0.018219\n",
            "Trial 47 epoch 3 got t_acc = 0.298127, v_acc = 1.555745, t_loss = 1.590452, and v_loss = 0.276000 at lr = 0.018219\n",
            "Trial 47 epoch 4 got t_acc = 0.317228, v_acc = 1.536018, t_loss = 1.586958, and v_loss = 0.294000 at lr = 0.018219\n",
            "Trial 47 epoch 5 got t_acc = 0.329588, v_acc = 1.517834, t_loss = 1.583478, and v_loss = 0.288000 at lr = 0.018219\n",
            "Trial 47 epoch 6 got t_acc = 0.346442, v_acc = 1.500862, t_loss = 1.580058, and v_loss = 0.292000 at lr = 0.018219\n",
            "Trial 47 epoch 7 got t_acc = 0.363296, v_acc = 1.485043, t_loss = 1.576712, and v_loss = 0.300000 at lr = 0.018219\n",
            "Trial 47 epoch 8 got t_acc = 0.377528, v_acc = 1.470162, t_loss = 1.573434, and v_loss = 0.306000 at lr = 0.018219\n",
            "Trial 47 epoch 9 got t_acc = 0.388015, v_acc = 1.456110, t_loss = 1.570287, and v_loss = 0.310000 at lr = 0.018219\n",
            "Trial 48 epoch 0 got t_acc = 0.208989, v_acc = 1.714439, t_loss = 1.623991, and v_loss = 0.242000 at lr = 0.001114\n",
            "Trial 48 epoch 1 got t_acc = 0.210861, v_acc = 1.711576, t_loss = 1.623467, and v_loss = 0.240000 at lr = 0.001114\n",
            "Trial 48 epoch 2 got t_acc = 0.211610, v_acc = 1.708759, t_loss = 1.622952, and v_loss = 0.242000 at lr = 0.001114\n",
            "Trial 48 epoch 3 got t_acc = 0.213483, v_acc = 1.705983, t_loss = 1.622441, and v_loss = 0.242000 at lr = 0.001114\n",
            "Trial 48 epoch 4 got t_acc = 0.213483, v_acc = 1.703241, t_loss = 1.621934, and v_loss = 0.242000 at lr = 0.001114\n",
            "Trial 48 epoch 5 got t_acc = 0.215356, v_acc = 1.700541, t_loss = 1.621432, and v_loss = 0.244000 at lr = 0.001114\n",
            "Trial 48 epoch 6 got t_acc = 0.217978, v_acc = 1.697884, t_loss = 1.620936, and v_loss = 0.244000 at lr = 0.001114\n",
            "Trial 48 epoch 7 got t_acc = 0.219101, v_acc = 1.695267, t_loss = 1.620443, and v_loss = 0.244000 at lr = 0.001114\n",
            "Trial 48 epoch 8 got t_acc = 0.221348, v_acc = 1.692682, t_loss = 1.619951, and v_loss = 0.244000 at lr = 0.001114\n",
            "Trial 48 epoch 9 got t_acc = 0.221723, v_acc = 1.690125, t_loss = 1.619460, and v_loss = 0.242000 at lr = 0.001114\n",
            "Trial 49 epoch 0 got t_acc = 0.238577, v_acc = 1.769238, t_loss = 1.614671, and v_loss = 0.260000 at lr = 0.000288\n",
            "Trial 49 epoch 1 got t_acc = 0.238951, v_acc = 1.767976, t_loss = 1.614380, and v_loss = 0.260000 at lr = 0.000288\n",
            "Trial 49 epoch 2 got t_acc = 0.238577, v_acc = 1.766722, t_loss = 1.614092, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 3 got t_acc = 0.238577, v_acc = 1.765476, t_loss = 1.613809, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 4 got t_acc = 0.238951, v_acc = 1.764240, t_loss = 1.613530, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 5 got t_acc = 0.238577, v_acc = 1.763011, t_loss = 1.613255, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 6 got t_acc = 0.238577, v_acc = 1.761792, t_loss = 1.612983, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 7 got t_acc = 0.238577, v_acc = 1.760580, t_loss = 1.612714, and v_loss = 0.258000 at lr = 0.000288\n",
            "Trial 49 epoch 8 got t_acc = 0.238951, v_acc = 1.759375, t_loss = 1.612450, and v_loss = 0.260000 at lr = 0.000288\n",
            "Trial 49 epoch 9 got t_acc = 0.238951, v_acc = 1.758179, t_loss = 1.612188, and v_loss = 0.260000 at lr = 0.000288\n",
            "Trial 50 epoch 0 got t_acc = 0.234831, v_acc = 1.722730, t_loss = 1.608676, and v_loss = 0.270000 at lr = 0.001393\n",
            "Trial 50 epoch 1 got t_acc = 0.236704, v_acc = 1.718136, t_loss = 1.607669, and v_loss = 0.268000 at lr = 0.001393\n",
            "Trial 50 epoch 2 got t_acc = 0.238577, v_acc = 1.713654, t_loss = 1.606715, and v_loss = 0.268000 at lr = 0.001393\n",
            "Trial 50 epoch 3 got t_acc = 0.238577, v_acc = 1.709272, t_loss = 1.605801, and v_loss = 0.268000 at lr = 0.001393\n",
            "Trial 50 epoch 4 got t_acc = 0.239700, v_acc = 1.704992, t_loss = 1.604924, and v_loss = 0.270000 at lr = 0.001393\n",
            "Trial 50 epoch 5 got t_acc = 0.241199, v_acc = 1.700818, t_loss = 1.604084, and v_loss = 0.268000 at lr = 0.001393\n",
            "Trial 50 epoch 6 got t_acc = 0.240449, v_acc = 1.696743, t_loss = 1.603286, and v_loss = 0.270000 at lr = 0.001393\n",
            "Trial 50 epoch 7 got t_acc = 0.241199, v_acc = 1.692746, t_loss = 1.602520, and v_loss = 0.270000 at lr = 0.001393\n",
            "Trial 50 epoch 8 got t_acc = 0.240449, v_acc = 1.688830, t_loss = 1.601788, and v_loss = 0.272000 at lr = 0.001393\n",
            "Trial 50 epoch 9 got t_acc = 0.241948, v_acc = 1.685002, t_loss = 1.601088, and v_loss = 0.276000 at lr = 0.001393\n",
            "Trial 51 epoch 0 got t_acc = 0.189888, v_acc = 1.668913, t_loss = 1.639082, and v_loss = 0.176000 at lr = 0.002899\n",
            "Trial 51 epoch 1 got t_acc = 0.193258, v_acc = 1.661448, t_loss = 1.635611, and v_loss = 0.180000 at lr = 0.002899\n",
            "Trial 51 epoch 2 got t_acc = 0.199625, v_acc = 1.654300, t_loss = 1.632339, and v_loss = 0.182000 at lr = 0.002899\n",
            "Trial 51 epoch 3 got t_acc = 0.205243, v_acc = 1.647437, t_loss = 1.629229, and v_loss = 0.192000 at lr = 0.002899\n",
            "Trial 51 epoch 4 got t_acc = 0.210487, v_acc = 1.640842, t_loss = 1.626284, and v_loss = 0.200000 at lr = 0.002899\n",
            "Trial 51 epoch 5 got t_acc = 0.216105, v_acc = 1.634514, t_loss = 1.623491, and v_loss = 0.200000 at lr = 0.002899\n",
            "Trial 51 epoch 6 got t_acc = 0.219476, v_acc = 1.628430, t_loss = 1.620842, and v_loss = 0.214000 at lr = 0.002899\n",
            "Trial 51 epoch 7 got t_acc = 0.223970, v_acc = 1.622571, t_loss = 1.618353, and v_loss = 0.214000 at lr = 0.002899\n",
            "Trial 51 epoch 8 got t_acc = 0.232584, v_acc = 1.616913, t_loss = 1.615984, and v_loss = 0.212000 at lr = 0.002899\n",
            "Trial 51 epoch 9 got t_acc = 0.237828, v_acc = 1.611441, t_loss = 1.613713, and v_loss = 0.218000 at lr = 0.002899\n",
            "Trial 52 epoch 0 got t_acc = 0.203371, v_acc = 1.662706, t_loss = 1.620841, and v_loss = 0.214000 at lr = 0.007305\n",
            "Trial 52 epoch 1 got t_acc = 0.213109, v_acc = 1.642966, t_loss = 1.615543, and v_loss = 0.214000 at lr = 0.007305\n",
            "Trial 52 epoch 2 got t_acc = 0.223221, v_acc = 1.625685, t_loss = 1.610966, and v_loss = 0.226000 at lr = 0.007305\n",
            "Trial 52 epoch 3 got t_acc = 0.238951, v_acc = 1.610384, t_loss = 1.606976, and v_loss = 0.226000 at lr = 0.007305\n",
            "Trial 52 epoch 4 got t_acc = 0.253184, v_acc = 1.596645, t_loss = 1.603478, and v_loss = 0.232000 at lr = 0.007305\n",
            "Trial 52 epoch 5 got t_acc = 0.264045, v_acc = 1.584126, t_loss = 1.600345, and v_loss = 0.228000 at lr = 0.007305\n",
            "Trial 52 epoch 6 got t_acc = 0.272659, v_acc = 1.572616, t_loss = 1.597497, and v_loss = 0.232000 at lr = 0.007305\n",
            "Trial 52 epoch 7 got t_acc = 0.283146, v_acc = 1.561942, t_loss = 1.594883, and v_loss = 0.244000 at lr = 0.007305\n",
            "Trial 52 epoch 8 got t_acc = 0.294007, v_acc = 1.551950, t_loss = 1.592447, and v_loss = 0.250000 at lr = 0.007305\n",
            "Trial 52 epoch 9 got t_acc = 0.302996, v_acc = 1.542551, t_loss = 1.590171, and v_loss = 0.256000 at lr = 0.007305\n",
            "Trial 53 epoch 0 got t_acc = 0.197004, v_acc = 1.699933, t_loss = 1.653989, and v_loss = 0.242000 at lr = 0.005946\n",
            "Trial 53 epoch 1 got t_acc = 0.209738, v_acc = 1.679604, t_loss = 1.646061, and v_loss = 0.242000 at lr = 0.005946\n",
            "Trial 53 epoch 2 got t_acc = 0.218727, v_acc = 1.661072, t_loss = 1.638928, and v_loss = 0.242000 at lr = 0.005946\n",
            "Trial 53 epoch 3 got t_acc = 0.223970, v_acc = 1.644108, t_loss = 1.632430, and v_loss = 0.238000 at lr = 0.005946\n",
            "Trial 53 epoch 4 got t_acc = 0.231461, v_acc = 1.628381, t_loss = 1.626466, and v_loss = 0.234000 at lr = 0.005946\n",
            "Trial 53 epoch 5 got t_acc = 0.241573, v_acc = 1.613796, t_loss = 1.620945, and v_loss = 0.230000 at lr = 0.005946\n",
            "Trial 53 epoch 6 got t_acc = 0.251311, v_acc = 1.600246, t_loss = 1.615849, and v_loss = 0.238000 at lr = 0.005946\n",
            "Trial 53 epoch 7 got t_acc = 0.261049, v_acc = 1.587590, t_loss = 1.611136, and v_loss = 0.242000 at lr = 0.005946\n",
            "Trial 53 epoch 8 got t_acc = 0.268539, v_acc = 1.575733, t_loss = 1.606771, and v_loss = 0.246000 at lr = 0.005946\n",
            "Trial 53 epoch 9 got t_acc = 0.277154, v_acc = 1.564591, t_loss = 1.602715, and v_loss = 0.240000 at lr = 0.005946\n",
            "Trial 54 epoch 0 got t_acc = 0.255805, v_acc = 1.589978, t_loss = 1.592491, and v_loss = 0.250000 at lr = 0.044230\n",
            "Trial 54 epoch 1 got t_acc = 0.316105, v_acc = 1.532075, t_loss = 1.578182, and v_loss = 0.306000 at lr = 0.044230\n",
            "Trial 54 epoch 2 got t_acc = 0.360300, v_acc = 1.487995, t_loss = 1.566730, and v_loss = 0.330000 at lr = 0.044230\n",
            "Trial 54 epoch 3 got t_acc = 0.386891, v_acc = 1.451412, t_loss = 1.557070, and v_loss = 0.340000 at lr = 0.044230\n",
            "Trial 54 epoch 4 got t_acc = 0.408240, v_acc = 1.419913, t_loss = 1.549013, and v_loss = 0.350000 at lr = 0.044230\n",
            "Trial 54 epoch 5 got t_acc = 0.430337, v_acc = 1.392106, t_loss = 1.541726, and v_loss = 0.352000 at lr = 0.044230\n",
            "Trial 54 epoch 6 got t_acc = 0.446442, v_acc = 1.367222, t_loss = 1.535508, and v_loss = 0.370000 at lr = 0.044230\n",
            "Trial 54 epoch 7 got t_acc = 0.458427, v_acc = 1.344497, t_loss = 1.529780, and v_loss = 0.382000 at lr = 0.044230\n",
            "Trial 54 epoch 8 got t_acc = 0.470412, v_acc = 1.323440, t_loss = 1.524701, and v_loss = 0.390000 at lr = 0.044230\n",
            "Trial 54 epoch 9 got t_acc = 0.483895, v_acc = 1.303950, t_loss = 1.520185, and v_loss = 0.388000 at lr = 0.044230\n",
            "Trial 55 epoch 0 got t_acc = 0.232584, v_acc = 1.672717, t_loss = 1.630865, and v_loss = 0.168000 at lr = 0.001703\n",
            "Trial 55 epoch 1 got t_acc = 0.234082, v_acc = 1.667629, t_loss = 1.629454, and v_loss = 0.168000 at lr = 0.001703\n",
            "Trial 55 epoch 2 got t_acc = 0.234831, v_acc = 1.662715, t_loss = 1.628060, and v_loss = 0.170000 at lr = 0.001703\n",
            "Trial 55 epoch 3 got t_acc = 0.235581, v_acc = 1.657966, t_loss = 1.626696, and v_loss = 0.176000 at lr = 0.001703\n",
            "Trial 55 epoch 4 got t_acc = 0.240075, v_acc = 1.653373, t_loss = 1.625365, and v_loss = 0.178000 at lr = 0.001703\n",
            "Trial 55 epoch 5 got t_acc = 0.241948, v_acc = 1.648916, t_loss = 1.624074, and v_loss = 0.182000 at lr = 0.001703\n",
            "Trial 55 epoch 6 got t_acc = 0.243071, v_acc = 1.644600, t_loss = 1.622815, and v_loss = 0.178000 at lr = 0.001703\n",
            "Trial 55 epoch 7 got t_acc = 0.244569, v_acc = 1.640420, t_loss = 1.621588, and v_loss = 0.178000 at lr = 0.001703\n",
            "Trial 55 epoch 8 got t_acc = 0.247191, v_acc = 1.636359, t_loss = 1.620399, and v_loss = 0.180000 at lr = 0.001703\n",
            "Trial 55 epoch 9 got t_acc = 0.250936, v_acc = 1.632418, t_loss = 1.619240, and v_loss = 0.186000 at lr = 0.001703\n",
            "Trial 56 epoch 0 got t_acc = 0.222097, v_acc = 1.657969, t_loss = 1.601068, and v_loss = 0.262000 at lr = 0.000401\n",
            "Trial 56 epoch 1 got t_acc = 0.221723, v_acc = 1.657014, t_loss = 1.600960, and v_loss = 0.262000 at lr = 0.000401\n",
            "Trial 56 epoch 2 got t_acc = 0.222472, v_acc = 1.656065, t_loss = 1.600852, and v_loss = 0.258000 at lr = 0.000401\n",
            "Trial 56 epoch 3 got t_acc = 0.222472, v_acc = 1.655121, t_loss = 1.600744, and v_loss = 0.258000 at lr = 0.000401\n",
            "Trial 56 epoch 4 got t_acc = 0.222472, v_acc = 1.654183, t_loss = 1.600638, and v_loss = 0.258000 at lr = 0.000401\n",
            "Trial 56 epoch 5 got t_acc = 0.222472, v_acc = 1.653249, t_loss = 1.600533, and v_loss = 0.258000 at lr = 0.000401\n",
            "Trial 56 epoch 6 got t_acc = 0.223596, v_acc = 1.652321, t_loss = 1.600429, and v_loss = 0.258000 at lr = 0.000401\n",
            "Trial 56 epoch 7 got t_acc = 0.223221, v_acc = 1.651399, t_loss = 1.600326, and v_loss = 0.260000 at lr = 0.000401\n",
            "Trial 56 epoch 8 got t_acc = 0.223596, v_acc = 1.650483, t_loss = 1.600223, and v_loss = 0.260000 at lr = 0.000401\n",
            "Trial 56 epoch 9 got t_acc = 0.225094, v_acc = 1.649571, t_loss = 1.600121, and v_loss = 0.262000 at lr = 0.000401\n",
            "Trial 57 epoch 0 got t_acc = 0.187640, v_acc = 1.673831, t_loss = 1.606475, and v_loss = 0.266000 at lr = 0.006507\n",
            "Trial 57 epoch 1 got t_acc = 0.199251, v_acc = 1.660988, t_loss = 1.603505, and v_loss = 0.270000 at lr = 0.006507\n",
            "Trial 57 epoch 2 got t_acc = 0.202996, v_acc = 1.648957, t_loss = 1.600752, and v_loss = 0.268000 at lr = 0.006507\n",
            "Trial 57 epoch 3 got t_acc = 0.212734, v_acc = 1.637651, t_loss = 1.598143, and v_loss = 0.272000 at lr = 0.006507\n",
            "Trial 57 epoch 4 got t_acc = 0.220974, v_acc = 1.627003, t_loss = 1.595695, and v_loss = 0.274000 at lr = 0.006507\n",
            "Trial 57 epoch 5 got t_acc = 0.232210, v_acc = 1.616915, t_loss = 1.593354, and v_loss = 0.280000 at lr = 0.006507\n",
            "Trial 57 epoch 6 got t_acc = 0.241573, v_acc = 1.607344, t_loss = 1.591191, and v_loss = 0.282000 at lr = 0.006507\n",
            "Trial 57 epoch 7 got t_acc = 0.254682, v_acc = 1.598232, t_loss = 1.589163, and v_loss = 0.288000 at lr = 0.006507\n",
            "Trial 57 epoch 8 got t_acc = 0.262921, v_acc = 1.589528, t_loss = 1.587255, and v_loss = 0.294000 at lr = 0.006507\n",
            "Trial 57 epoch 9 got t_acc = 0.271161, v_acc = 1.581198, t_loss = 1.585464, and v_loss = 0.302000 at lr = 0.006507\n",
            "Trial 58 epoch 0 got t_acc = 0.241948, v_acc = 1.645428, t_loss = 1.621610, and v_loss = 0.192000 at lr = 0.019808\n",
            "Trial 58 epoch 1 got t_acc = 0.268539, v_acc = 1.608310, t_loss = 1.610219, and v_loss = 0.218000 at lr = 0.019808\n",
            "Trial 58 epoch 2 got t_acc = 0.291386, v_acc = 1.576571, t_loss = 1.601187, and v_loss = 0.240000 at lr = 0.019808\n",
            "Trial 58 epoch 3 got t_acc = 0.308989, v_acc = 1.549138, t_loss = 1.593843, and v_loss = 0.252000 at lr = 0.019808\n",
            "Trial 58 epoch 4 got t_acc = 0.332210, v_acc = 1.524962, t_loss = 1.587730, and v_loss = 0.284000 at lr = 0.019808\n",
            "Trial 58 epoch 5 got t_acc = 0.346442, v_acc = 1.503306, t_loss = 1.582290, and v_loss = 0.292000 at lr = 0.019808\n",
            "Trial 58 epoch 6 got t_acc = 0.359176, v_acc = 1.483671, t_loss = 1.577387, and v_loss = 0.298000 at lr = 0.019808\n",
            "Trial 58 epoch 7 got t_acc = 0.369663, v_acc = 1.465747, t_loss = 1.572851, and v_loss = 0.312000 at lr = 0.019808\n",
            "Trial 58 epoch 8 got t_acc = 0.381273, v_acc = 1.449179, t_loss = 1.568595, and v_loss = 0.316000 at lr = 0.019808\n",
            "Trial 58 epoch 9 got t_acc = 0.391386, v_acc = 1.433764, t_loss = 1.564627, and v_loss = 0.324000 at lr = 0.019808\n",
            "Trial 59 epoch 0 got t_acc = 0.215356, v_acc = 1.690618, t_loss = 1.607813, and v_loss = 0.262000 at lr = 0.000423\n",
            "Trial 59 epoch 1 got t_acc = 0.216479, v_acc = 1.689262, t_loss = 1.607588, and v_loss = 0.260000 at lr = 0.000423\n",
            "Trial 59 epoch 2 got t_acc = 0.217228, v_acc = 1.687916, t_loss = 1.607365, and v_loss = 0.260000 at lr = 0.000423\n",
            "Trial 59 epoch 3 got t_acc = 0.218352, v_acc = 1.686578, t_loss = 1.607143, and v_loss = 0.256000 at lr = 0.000423\n",
            "Trial 59 epoch 4 got t_acc = 0.218352, v_acc = 1.685250, t_loss = 1.606923, and v_loss = 0.260000 at lr = 0.000423\n",
            "Trial 59 epoch 5 got t_acc = 0.217603, v_acc = 1.683930, t_loss = 1.606703, and v_loss = 0.258000 at lr = 0.000423\n",
            "Trial 59 epoch 6 got t_acc = 0.217978, v_acc = 1.682619, t_loss = 1.606484, and v_loss = 0.260000 at lr = 0.000423\n",
            "Trial 59 epoch 7 got t_acc = 0.219101, v_acc = 1.681316, t_loss = 1.606267, and v_loss = 0.264000 at lr = 0.000423\n",
            "Trial 59 epoch 8 got t_acc = 0.220225, v_acc = 1.680021, t_loss = 1.606051, and v_loss = 0.258000 at lr = 0.000423\n",
            "Trial 59 epoch 9 got t_acc = 0.220974, v_acc = 1.678736, t_loss = 1.605836, and v_loss = 0.260000 at lr = 0.000423\n",
            "Trial 60 epoch 0 got t_acc = 0.173034, v_acc = 1.713254, t_loss = 1.651758, and v_loss = 0.210000 at lr = 0.001020\n",
            "Trial 60 epoch 1 got t_acc = 0.174532, v_acc = 1.709455, t_loss = 1.650673, and v_loss = 0.210000 at lr = 0.001020\n",
            "Trial 60 epoch 2 got t_acc = 0.177528, v_acc = 1.705724, t_loss = 1.649615, and v_loss = 0.210000 at lr = 0.001020\n",
            "Trial 60 epoch 3 got t_acc = 0.179401, v_acc = 1.702057, t_loss = 1.648577, and v_loss = 0.206000 at lr = 0.001020\n",
            "Trial 60 epoch 4 got t_acc = 0.181648, v_acc = 1.698452, t_loss = 1.647566, and v_loss = 0.202000 at lr = 0.001020\n",
            "Trial 60 epoch 5 got t_acc = 0.182772, v_acc = 1.694909, t_loss = 1.646574, and v_loss = 0.206000 at lr = 0.001020\n",
            "Trial 60 epoch 6 got t_acc = 0.185393, v_acc = 1.691425, t_loss = 1.645604, and v_loss = 0.204000 at lr = 0.001020\n",
            "Trial 60 epoch 7 got t_acc = 0.187266, v_acc = 1.687997, t_loss = 1.644657, and v_loss = 0.204000 at lr = 0.001020\n",
            "Trial 60 epoch 8 got t_acc = 0.189513, v_acc = 1.684623, t_loss = 1.643732, and v_loss = 0.204000 at lr = 0.001020\n",
            "Trial 60 epoch 9 got t_acc = 0.191011, v_acc = 1.681303, t_loss = 1.642825, and v_loss = 0.208000 at lr = 0.001020\n",
            "Trial 61 epoch 0 got t_acc = 0.200000, v_acc = 1.682460, t_loss = 1.626233, and v_loss = 0.196000 at lr = 0.000294\n",
            "Trial 61 epoch 1 got t_acc = 0.200749, v_acc = 1.681589, t_loss = 1.626073, and v_loss = 0.198000 at lr = 0.000294\n",
            "Trial 61 epoch 2 got t_acc = 0.200749, v_acc = 1.680721, t_loss = 1.625913, and v_loss = 0.200000 at lr = 0.000294\n",
            "Trial 61 epoch 3 got t_acc = 0.201124, v_acc = 1.679855, t_loss = 1.625754, and v_loss = 0.200000 at lr = 0.000294\n",
            "Trial 61 epoch 4 got t_acc = 0.202247, v_acc = 1.678992, t_loss = 1.625595, and v_loss = 0.200000 at lr = 0.000294\n",
            "Trial 61 epoch 5 got t_acc = 0.202247, v_acc = 1.678133, t_loss = 1.625437, and v_loss = 0.200000 at lr = 0.000294\n",
            "Trial 61 epoch 6 got t_acc = 0.202622, v_acc = 1.677277, t_loss = 1.625279, and v_loss = 0.202000 at lr = 0.000294\n",
            "Trial 61 epoch 7 got t_acc = 0.203371, v_acc = 1.676423, t_loss = 1.625121, and v_loss = 0.202000 at lr = 0.000294\n",
            "Trial 61 epoch 8 got t_acc = 0.203745, v_acc = 1.675573, t_loss = 1.624962, and v_loss = 0.202000 at lr = 0.000294\n",
            "Trial 61 epoch 9 got t_acc = 0.203745, v_acc = 1.674725, t_loss = 1.624804, and v_loss = 0.202000 at lr = 0.000294\n",
            "Trial 62 epoch 0 got t_acc = 0.169663, v_acc = 1.716379, t_loss = 1.609075, and v_loss = 0.230000 at lr = 0.002922\n",
            "Trial 62 epoch 1 got t_acc = 0.172285, v_acc = 1.706995, t_loss = 1.606930, and v_loss = 0.234000 at lr = 0.002922\n",
            "Trial 62 epoch 2 got t_acc = 0.174532, v_acc = 1.698049, t_loss = 1.604919, and v_loss = 0.234000 at lr = 0.002922\n",
            "Trial 62 epoch 3 got t_acc = 0.177528, v_acc = 1.689505, t_loss = 1.603029, and v_loss = 0.232000 at lr = 0.002922\n",
            "Trial 62 epoch 4 got t_acc = 0.181648, v_acc = 1.681346, t_loss = 1.601235, and v_loss = 0.234000 at lr = 0.002922\n",
            "Trial 62 epoch 5 got t_acc = 0.183521, v_acc = 1.673518, t_loss = 1.599550, and v_loss = 0.236000 at lr = 0.002922\n",
            "Trial 62 epoch 6 got t_acc = 0.186517, v_acc = 1.666009, t_loss = 1.597957, and v_loss = 0.234000 at lr = 0.002922\n",
            "Trial 62 epoch 7 got t_acc = 0.190262, v_acc = 1.658785, t_loss = 1.596440, and v_loss = 0.234000 at lr = 0.002922\n",
            "Trial 62 epoch 8 got t_acc = 0.194007, v_acc = 1.651843, t_loss = 1.594993, and v_loss = 0.232000 at lr = 0.002922\n",
            "Trial 62 epoch 9 got t_acc = 0.199251, v_acc = 1.645147, t_loss = 1.593623, and v_loss = 0.232000 at lr = 0.002922\n",
            "Trial 63 epoch 0 got t_acc = 0.156929, v_acc = 1.747414, t_loss = 1.635009, and v_loss = 0.166000 at lr = 0.000608\n",
            "Trial 63 epoch 1 got t_acc = 0.157678, v_acc = 1.744994, t_loss = 1.634409, and v_loss = 0.166000 at lr = 0.000608\n",
            "Trial 63 epoch 2 got t_acc = 0.158052, v_acc = 1.742600, t_loss = 1.633818, and v_loss = 0.166000 at lr = 0.000608\n",
            "Trial 63 epoch 3 got t_acc = 0.158052, v_acc = 1.740235, t_loss = 1.633236, and v_loss = 0.166000 at lr = 0.000608\n",
            "Trial 63 epoch 4 got t_acc = 0.159176, v_acc = 1.737893, t_loss = 1.632665, and v_loss = 0.168000 at lr = 0.000608\n",
            "Trial 63 epoch 5 got t_acc = 0.160300, v_acc = 1.735580, t_loss = 1.632103, and v_loss = 0.168000 at lr = 0.000608\n",
            "Trial 63 epoch 6 got t_acc = 0.161049, v_acc = 1.733293, t_loss = 1.631550, and v_loss = 0.166000 at lr = 0.000608\n",
            "Trial 63 epoch 7 got t_acc = 0.162547, v_acc = 1.731035, t_loss = 1.631008, and v_loss = 0.168000 at lr = 0.000608\n",
            "Trial 63 epoch 8 got t_acc = 0.162547, v_acc = 1.728805, t_loss = 1.630475, and v_loss = 0.170000 at lr = 0.000608\n",
            "Trial 63 epoch 9 got t_acc = 0.162172, v_acc = 1.726600, t_loss = 1.629951, and v_loss = 0.174000 at lr = 0.000608\n",
            "Trial 64 epoch 0 got t_acc = 0.187640, v_acc = 1.687312, t_loss = 1.621349, and v_loss = 0.206000 at lr = 0.003817\n",
            "Trial 64 epoch 1 got t_acc = 0.188015, v_acc = 1.673430, t_loss = 1.619331, and v_loss = 0.214000 at lr = 0.003817\n",
            "Trial 64 epoch 2 got t_acc = 0.191760, v_acc = 1.660867, t_loss = 1.617408, and v_loss = 0.220000 at lr = 0.003817\n",
            "Trial 64 epoch 3 got t_acc = 0.197378, v_acc = 1.649402, t_loss = 1.615544, and v_loss = 0.218000 at lr = 0.003817\n",
            "Trial 64 epoch 4 got t_acc = 0.208240, v_acc = 1.638843, t_loss = 1.613740, and v_loss = 0.228000 at lr = 0.003817\n",
            "Trial 64 epoch 5 got t_acc = 0.213109, v_acc = 1.629070, t_loss = 1.612023, and v_loss = 0.232000 at lr = 0.003817\n",
            "Trial 64 epoch 6 got t_acc = 0.222472, v_acc = 1.619941, t_loss = 1.610391, and v_loss = 0.228000 at lr = 0.003817\n",
            "Trial 64 epoch 7 got t_acc = 0.229963, v_acc = 1.611391, t_loss = 1.608810, and v_loss = 0.230000 at lr = 0.003817\n",
            "Trial 64 epoch 8 got t_acc = 0.237079, v_acc = 1.603385, t_loss = 1.607281, and v_loss = 0.236000 at lr = 0.003817\n",
            "Trial 64 epoch 9 got t_acc = 0.239700, v_acc = 1.595856, t_loss = 1.605800, and v_loss = 0.236000 at lr = 0.003817\n",
            "Trial 65 epoch 0 got t_acc = 0.241573, v_acc = 1.638072, t_loss = 1.607789, and v_loss = 0.238000 at lr = 0.000905\n",
            "Trial 65 epoch 1 got t_acc = 0.243071, v_acc = 1.636076, t_loss = 1.607545, and v_loss = 0.234000 at lr = 0.000905\n",
            "Trial 65 epoch 2 got t_acc = 0.243446, v_acc = 1.634106, t_loss = 1.607303, and v_loss = 0.234000 at lr = 0.000905\n",
            "Trial 65 epoch 3 got t_acc = 0.244569, v_acc = 1.632161, t_loss = 1.607064, and v_loss = 0.234000 at lr = 0.000905\n",
            "Trial 65 epoch 4 got t_acc = 0.244195, v_acc = 1.630240, t_loss = 1.606827, and v_loss = 0.236000 at lr = 0.000905\n",
            "Trial 65 epoch 5 got t_acc = 0.244195, v_acc = 1.628342, t_loss = 1.606590, and v_loss = 0.238000 at lr = 0.000905\n",
            "Trial 65 epoch 6 got t_acc = 0.244569, v_acc = 1.626468, t_loss = 1.606354, and v_loss = 0.240000 at lr = 0.000905\n",
            "Trial 65 epoch 7 got t_acc = 0.246816, v_acc = 1.624614, t_loss = 1.606119, and v_loss = 0.240000 at lr = 0.000905\n",
            "Trial 65 epoch 8 got t_acc = 0.248315, v_acc = 1.622779, t_loss = 1.605884, and v_loss = 0.240000 at lr = 0.000905\n",
            "Trial 65 epoch 9 got t_acc = 0.250562, v_acc = 1.620967, t_loss = 1.605651, and v_loss = 0.236000 at lr = 0.000905\n",
            "Trial 66 epoch 0 got t_acc = 0.168539, v_acc = 1.713344, t_loss = 1.619254, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 1 got t_acc = 0.169288, v_acc = 1.712217, t_loss = 1.618853, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 2 got t_acc = 0.169663, v_acc = 1.711097, t_loss = 1.618454, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 3 got t_acc = 0.170412, v_acc = 1.709983, t_loss = 1.618058, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 4 got t_acc = 0.171161, v_acc = 1.708874, t_loss = 1.617667, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 5 got t_acc = 0.172285, v_acc = 1.707772, t_loss = 1.617280, and v_loss = 0.212000 at lr = 0.000336\n",
            "Trial 66 epoch 6 got t_acc = 0.172659, v_acc = 1.706675, t_loss = 1.616896, and v_loss = 0.212000 at lr = 0.000336\n",
            "Trial 66 epoch 7 got t_acc = 0.173034, v_acc = 1.705583, t_loss = 1.616514, and v_loss = 0.210000 at lr = 0.000336\n",
            "Trial 66 epoch 8 got t_acc = 0.173408, v_acc = 1.704495, t_loss = 1.616136, and v_loss = 0.214000 at lr = 0.000336\n",
            "Trial 66 epoch 9 got t_acc = 0.173408, v_acc = 1.703414, t_loss = 1.615761, and v_loss = 0.212000 at lr = 0.000336\n",
            "Trial 67 epoch 0 got t_acc = 0.234831, v_acc = 1.615510, t_loss = 1.604475, and v_loss = 0.216000 at lr = 0.036257\n",
            "Trial 67 epoch 1 got t_acc = 0.287266, v_acc = 1.557709, t_loss = 1.593170, and v_loss = 0.262000 at lr = 0.036257\n",
            "Trial 67 epoch 2 got t_acc = 0.322472, v_acc = 1.516728, t_loss = 1.585014, and v_loss = 0.282000 at lr = 0.036257\n",
            "Trial 67 epoch 3 got t_acc = 0.349813, v_acc = 1.484181, t_loss = 1.577818, and v_loss = 0.318000 at lr = 0.036257\n",
            "Trial 67 epoch 4 got t_acc = 0.373408, v_acc = 1.456513, t_loss = 1.571095, and v_loss = 0.320000 at lr = 0.036257\n",
            "Trial 67 epoch 5 got t_acc = 0.400749, v_acc = 1.431911, t_loss = 1.564890, and v_loss = 0.338000 at lr = 0.036257\n",
            "Trial 67 epoch 6 got t_acc = 0.420599, v_acc = 1.409676, t_loss = 1.558927, and v_loss = 0.344000 at lr = 0.036257\n",
            "Trial 67 epoch 7 got t_acc = 0.433708, v_acc = 1.389334, t_loss = 1.553158, and v_loss = 0.338000 at lr = 0.036257\n",
            "Trial 67 epoch 8 got t_acc = 0.443446, v_acc = 1.370535, t_loss = 1.547744, and v_loss = 0.342000 at lr = 0.036257\n",
            "Trial 67 epoch 9 got t_acc = 0.454682, v_acc = 1.352839, t_loss = 1.542524, and v_loss = 0.340000 at lr = 0.036257\n",
            "Trial 68 epoch 0 got t_acc = 0.211985, v_acc = 1.655363, t_loss = 1.609291, and v_loss = 0.214000 at lr = 0.000385\n",
            "Trial 68 epoch 1 got t_acc = 0.211985, v_acc = 1.654485, t_loss = 1.609157, and v_loss = 0.214000 at lr = 0.000385\n",
            "Trial 68 epoch 2 got t_acc = 0.213858, v_acc = 1.653611, t_loss = 1.609023, and v_loss = 0.214000 at lr = 0.000385\n",
            "Trial 68 epoch 3 got t_acc = 0.215356, v_acc = 1.652741, t_loss = 1.608890, and v_loss = 0.214000 at lr = 0.000385\n",
            "Trial 68 epoch 4 got t_acc = 0.215730, v_acc = 1.651876, t_loss = 1.608757, and v_loss = 0.216000 at lr = 0.000385\n",
            "Trial 68 epoch 5 got t_acc = 0.216479, v_acc = 1.651015, t_loss = 1.608624, and v_loss = 0.216000 at lr = 0.000385\n",
            "Trial 68 epoch 6 got t_acc = 0.216479, v_acc = 1.650159, t_loss = 1.608491, and v_loss = 0.218000 at lr = 0.000385\n",
            "Trial 68 epoch 7 got t_acc = 0.217603, v_acc = 1.649308, t_loss = 1.608359, and v_loss = 0.218000 at lr = 0.000385\n",
            "Trial 68 epoch 8 got t_acc = 0.217603, v_acc = 1.648462, t_loss = 1.608227, and v_loss = 0.218000 at lr = 0.000385\n",
            "Trial 68 epoch 9 got t_acc = 0.219101, v_acc = 1.647620, t_loss = 1.608096, and v_loss = 0.218000 at lr = 0.000385\n",
            "Trial 69 epoch 0 got t_acc = 0.259925, v_acc = 1.594770, t_loss = 1.608457, and v_loss = 0.208000 at lr = 0.057093\n",
            "Trial 69 epoch 1 got t_acc = 0.313858, v_acc = 1.517709, t_loss = 1.589650, and v_loss = 0.262000 at lr = 0.057093\n",
            "Trial 69 epoch 2 got t_acc = 0.364794, v_acc = 1.463983, t_loss = 1.576560, and v_loss = 0.290000 at lr = 0.057093\n",
            "Trial 69 epoch 3 got t_acc = 0.401873, v_acc = 1.421314, t_loss = 1.565255, and v_loss = 0.302000 at lr = 0.057093\n",
            "Trial 69 epoch 4 got t_acc = 0.429963, v_acc = 1.385816, t_loss = 1.555168, and v_loss = 0.314000 at lr = 0.057093\n",
            "Trial 69 epoch 5 got t_acc = 0.446067, v_acc = 1.355347, t_loss = 1.546256, and v_loss = 0.322000 at lr = 0.057093\n",
            "Trial 69 epoch 6 got t_acc = 0.459925, v_acc = 1.328584, t_loss = 1.538920, and v_loss = 0.336000 at lr = 0.057093\n",
            "Trial 69 epoch 7 got t_acc = 0.473408, v_acc = 1.304401, t_loss = 1.532540, and v_loss = 0.336000 at lr = 0.057093\n",
            "Trial 69 epoch 8 got t_acc = 0.483521, v_acc = 1.282270, t_loss = 1.526968, and v_loss = 0.348000 at lr = 0.057093\n",
            "Trial 69 epoch 9 got t_acc = 0.496629, v_acc = 1.261858, t_loss = 1.521999, and v_loss = 0.350000 at lr = 0.057093\n",
            "Trial 70 epoch 0 got t_acc = 0.185019, v_acc = 1.676110, t_loss = 1.629057, and v_loss = 0.182000 at lr = 0.002230\n",
            "Trial 70 epoch 1 got t_acc = 0.185768, v_acc = 1.670320, t_loss = 1.626866, and v_loss = 0.190000 at lr = 0.002230\n",
            "Trial 70 epoch 2 got t_acc = 0.189888, v_acc = 1.664703, t_loss = 1.624751, and v_loss = 0.192000 at lr = 0.002230\n",
            "Trial 70 epoch 3 got t_acc = 0.195506, v_acc = 1.659256, t_loss = 1.622715, and v_loss = 0.196000 at lr = 0.002230\n",
            "Trial 70 epoch 4 got t_acc = 0.201498, v_acc = 1.653955, t_loss = 1.620742, and v_loss = 0.198000 at lr = 0.002230\n",
            "Trial 70 epoch 5 got t_acc = 0.205618, v_acc = 1.648805, t_loss = 1.618837, and v_loss = 0.198000 at lr = 0.002230\n",
            "Trial 70 epoch 6 got t_acc = 0.209363, v_acc = 1.643793, t_loss = 1.616985, and v_loss = 0.202000 at lr = 0.002230\n",
            "Trial 70 epoch 7 got t_acc = 0.214232, v_acc = 1.638914, t_loss = 1.615201, and v_loss = 0.212000 at lr = 0.002230\n",
            "Trial 70 epoch 8 got t_acc = 0.218352, v_acc = 1.634163, t_loss = 1.613482, and v_loss = 0.216000 at lr = 0.002230\n",
            "Trial 70 epoch 9 got t_acc = 0.223221, v_acc = 1.629538, t_loss = 1.611823, and v_loss = 0.220000 at lr = 0.002230\n",
            "Trial 71 epoch 0 got t_acc = 0.167790, v_acc = 1.669697, t_loss = 1.628772, and v_loss = 0.170000 at lr = 0.005922\n",
            "Trial 71 epoch 1 got t_acc = 0.176030, v_acc = 1.659842, t_loss = 1.625052, and v_loss = 0.170000 at lr = 0.005922\n",
            "Trial 71 epoch 2 got t_acc = 0.185393, v_acc = 1.650632, t_loss = 1.621711, and v_loss = 0.172000 at lr = 0.005922\n",
            "Trial 71 epoch 3 got t_acc = 0.195131, v_acc = 1.641958, t_loss = 1.618697, and v_loss = 0.186000 at lr = 0.005922\n",
            "Trial 71 epoch 4 got t_acc = 0.202996, v_acc = 1.633746, t_loss = 1.615919, and v_loss = 0.194000 at lr = 0.005922\n",
            "Trial 71 epoch 5 got t_acc = 0.207865, v_acc = 1.625943, t_loss = 1.613373, and v_loss = 0.202000 at lr = 0.005922\n",
            "Trial 71 epoch 6 got t_acc = 0.217978, v_acc = 1.618510, t_loss = 1.611028, and v_loss = 0.210000 at lr = 0.005922\n",
            "Trial 71 epoch 7 got t_acc = 0.227715, v_acc = 1.611381, t_loss = 1.608837, and v_loss = 0.222000 at lr = 0.005922\n",
            "Trial 71 epoch 8 got t_acc = 0.236330, v_acc = 1.604539, t_loss = 1.606778, and v_loss = 0.236000 at lr = 0.005922\n",
            "Trial 71 epoch 9 got t_acc = 0.243446, v_acc = 1.597958, t_loss = 1.604840, and v_loss = 0.240000 at lr = 0.005922\n",
            "Trial 72 epoch 0 got t_acc = 0.244569, v_acc = 1.623408, t_loss = 1.604272, and v_loss = 0.288000 at lr = 0.000208\n",
            "Trial 72 epoch 1 got t_acc = 0.244944, v_acc = 1.623041, t_loss = 1.604175, and v_loss = 0.288000 at lr = 0.000208\n",
            "Trial 72 epoch 2 got t_acc = 0.244944, v_acc = 1.622675, t_loss = 1.604077, and v_loss = 0.288000 at lr = 0.000208\n",
            "Trial 72 epoch 3 got t_acc = 0.245318, v_acc = 1.622309, t_loss = 1.603980, and v_loss = 0.288000 at lr = 0.000208\n",
            "Trial 72 epoch 4 got t_acc = 0.244944, v_acc = 1.621945, t_loss = 1.603883, and v_loss = 0.288000 at lr = 0.000208\n",
            "Trial 72 epoch 5 got t_acc = 0.245318, v_acc = 1.621581, t_loss = 1.603786, and v_loss = 0.286000 at lr = 0.000208\n",
            "Trial 72 epoch 6 got t_acc = 0.245318, v_acc = 1.621217, t_loss = 1.603690, and v_loss = 0.286000 at lr = 0.000208\n",
            "Trial 72 epoch 7 got t_acc = 0.245318, v_acc = 1.620855, t_loss = 1.603593, and v_loss = 0.286000 at lr = 0.000208\n",
            "Trial 72 epoch 8 got t_acc = 0.246067, v_acc = 1.620494, t_loss = 1.603498, and v_loss = 0.286000 at lr = 0.000208\n",
            "Trial 72 epoch 9 got t_acc = 0.246442, v_acc = 1.620134, t_loss = 1.603402, and v_loss = 0.286000 at lr = 0.000208\n",
            "Trial 73 epoch 0 got t_acc = 0.267041, v_acc = 1.615854, t_loss = 1.595261, and v_loss = 0.250000 at lr = 0.029554\n",
            "Trial 73 epoch 1 got t_acc = 0.294757, v_acc = 1.572725, t_loss = 1.586549, and v_loss = 0.266000 at lr = 0.029554\n",
            "Trial 73 epoch 2 got t_acc = 0.320225, v_acc = 1.537155, t_loss = 1.578567, and v_loss = 0.302000 at lr = 0.029554\n",
            "Trial 73 epoch 3 got t_acc = 0.350936, v_acc = 1.506686, t_loss = 1.571485, and v_loss = 0.320000 at lr = 0.029554\n",
            "Trial 73 epoch 4 got t_acc = 0.367041, v_acc = 1.479894, t_loss = 1.565174, and v_loss = 0.338000 at lr = 0.029554\n",
            "Trial 73 epoch 5 got t_acc = 0.383895, v_acc = 1.455884, t_loss = 1.559335, and v_loss = 0.344000 at lr = 0.029554\n",
            "Trial 73 epoch 6 got t_acc = 0.392884, v_acc = 1.434216, t_loss = 1.554070, and v_loss = 0.360000 at lr = 0.029554\n",
            "Trial 73 epoch 7 got t_acc = 0.407116, v_acc = 1.414453, t_loss = 1.549348, and v_loss = 0.370000 at lr = 0.029554\n",
            "Trial 73 epoch 8 got t_acc = 0.417228, v_acc = 1.396300, t_loss = 1.545057, and v_loss = 0.368000 at lr = 0.029554\n",
            "Trial 73 epoch 9 got t_acc = 0.425094, v_acc = 1.379435, t_loss = 1.541112, and v_loss = 0.368000 at lr = 0.029554\n",
            "Trial 74 epoch 0 got t_acc = 0.202622, v_acc = 1.683810, t_loss = 1.596127, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 1 got t_acc = 0.202996, v_acc = 1.683502, t_loss = 1.596088, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 2 got t_acc = 0.202996, v_acc = 1.683195, t_loss = 1.596049, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 3 got t_acc = 0.202996, v_acc = 1.682888, t_loss = 1.596010, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 4 got t_acc = 0.203371, v_acc = 1.682582, t_loss = 1.595971, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 5 got t_acc = 0.203745, v_acc = 1.682277, t_loss = 1.595932, and v_loss = 0.244000 at lr = 0.000109\n",
            "Trial 74 epoch 6 got t_acc = 0.203745, v_acc = 1.681972, t_loss = 1.595894, and v_loss = 0.242000 at lr = 0.000109\n",
            "Trial 74 epoch 7 got t_acc = 0.204494, v_acc = 1.681668, t_loss = 1.595855, and v_loss = 0.242000 at lr = 0.000109\n",
            "Trial 74 epoch 8 got t_acc = 0.204494, v_acc = 1.681364, t_loss = 1.595816, and v_loss = 0.242000 at lr = 0.000109\n",
            "Trial 74 epoch 9 got t_acc = 0.205243, v_acc = 1.681061, t_loss = 1.595778, and v_loss = 0.242000 at lr = 0.000109\n",
            "Trial 75 epoch 0 got t_acc = 0.215730, v_acc = 1.658137, t_loss = 1.617709, and v_loss = 0.262000 at lr = 0.006739\n",
            "Trial 75 epoch 1 got t_acc = 0.228090, v_acc = 1.642335, t_loss = 1.612576, and v_loss = 0.262000 at lr = 0.006739\n",
            "Trial 75 epoch 2 got t_acc = 0.236704, v_acc = 1.627802, t_loss = 1.608084, and v_loss = 0.268000 at lr = 0.006739\n",
            "Trial 75 epoch 3 got t_acc = 0.240449, v_acc = 1.614320, t_loss = 1.604084, and v_loss = 0.264000 at lr = 0.006739\n",
            "Trial 75 epoch 4 got t_acc = 0.252060, v_acc = 1.601726, t_loss = 1.600478, and v_loss = 0.268000 at lr = 0.006739\n",
            "Trial 75 epoch 5 got t_acc = 0.259176, v_acc = 1.589929, t_loss = 1.597225, and v_loss = 0.264000 at lr = 0.006739\n",
            "Trial 75 epoch 6 got t_acc = 0.265918, v_acc = 1.578861, t_loss = 1.594252, and v_loss = 0.264000 at lr = 0.006739\n",
            "Trial 75 epoch 7 got t_acc = 0.279401, v_acc = 1.568421, t_loss = 1.591511, and v_loss = 0.264000 at lr = 0.006739\n",
            "Trial 75 epoch 8 got t_acc = 0.284270, v_acc = 1.558546, t_loss = 1.588967, and v_loss = 0.274000 at lr = 0.006739\n",
            "Trial 75 epoch 9 got t_acc = 0.297004, v_acc = 1.549180, t_loss = 1.586565, and v_loss = 0.268000 at lr = 0.006739\n",
            "Trial 76 epoch 0 got t_acc = 0.330712, v_acc = 1.525914, t_loss = 1.602728, and v_loss = 0.222000 at lr = 0.084230\n",
            "Trial 76 epoch 1 got t_acc = 0.388390, v_acc = 1.443033, t_loss = 1.561958, and v_loss = 0.342000 at lr = 0.084230\n",
            "Trial 76 epoch 2 got t_acc = 0.426966, v_acc = 1.384086, t_loss = 1.548240, and v_loss = 0.352000 at lr = 0.084230\n",
            "Trial 76 epoch 3 got t_acc = 0.460300, v_acc = 1.337450, t_loss = 1.534044, and v_loss = 0.372000 at lr = 0.084230\n",
            "Trial 76 epoch 4 got t_acc = 0.474906, v_acc = 1.298592, t_loss = 1.524603, and v_loss = 0.368000 at lr = 0.084230\n",
            "Trial 76 epoch 5 got t_acc = 0.491760, v_acc = 1.265242, t_loss = 1.515411, and v_loss = 0.382000 at lr = 0.084230\n",
            "Trial 76 epoch 6 got t_acc = 0.507865, v_acc = 1.235882, t_loss = 1.508310, and v_loss = 0.382000 at lr = 0.084230\n",
            "Trial 76 epoch 7 got t_acc = 0.521723, v_acc = 1.209773, t_loss = 1.501694, and v_loss = 0.368000 at lr = 0.084230\n",
            "Trial 76 epoch 8 got t_acc = 0.533708, v_acc = 1.186304, t_loss = 1.496815, and v_loss = 0.378000 at lr = 0.084230\n",
            "Trial 76 epoch 9 got t_acc = 0.546816, v_acc = 1.164629, t_loss = 1.491793, and v_loss = 0.374000 at lr = 0.084230\n",
            "Trial 77 epoch 0 got t_acc = 0.326592, v_acc = 1.529282, t_loss = 1.586081, and v_loss = 0.298000 at lr = 0.073440\n",
            "Trial 77 epoch 1 got t_acc = 0.380524, v_acc = 1.464912, t_loss = 1.569339, and v_loss = 0.326000 at lr = 0.073440\n",
            "Trial 77 epoch 2 got t_acc = 0.410112, v_acc = 1.415024, t_loss = 1.556943, and v_loss = 0.348000 at lr = 0.073440\n",
            "Trial 77 epoch 3 got t_acc = 0.433708, v_acc = 1.373449, t_loss = 1.547061, and v_loss = 0.346000 at lr = 0.073440\n",
            "Trial 77 epoch 4 got t_acc = 0.456554, v_acc = 1.337401, t_loss = 1.538312, and v_loss = 0.354000 at lr = 0.073440\n",
            "Trial 77 epoch 5 got t_acc = 0.472285, v_acc = 1.305634, t_loss = 1.530683, and v_loss = 0.346000 at lr = 0.073440\n",
            "Trial 77 epoch 6 got t_acc = 0.484270, v_acc = 1.277169, t_loss = 1.524351, and v_loss = 0.354000 at lr = 0.073440\n",
            "Trial 77 epoch 7 got t_acc = 0.499251, v_acc = 1.251636, t_loss = 1.519002, and v_loss = 0.350000 at lr = 0.073440\n",
            "Trial 77 epoch 8 got t_acc = 0.512734, v_acc = 1.228359, t_loss = 1.514854, and v_loss = 0.356000 at lr = 0.073440\n",
            "Trial 77 epoch 9 got t_acc = 0.522472, v_acc = 1.206881, t_loss = 1.510870, and v_loss = 0.362000 at lr = 0.073440\n",
            "Trial 78 epoch 0 got t_acc = 0.173034, v_acc = 1.714846, t_loss = 1.625930, and v_loss = 0.182000 at lr = 0.000858\n",
            "Trial 78 epoch 1 got t_acc = 0.174157, v_acc = 1.711213, t_loss = 1.625198, and v_loss = 0.180000 at lr = 0.000858\n",
            "Trial 78 epoch 2 got t_acc = 0.175281, v_acc = 1.707645, t_loss = 1.624477, and v_loss = 0.180000 at lr = 0.000858\n",
            "Trial 78 epoch 3 got t_acc = 0.177154, v_acc = 1.704140, t_loss = 1.623764, and v_loss = 0.180000 at lr = 0.000858\n",
            "Trial 78 epoch 4 got t_acc = 0.178277, v_acc = 1.700700, t_loss = 1.623057, and v_loss = 0.180000 at lr = 0.000858\n",
            "Trial 78 epoch 5 got t_acc = 0.180524, v_acc = 1.697323, t_loss = 1.622358, and v_loss = 0.178000 at lr = 0.000858\n",
            "Trial 78 epoch 6 got t_acc = 0.183146, v_acc = 1.694007, t_loss = 1.621670, and v_loss = 0.178000 at lr = 0.000858\n",
            "Trial 78 epoch 7 got t_acc = 0.183521, v_acc = 1.690754, t_loss = 1.620992, and v_loss = 0.178000 at lr = 0.000858\n",
            "Trial 78 epoch 8 got t_acc = 0.184644, v_acc = 1.687562, t_loss = 1.620324, and v_loss = 0.178000 at lr = 0.000858\n",
            "Trial 78 epoch 9 got t_acc = 0.185393, v_acc = 1.684429, t_loss = 1.619666, and v_loss = 0.182000 at lr = 0.000858\n",
            "Trial 79 epoch 0 got t_acc = 0.198502, v_acc = 1.714606, t_loss = 1.630816, and v_loss = 0.210000 at lr = 0.000766\n",
            "Trial 79 epoch 1 got t_acc = 0.199625, v_acc = 1.711270, t_loss = 1.629381, and v_loss = 0.208000 at lr = 0.000766\n",
            "Trial 79 epoch 2 got t_acc = 0.201124, v_acc = 1.708020, t_loss = 1.628009, and v_loss = 0.210000 at lr = 0.000766\n",
            "Trial 79 epoch 3 got t_acc = 0.202247, v_acc = 1.704849, t_loss = 1.626690, and v_loss = 0.214000 at lr = 0.000766\n",
            "Trial 79 epoch 4 got t_acc = 0.203371, v_acc = 1.701756, t_loss = 1.625428, and v_loss = 0.216000 at lr = 0.000766\n",
            "Trial 79 epoch 5 got t_acc = 0.204120, v_acc = 1.698735, t_loss = 1.624212, and v_loss = 0.222000 at lr = 0.000766\n",
            "Trial 79 epoch 6 got t_acc = 0.205618, v_acc = 1.695785, t_loss = 1.623040, and v_loss = 0.224000 at lr = 0.000766\n",
            "Trial 79 epoch 7 got t_acc = 0.206367, v_acc = 1.692902, t_loss = 1.621910, and v_loss = 0.222000 at lr = 0.000766\n",
            "Trial 79 epoch 8 got t_acc = 0.207491, v_acc = 1.690078, t_loss = 1.620818, and v_loss = 0.230000 at lr = 0.000766\n",
            "Trial 79 epoch 9 got t_acc = 0.208614, v_acc = 1.687312, t_loss = 1.619761, and v_loss = 0.228000 at lr = 0.000766\n",
            "Trial 80 epoch 0 got t_acc = 0.193633, v_acc = 1.657083, t_loss = 1.623997, and v_loss = 0.200000 at lr = 0.005998\n",
            "Trial 80 epoch 1 got t_acc = 0.204120, v_acc = 1.641270, t_loss = 1.619068, and v_loss = 0.198000 at lr = 0.005998\n",
            "Trial 80 epoch 2 got t_acc = 0.217603, v_acc = 1.626973, t_loss = 1.614685, and v_loss = 0.196000 at lr = 0.005998\n",
            "Trial 80 epoch 3 got t_acc = 0.228464, v_acc = 1.613967, t_loss = 1.610716, and v_loss = 0.202000 at lr = 0.005998\n",
            "Trial 80 epoch 4 got t_acc = 0.244195, v_acc = 1.602038, t_loss = 1.607084, and v_loss = 0.206000 at lr = 0.005998\n",
            "Trial 80 epoch 5 got t_acc = 0.249813, v_acc = 1.591013, t_loss = 1.603712, and v_loss = 0.210000 at lr = 0.005998\n",
            "Trial 80 epoch 6 got t_acc = 0.258427, v_acc = 1.580779, t_loss = 1.600568, and v_loss = 0.234000 at lr = 0.005998\n",
            "Trial 80 epoch 7 got t_acc = 0.271161, v_acc = 1.571198, t_loss = 1.597631, and v_loss = 0.232000 at lr = 0.005998\n",
            "Trial 80 epoch 8 got t_acc = 0.279775, v_acc = 1.562173, t_loss = 1.594849, and v_loss = 0.236000 at lr = 0.005998\n",
            "Trial 80 epoch 9 got t_acc = 0.292135, v_acc = 1.553653, t_loss = 1.592204, and v_loss = 0.260000 at lr = 0.005998\n",
            "Trial 81 epoch 0 got t_acc = 0.300000, v_acc = 1.556218, t_loss = 1.578980, and v_loss = 0.254000 at lr = 0.040032\n",
            "Trial 81 epoch 1 got t_acc = 0.344569, v_acc = 1.497255, t_loss = 1.565404, and v_loss = 0.324000 at lr = 0.040032\n",
            "Trial 81 epoch 2 got t_acc = 0.377154, v_acc = 1.452694, t_loss = 1.554186, and v_loss = 0.330000 at lr = 0.040032\n",
            "Trial 81 epoch 3 got t_acc = 0.404869, v_acc = 1.415940, t_loss = 1.544298, and v_loss = 0.372000 at lr = 0.040032\n",
            "Trial 81 epoch 4 got t_acc = 0.422846, v_acc = 1.384476, t_loss = 1.536129, and v_loss = 0.360000 at lr = 0.040032\n",
            "Trial 81 epoch 5 got t_acc = 0.441948, v_acc = 1.357032, t_loss = 1.529218, and v_loss = 0.368000 at lr = 0.040032\n",
            "Trial 81 epoch 6 got t_acc = 0.457678, v_acc = 1.332595, t_loss = 1.523216, and v_loss = 0.372000 at lr = 0.040032\n",
            "Trial 81 epoch 7 got t_acc = 0.470787, v_acc = 1.310511, t_loss = 1.518032, and v_loss = 0.368000 at lr = 0.040032\n",
            "Trial 81 epoch 8 got t_acc = 0.485393, v_acc = 1.290300, t_loss = 1.513696, and v_loss = 0.368000 at lr = 0.040032\n",
            "Trial 81 epoch 9 got t_acc = 0.499251, v_acc = 1.271704, t_loss = 1.510087, and v_loss = 0.370000 at lr = 0.040032\n",
            "Trial 82 epoch 0 got t_acc = 0.226592, v_acc = 1.677336, t_loss = 1.625667, and v_loss = 0.178000 at lr = 0.002133\n",
            "Trial 82 epoch 1 got t_acc = 0.227715, v_acc = 1.672906, t_loss = 1.624765, and v_loss = 0.184000 at lr = 0.002133\n",
            "Trial 82 epoch 2 got t_acc = 0.227715, v_acc = 1.668558, t_loss = 1.623889, and v_loss = 0.186000 at lr = 0.002133\n",
            "Trial 82 epoch 3 got t_acc = 0.228839, v_acc = 1.664300, t_loss = 1.623037, and v_loss = 0.186000 at lr = 0.002133\n",
            "Trial 82 epoch 4 got t_acc = 0.234082, v_acc = 1.660130, t_loss = 1.622206, and v_loss = 0.186000 at lr = 0.002133\n",
            "Trial 82 epoch 5 got t_acc = 0.235206, v_acc = 1.656037, t_loss = 1.621393, and v_loss = 0.184000 at lr = 0.002133\n",
            "Trial 82 epoch 6 got t_acc = 0.235581, v_acc = 1.652012, t_loss = 1.620589, and v_loss = 0.184000 at lr = 0.002133\n",
            "Trial 82 epoch 7 got t_acc = 0.237079, v_acc = 1.648058, t_loss = 1.619809, and v_loss = 0.182000 at lr = 0.002133\n",
            "Trial 82 epoch 8 got t_acc = 0.239326, v_acc = 1.644166, t_loss = 1.619048, and v_loss = 0.184000 at lr = 0.002133\n",
            "Trial 82 epoch 9 got t_acc = 0.242322, v_acc = 1.640331, t_loss = 1.618305, and v_loss = 0.188000 at lr = 0.002133\n",
            "Trial 83 epoch 0 got t_acc = 0.221348, v_acc = 1.647041, t_loss = 1.638702, and v_loss = 0.162000 at lr = 0.020021\n",
            "Trial 83 epoch 1 got t_acc = 0.258801, v_acc = 1.607950, t_loss = 1.623093, and v_loss = 0.182000 at lr = 0.020021\n",
            "Trial 83 epoch 2 got t_acc = 0.288764, v_acc = 1.575547, t_loss = 1.610570, and v_loss = 0.206000 at lr = 0.020021\n",
            "Trial 83 epoch 3 got t_acc = 0.314607, v_acc = 1.547948, t_loss = 1.600197, and v_loss = 0.234000 at lr = 0.020021\n",
            "Trial 83 epoch 4 got t_acc = 0.335581, v_acc = 1.523791, t_loss = 1.591500, and v_loss = 0.244000 at lr = 0.020021\n",
            "Trial 83 epoch 5 got t_acc = 0.354682, v_acc = 1.502288, t_loss = 1.584138, and v_loss = 0.262000 at lr = 0.020021\n",
            "Trial 83 epoch 6 got t_acc = 0.372285, v_acc = 1.482860, t_loss = 1.577730, and v_loss = 0.268000 at lr = 0.020021\n",
            "Trial 83 epoch 7 got t_acc = 0.383895, v_acc = 1.465002, t_loss = 1.572165, and v_loss = 0.274000 at lr = 0.020021\n",
            "Trial 83 epoch 8 got t_acc = 0.398876, v_acc = 1.448354, t_loss = 1.567159, and v_loss = 0.288000 at lr = 0.020021\n",
            "Trial 83 epoch 9 got t_acc = 0.411985, v_acc = 1.432720, t_loss = 1.562606, and v_loss = 0.298000 at lr = 0.020021\n",
            "Trial 84 epoch 0 got t_acc = 0.221348, v_acc = 1.639932, t_loss = 1.612372, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 1 got t_acc = 0.223221, v_acc = 1.639162, t_loss = 1.612131, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 2 got t_acc = 0.223221, v_acc = 1.638396, t_loss = 1.611891, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 3 got t_acc = 0.223596, v_acc = 1.637632, t_loss = 1.611651, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 4 got t_acc = 0.224719, v_acc = 1.636872, t_loss = 1.611413, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 5 got t_acc = 0.225468, v_acc = 1.636114, t_loss = 1.611176, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 6 got t_acc = 0.226966, v_acc = 1.635358, t_loss = 1.610940, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 7 got t_acc = 0.226966, v_acc = 1.634605, t_loss = 1.610706, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 8 got t_acc = 0.226966, v_acc = 1.633856, t_loss = 1.610474, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 84 epoch 9 got t_acc = 0.227715, v_acc = 1.633111, t_loss = 1.610242, and v_loss = 0.224000 at lr = 0.000394\n",
            "Trial 85 epoch 0 got t_acc = 0.193633, v_acc = 1.695973, t_loss = 1.630333, and v_loss = 0.184000 at lr = 0.001548\n",
            "Trial 85 epoch 1 got t_acc = 0.196255, v_acc = 1.691744, t_loss = 1.629134, and v_loss = 0.184000 at lr = 0.001548\n",
            "Trial 85 epoch 2 got t_acc = 0.197004, v_acc = 1.687600, t_loss = 1.627958, and v_loss = 0.184000 at lr = 0.001548\n",
            "Trial 85 epoch 3 got t_acc = 0.198876, v_acc = 1.683531, t_loss = 1.626802, and v_loss = 0.188000 at lr = 0.001548\n",
            "Trial 85 epoch 4 got t_acc = 0.200375, v_acc = 1.679545, t_loss = 1.625670, and v_loss = 0.190000 at lr = 0.001548\n",
            "Trial 85 epoch 5 got t_acc = 0.200749, v_acc = 1.675639, t_loss = 1.624564, and v_loss = 0.192000 at lr = 0.001548\n",
            "Trial 85 epoch 6 got t_acc = 0.204120, v_acc = 1.671809, t_loss = 1.623482, and v_loss = 0.190000 at lr = 0.001548\n",
            "Trial 85 epoch 7 got t_acc = 0.206367, v_acc = 1.668053, t_loss = 1.622425, and v_loss = 0.192000 at lr = 0.001548\n",
            "Trial 85 epoch 8 got t_acc = 0.209738, v_acc = 1.664361, t_loss = 1.621386, and v_loss = 0.192000 at lr = 0.001548\n",
            "Trial 85 epoch 9 got t_acc = 0.212360, v_acc = 1.660743, t_loss = 1.620370, and v_loss = 0.192000 at lr = 0.001548\n",
            "Trial 86 epoch 0 got t_acc = 0.183146, v_acc = 1.708767, t_loss = 1.611980, and v_loss = 0.244000 at lr = 0.000240\n",
            "Trial 86 epoch 1 got t_acc = 0.184270, v_acc = 1.708063, t_loss = 1.611861, and v_loss = 0.244000 at lr = 0.000240\n",
            "Trial 86 epoch 2 got t_acc = 0.185019, v_acc = 1.707360, t_loss = 1.611742, and v_loss = 0.244000 at lr = 0.000240\n",
            "Trial 86 epoch 3 got t_acc = 0.185768, v_acc = 1.706660, t_loss = 1.611623, and v_loss = 0.244000 at lr = 0.000240\n",
            "Trial 86 epoch 4 got t_acc = 0.185768, v_acc = 1.705963, t_loss = 1.611504, and v_loss = 0.244000 at lr = 0.000240\n",
            "Trial 86 epoch 5 got t_acc = 0.185393, v_acc = 1.705268, t_loss = 1.611386, and v_loss = 0.242000 at lr = 0.000240\n",
            "Trial 86 epoch 6 got t_acc = 0.185768, v_acc = 1.704575, t_loss = 1.611268, and v_loss = 0.242000 at lr = 0.000240\n",
            "Trial 86 epoch 7 got t_acc = 0.185768, v_acc = 1.703884, t_loss = 1.611150, and v_loss = 0.242000 at lr = 0.000240\n",
            "Trial 86 epoch 8 got t_acc = 0.185768, v_acc = 1.703196, t_loss = 1.611032, and v_loss = 0.242000 at lr = 0.000240\n",
            "Trial 86 epoch 9 got t_acc = 0.185768, v_acc = 1.702510, t_loss = 1.610914, and v_loss = 0.242000 at lr = 0.000240\n",
            "Trial 87 epoch 0 got t_acc = 0.216854, v_acc = 1.685271, t_loss = 1.607748, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 1 got t_acc = 0.217603, v_acc = 1.684997, t_loss = 1.607653, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 2 got t_acc = 0.217228, v_acc = 1.684722, t_loss = 1.607559, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 3 got t_acc = 0.217228, v_acc = 1.684449, t_loss = 1.607465, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 4 got t_acc = 0.217603, v_acc = 1.684175, t_loss = 1.607371, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 5 got t_acc = 0.217978, v_acc = 1.683902, t_loss = 1.607277, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 6 got t_acc = 0.218352, v_acc = 1.683630, t_loss = 1.607184, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 7 got t_acc = 0.218352, v_acc = 1.683357, t_loss = 1.607091, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 8 got t_acc = 0.217978, v_acc = 1.683086, t_loss = 1.606998, and v_loss = 0.196000 at lr = 0.000120\n",
            "Trial 87 epoch 9 got t_acc = 0.217978, v_acc = 1.682814, t_loss = 1.606905, and v_loss = 0.198000 at lr = 0.000120\n",
            "Trial 88 epoch 0 got t_acc = 0.307865, v_acc = 1.538568, t_loss = 1.572738, and v_loss = 0.280000 at lr = 0.083290\n",
            "Trial 88 epoch 1 got t_acc = 0.383146, v_acc = 1.446619, t_loss = 1.558661, and v_loss = 0.282000 at lr = 0.083290\n",
            "Trial 88 epoch 2 got t_acc = 0.415730, v_acc = 1.384848, t_loss = 1.541363, and v_loss = 0.314000 at lr = 0.083290\n",
            "Trial 88 epoch 3 got t_acc = 0.450936, v_acc = 1.337485, t_loss = 1.532688, and v_loss = 0.326000 at lr = 0.083290\n",
            "Trial 88 epoch 4 got t_acc = 0.469288, v_acc = 1.298405, t_loss = 1.523151, and v_loss = 0.334000 at lr = 0.083290\n",
            "Trial 88 epoch 5 got t_acc = 0.492509, v_acc = 1.264900, t_loss = 1.517809, and v_loss = 0.340000 at lr = 0.083290\n",
            "Trial 88 epoch 6 got t_acc = 0.506742, v_acc = 1.235460, t_loss = 1.511402, and v_loss = 0.336000 at lr = 0.083290\n",
            "Trial 88 epoch 7 got t_acc = 0.519101, v_acc = 1.209280, t_loss = 1.507301, and v_loss = 0.344000 at lr = 0.083290\n",
            "Trial 88 epoch 8 got t_acc = 0.538577, v_acc = 1.185780, t_loss = 1.501852, and v_loss = 0.348000 at lr = 0.083290\n",
            "Trial 88 epoch 9 got t_acc = 0.549438, v_acc = 1.164143, t_loss = 1.498349, and v_loss = 0.348000 at lr = 0.083290\n",
            "Trial 89 epoch 0 got t_acc = 0.240449, v_acc = 1.666626, t_loss = 1.614359, and v_loss = 0.250000 at lr = 0.001967\n",
            "Trial 89 epoch 1 got t_acc = 0.242697, v_acc = 1.662140, t_loss = 1.613065, and v_loss = 0.252000 at lr = 0.001967\n",
            "Trial 89 epoch 2 got t_acc = 0.243820, v_acc = 1.657751, t_loss = 1.611799, and v_loss = 0.252000 at lr = 0.001967\n",
            "Trial 89 epoch 3 got t_acc = 0.246816, v_acc = 1.653460, t_loss = 1.610562, and v_loss = 0.254000 at lr = 0.001967\n",
            "Trial 89 epoch 4 got t_acc = 0.249813, v_acc = 1.649262, t_loss = 1.609356, and v_loss = 0.254000 at lr = 0.001967\n",
            "Trial 89 epoch 5 got t_acc = 0.250562, v_acc = 1.645156, t_loss = 1.608177, and v_loss = 0.254000 at lr = 0.001967\n",
            "Trial 89 epoch 6 got t_acc = 0.252809, v_acc = 1.641141, t_loss = 1.607028, and v_loss = 0.252000 at lr = 0.001967\n",
            "Trial 89 epoch 7 got t_acc = 0.253558, v_acc = 1.637212, t_loss = 1.605905, and v_loss = 0.252000 at lr = 0.001967\n",
            "Trial 89 epoch 8 got t_acc = 0.255805, v_acc = 1.633361, t_loss = 1.604805, and v_loss = 0.250000 at lr = 0.001967\n",
            "Trial 89 epoch 9 got t_acc = 0.257303, v_acc = 1.629589, t_loss = 1.603728, and v_loss = 0.252000 at lr = 0.001967\n",
            "Trial 90 epoch 0 got t_acc = 0.257303, v_acc = 1.580696, t_loss = 1.590101, and v_loss = 0.268000 at lr = 0.037208\n",
            "Trial 90 epoch 1 got t_acc = 0.314607, v_acc = 1.531436, t_loss = 1.578753, and v_loss = 0.320000 at lr = 0.037208\n",
            "Trial 90 epoch 2 got t_acc = 0.347566, v_acc = 1.493570, t_loss = 1.568874, and v_loss = 0.352000 at lr = 0.037208\n",
            "Trial 90 epoch 3 got t_acc = 0.368165, v_acc = 1.461503, t_loss = 1.560419, and v_loss = 0.360000 at lr = 0.037208\n",
            "Trial 90 epoch 4 got t_acc = 0.387266, v_acc = 1.433339, t_loss = 1.553011, and v_loss = 0.366000 at lr = 0.037208\n",
            "Trial 90 epoch 5 got t_acc = 0.402622, v_acc = 1.408337, t_loss = 1.546674, and v_loss = 0.370000 at lr = 0.037208\n",
            "Trial 90 epoch 6 got t_acc = 0.424719, v_acc = 1.385661, t_loss = 1.541233, and v_loss = 0.368000 at lr = 0.037208\n",
            "Trial 90 epoch 7 got t_acc = 0.432210, v_acc = 1.364838, t_loss = 1.536486, and v_loss = 0.360000 at lr = 0.037208\n",
            "Trial 90 epoch 8 got t_acc = 0.442697, v_acc = 1.345439, t_loss = 1.532518, and v_loss = 0.360000 at lr = 0.037208\n",
            "Trial 90 epoch 9 got t_acc = 0.456554, v_acc = 1.327492, t_loss = 1.528801, and v_loss = 0.352000 at lr = 0.037208\n",
            "Trial 91 epoch 0 got t_acc = 0.188390, v_acc = 1.680253, t_loss = 1.603588, and v_loss = 0.216000 at lr = 0.000751\n",
            "Trial 91 epoch 1 got t_acc = 0.187640, v_acc = 1.678511, t_loss = 1.603267, and v_loss = 0.222000 at lr = 0.000751\n",
            "Trial 91 epoch 2 got t_acc = 0.189888, v_acc = 1.676782, t_loss = 1.602949, and v_loss = 0.224000 at lr = 0.000751\n",
            "Trial 91 epoch 3 got t_acc = 0.190637, v_acc = 1.675065, t_loss = 1.602635, and v_loss = 0.224000 at lr = 0.000751\n",
            "Trial 91 epoch 4 got t_acc = 0.191386, v_acc = 1.673360, t_loss = 1.602322, and v_loss = 0.224000 at lr = 0.000751\n",
            "Trial 91 epoch 5 got t_acc = 0.191386, v_acc = 1.671664, t_loss = 1.602012, and v_loss = 0.224000 at lr = 0.000751\n",
            "Trial 91 epoch 6 got t_acc = 0.193633, v_acc = 1.669979, t_loss = 1.601705, and v_loss = 0.224000 at lr = 0.000751\n",
            "Trial 91 epoch 7 got t_acc = 0.194757, v_acc = 1.668305, t_loss = 1.601400, and v_loss = 0.226000 at lr = 0.000751\n",
            "Trial 91 epoch 8 got t_acc = 0.196255, v_acc = 1.666643, t_loss = 1.601099, and v_loss = 0.226000 at lr = 0.000751\n",
            "Trial 91 epoch 9 got t_acc = 0.196629, v_acc = 1.664989, t_loss = 1.600799, and v_loss = 0.228000 at lr = 0.000751\n",
            "Trial 92 epoch 0 got t_acc = 0.177154, v_acc = 1.689050, t_loss = 1.626586, and v_loss = 0.174000 at lr = 0.004061\n",
            "Trial 92 epoch 1 got t_acc = 0.185393, v_acc = 1.677396, t_loss = 1.622069, and v_loss = 0.172000 at lr = 0.004061\n",
            "Trial 92 epoch 2 got t_acc = 0.190637, v_acc = 1.666494, t_loss = 1.617992, and v_loss = 0.168000 at lr = 0.004061\n",
            "Trial 92 epoch 3 got t_acc = 0.194757, v_acc = 1.656258, t_loss = 1.614280, and v_loss = 0.174000 at lr = 0.004061\n",
            "Trial 92 epoch 4 got t_acc = 0.200749, v_acc = 1.646640, t_loss = 1.610866, and v_loss = 0.182000 at lr = 0.004061\n",
            "Trial 92 epoch 5 got t_acc = 0.210861, v_acc = 1.637582, t_loss = 1.607719, and v_loss = 0.182000 at lr = 0.004061\n",
            "Trial 92 epoch 6 got t_acc = 0.219101, v_acc = 1.629012, t_loss = 1.604819, and v_loss = 0.184000 at lr = 0.004061\n",
            "Trial 92 epoch 7 got t_acc = 0.225843, v_acc = 1.620880, t_loss = 1.602128, and v_loss = 0.196000 at lr = 0.004061\n",
            "Trial 92 epoch 8 got t_acc = 0.232584, v_acc = 1.613146, t_loss = 1.599624, and v_loss = 0.204000 at lr = 0.004061\n",
            "Trial 92 epoch 9 got t_acc = 0.237079, v_acc = 1.605760, t_loss = 1.597269, and v_loss = 0.208000 at lr = 0.004061\n",
            "Trial 93 epoch 0 got t_acc = 0.205243, v_acc = 1.697747, t_loss = 1.625747, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 1 got t_acc = 0.205243, v_acc = 1.697356, t_loss = 1.625667, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 2 got t_acc = 0.205618, v_acc = 1.696966, t_loss = 1.625587, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 3 got t_acc = 0.205993, v_acc = 1.696578, t_loss = 1.625508, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 4 got t_acc = 0.206367, v_acc = 1.696190, t_loss = 1.625429, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 5 got t_acc = 0.205993, v_acc = 1.695803, t_loss = 1.625350, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 6 got t_acc = 0.205993, v_acc = 1.695417, t_loss = 1.625271, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 7 got t_acc = 0.206367, v_acc = 1.695032, t_loss = 1.625192, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 8 got t_acc = 0.207116, v_acc = 1.694648, t_loss = 1.625114, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 93 epoch 9 got t_acc = 0.207116, v_acc = 1.694266, t_loss = 1.625036, and v_loss = 0.260000 at lr = 0.000136\n",
            "Trial 94 epoch 0 got t_acc = 0.217978, v_acc = 1.693891, t_loss = 1.624331, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 1 got t_acc = 0.220599, v_acc = 1.691491, t_loss = 1.623646, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 2 got t_acc = 0.220599, v_acc = 1.689131, t_loss = 1.622983, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 3 got t_acc = 0.220974, v_acc = 1.686807, t_loss = 1.622335, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 4 got t_acc = 0.221723, v_acc = 1.684520, t_loss = 1.621707, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 5 got t_acc = 0.222472, v_acc = 1.682270, t_loss = 1.621098, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 6 got t_acc = 0.223596, v_acc = 1.680055, t_loss = 1.620506, and v_loss = 0.234000 at lr = 0.000878\n",
            "Trial 94 epoch 7 got t_acc = 0.224719, v_acc = 1.677872, t_loss = 1.619933, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 8 got t_acc = 0.223970, v_acc = 1.675721, t_loss = 1.619377, and v_loss = 0.236000 at lr = 0.000878\n",
            "Trial 94 epoch 9 got t_acc = 0.225468, v_acc = 1.673601, t_loss = 1.618840, and v_loss = 0.234000 at lr = 0.000878\n",
            "Trial 95 epoch 0 got t_acc = 0.176030, v_acc = 1.706931, t_loss = 1.648728, and v_loss = 0.174000 at lr = 0.003205\n",
            "Trial 95 epoch 1 got t_acc = 0.182022, v_acc = 1.695252, t_loss = 1.645770, and v_loss = 0.174000 at lr = 0.003205\n",
            "Trial 95 epoch 2 got t_acc = 0.187266, v_acc = 1.684282, t_loss = 1.642922, and v_loss = 0.178000 at lr = 0.003205\n",
            "Trial 95 epoch 3 got t_acc = 0.194007, v_acc = 1.673922, t_loss = 1.640186, and v_loss = 0.182000 at lr = 0.003205\n",
            "Trial 95 epoch 4 got t_acc = 0.202996, v_acc = 1.664146, t_loss = 1.637545, and v_loss = 0.186000 at lr = 0.003205\n",
            "Trial 95 epoch 5 got t_acc = 0.206367, v_acc = 1.654895, t_loss = 1.634998, and v_loss = 0.190000 at lr = 0.003205\n",
            "Trial 95 epoch 6 got t_acc = 0.210487, v_acc = 1.646094, t_loss = 1.632516, and v_loss = 0.188000 at lr = 0.003205\n",
            "Trial 95 epoch 7 got t_acc = 0.217978, v_acc = 1.637685, t_loss = 1.630108, and v_loss = 0.182000 at lr = 0.003205\n",
            "Trial 95 epoch 8 got t_acc = 0.222846, v_acc = 1.629676, t_loss = 1.627777, and v_loss = 0.184000 at lr = 0.003205\n",
            "Trial 95 epoch 9 got t_acc = 0.232959, v_acc = 1.622011, t_loss = 1.625530, and v_loss = 0.182000 at lr = 0.003205\n",
            "Trial 96 epoch 0 got t_acc = 0.167041, v_acc = 1.850739, t_loss = 1.688250, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 1 got t_acc = 0.167041, v_acc = 1.849174, t_loss = 1.687590, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 2 got t_acc = 0.167041, v_acc = 1.847618, t_loss = 1.686936, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 3 got t_acc = 0.167041, v_acc = 1.846071, t_loss = 1.686287, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 4 got t_acc = 0.167041, v_acc = 1.844533, t_loss = 1.685646, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 5 got t_acc = 0.167416, v_acc = 1.843004, t_loss = 1.685012, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 6 got t_acc = 0.167790, v_acc = 1.841484, t_loss = 1.684385, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 7 got t_acc = 0.167790, v_acc = 1.839974, t_loss = 1.683764, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 8 got t_acc = 0.168165, v_acc = 1.838476, t_loss = 1.683152, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 96 epoch 9 got t_acc = 0.168165, v_acc = 1.836988, t_loss = 1.682547, and v_loss = 0.182000 at lr = 0.000209\n",
            "Trial 97 epoch 0 got t_acc = 0.212734, v_acc = 1.688080, t_loss = 1.650531, and v_loss = 0.184000 at lr = 0.001961\n",
            "Trial 97 epoch 1 got t_acc = 0.213858, v_acc = 1.683967, t_loss = 1.648328, and v_loss = 0.188000 at lr = 0.001961\n",
            "Trial 97 epoch 2 got t_acc = 0.217603, v_acc = 1.679944, t_loss = 1.646187, and v_loss = 0.188000 at lr = 0.001961\n",
            "Trial 97 epoch 3 got t_acc = 0.219476, v_acc = 1.675997, t_loss = 1.644094, and v_loss = 0.190000 at lr = 0.001961\n",
            "Trial 97 epoch 4 got t_acc = 0.220974, v_acc = 1.672121, t_loss = 1.642048, and v_loss = 0.192000 at lr = 0.001961\n",
            "Trial 97 epoch 5 got t_acc = 0.223596, v_acc = 1.668331, t_loss = 1.640052, and v_loss = 0.192000 at lr = 0.001961\n",
            "Trial 97 epoch 6 got t_acc = 0.227341, v_acc = 1.664614, t_loss = 1.638117, and v_loss = 0.196000 at lr = 0.001961\n",
            "Trial 97 epoch 7 got t_acc = 0.229213, v_acc = 1.660957, t_loss = 1.636232, and v_loss = 0.192000 at lr = 0.001961\n",
            "Trial 97 epoch 8 got t_acc = 0.231835, v_acc = 1.657360, t_loss = 1.634391, and v_loss = 0.194000 at lr = 0.001961\n",
            "Trial 97 epoch 9 got t_acc = 0.234831, v_acc = 1.653828, t_loss = 1.632598, and v_loss = 0.200000 at lr = 0.001961\n",
            "Trial 98 epoch 0 got t_acc = 0.202996, v_acc = 1.699078, t_loss = 1.617582, and v_loss = 0.212000 at lr = 0.001012\n",
            "Trial 98 epoch 1 got t_acc = 0.202622, v_acc = 1.696701, t_loss = 1.617227, and v_loss = 0.212000 at lr = 0.001012\n",
            "Trial 98 epoch 2 got t_acc = 0.204869, v_acc = 1.694352, t_loss = 1.616877, and v_loss = 0.212000 at lr = 0.001012\n",
            "Trial 98 epoch 3 got t_acc = 0.205993, v_acc = 1.692030, t_loss = 1.616532, and v_loss = 0.210000 at lr = 0.001012\n",
            "Trial 98 epoch 4 got t_acc = 0.206367, v_acc = 1.689734, t_loss = 1.616188, and v_loss = 0.212000 at lr = 0.001012\n",
            "Trial 98 epoch 5 got t_acc = 0.208240, v_acc = 1.687467, t_loss = 1.615845, and v_loss = 0.212000 at lr = 0.001012\n",
            "Trial 98 epoch 6 got t_acc = 0.209738, v_acc = 1.685226, t_loss = 1.615508, and v_loss = 0.210000 at lr = 0.001012\n",
            "Trial 98 epoch 7 got t_acc = 0.211985, v_acc = 1.683009, t_loss = 1.615174, and v_loss = 0.210000 at lr = 0.001012\n",
            "Trial 98 epoch 8 got t_acc = 0.213109, v_acc = 1.680817, t_loss = 1.614842, and v_loss = 0.206000 at lr = 0.001012\n",
            "Trial 98 epoch 9 got t_acc = 0.212734, v_acc = 1.678648, t_loss = 1.614512, and v_loss = 0.206000 at lr = 0.001012\n",
            "Trial 99 epoch 0 got t_acc = 0.210861, v_acc = 1.682841, t_loss = 1.637479, and v_loss = 0.170000 at lr = 0.005228\n",
            "Trial 99 epoch 1 got t_acc = 0.220599, v_acc = 1.669376, t_loss = 1.632149, and v_loss = 0.172000 at lr = 0.005228\n",
            "Trial 99 epoch 2 got t_acc = 0.226217, v_acc = 1.656757, t_loss = 1.627311, and v_loss = 0.170000 at lr = 0.005228\n",
            "Trial 99 epoch 3 got t_acc = 0.234082, v_acc = 1.644881, t_loss = 1.622913, and v_loss = 0.184000 at lr = 0.005228\n",
            "Trial 99 epoch 4 got t_acc = 0.242322, v_acc = 1.633687, t_loss = 1.618898, and v_loss = 0.182000 at lr = 0.005228\n",
            "Trial 99 epoch 5 got t_acc = 0.248689, v_acc = 1.623072, t_loss = 1.615186, and v_loss = 0.180000 at lr = 0.005228\n",
            "Trial 99 epoch 6 got t_acc = 0.255431, v_acc = 1.613000, t_loss = 1.611748, and v_loss = 0.180000 at lr = 0.005228\n",
            "Trial 99 epoch 7 got t_acc = 0.262547, v_acc = 1.603383, t_loss = 1.608529, and v_loss = 0.190000 at lr = 0.005228\n",
            "Trial 99 epoch 8 got t_acc = 0.270412, v_acc = 1.594172, t_loss = 1.605508, and v_loss = 0.202000 at lr = 0.005228\n",
            "Trial 99 epoch 9 got t_acc = 0.278277, v_acc = 1.585356, t_loss = 1.602666, and v_loss = 0.206000 at lr = 0.005228\n",
            "\n",
            "Got highest train accuracy = 0.553184 at lr = 0.080457\n",
            "Got highest val accuracy = 0.390000 at lr = 0.044230\n",
            "Got lowest train loss = 1.164143 at lr = 0.083290\n",
            "Got lowest val loss = 1.491793 at lr = 0.084230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u_qfDg0ApDE",
        "outputId": "2248f014-7474-46ea-9139-d2db1b56de0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "lr=0.044230\n",
        "\n",
        "train_log = []\n",
        "val_log = []\n",
        "losses = []\n",
        "train_count = []\n",
        "counter = 0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "NN = []\n",
        "NN.append(weights_layer(X_TRAIN.shape[1],200,lr))\n",
        "NN.append(ReLU())\n",
        "NN.append(weights_layer(200,200,lr))\n",
        "NN.append(ReLU())\n",
        "NN.append(weights_layer(200,5,lr))\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    for x_batch,y_batch in iterate_minibatches(X_TRAIN,Y_TRAIN,batchsize=2536,shuffle=True):\n",
        "        train(NN,x_batch,y_batch)\n",
        "\n",
        "    #train(NN,X_TRAIN,Y_TRAIN)\n",
        "\n",
        "    train_predictions, train_loss = predict(NN,X_TRAIN, Y_TRAIN)\n",
        "\n",
        "    val_predictions, val_loss = predict(NN,X_VAL, Y_VAL)\n",
        "\n",
        "    train_log.append(np.mean(train_predictions==Y_TRAIN))\n",
        "\n",
        "    val_log.append(np.mean(val_predictions==Y_VAL))\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\"Ran epoch %d and got train accuracy = %f and val accuracy = %f\" % (epoch, train_log[-1], val_log[-1]))\n",
        "\n",
        "print()\n",
        "plt.plot(train_log,label='train accuracy')\n",
        "plt.plot(val_log,label='val accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_losses, label=\"Train losses\") \n",
        "\n",
        "plt.plot(val_losses, label=\"Val losses\") \n",
        "\n",
        "lowest_train_loss, lowest_val_loss = min(train_losses) , min(val_losses)\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.legend() \n",
        "\n",
        "lowest_x = val_losses.index(lowest_val_loss)\n",
        "\n",
        "plt.show() \n",
        "\n",
        "print()\n",
        "print(\"For Q4,\")\n",
        "print(\"Best train accuracy:\",max(train_log))\n",
        "print(\"Best val accuracy:\",max(val_log))\n",
        "print('Lowest Train Loss is ' + str(lowest_train_loss))\n",
        "print('Lowest Val Loss is ' + str(lowest_val_loss))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 185.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 169.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 185.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 0 and got train accuracy = 0.262172 and val accuracy = 0.240000\n",
            "Ran epoch 1 and got train accuracy = 0.314981 and val accuracy = 0.274000\n",
            "Ran epoch 2 and got train accuracy = 0.350936 and val accuracy = 0.292000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 197.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 376.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 268.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 3 and got train accuracy = 0.378652 and val accuracy = 0.312000\n",
            "Ran epoch 4 and got train accuracy = 0.395131 and val accuracy = 0.322000\n",
            "Ran epoch 5 and got train accuracy = 0.413483 and val accuracy = 0.326000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 265.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 170.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 6 and got train accuracy = 0.432584 and val accuracy = 0.326000\n",
            "Ran epoch 7 and got train accuracy = 0.438577 and val accuracy = 0.334000\n",
            "Ran epoch 8 and got train accuracy = 0.452809 and val accuracy = 0.344000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 243.20it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 159.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 212.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 9 and got train accuracy = 0.469288 and val accuracy = 0.346000\n",
            "Ran epoch 10 and got train accuracy = 0.477903 and val accuracy = 0.348000\n",
            "Ran epoch 11 and got train accuracy = 0.483146 and val accuracy = 0.358000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 167.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 186.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 12 and got train accuracy = 0.488015 and val accuracy = 0.354000\n",
            "Ran epoch 13 and got train accuracy = 0.496255 and val accuracy = 0.342000\n",
            "Ran epoch 14 and got train accuracy = 0.503745 and val accuracy = 0.352000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 153.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 204.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 191.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 15 and got train accuracy = 0.513858 and val accuracy = 0.350000\n",
            "Ran epoch 16 and got train accuracy = 0.518352 and val accuracy = 0.356000\n",
            "Ran epoch 17 and got train accuracy = 0.526592 and val accuracy = 0.358000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 197.43it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 246.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 219.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 18 and got train accuracy = 0.531835 and val accuracy = 0.362000\n",
            "Ran epoch 19 and got train accuracy = 0.537453 and val accuracy = 0.366000\n",
            "Ran epoch 20 and got train accuracy = 0.541948 and val accuracy = 0.370000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 178.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 181.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 241.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 21 and got train accuracy = 0.545693 and val accuracy = 0.368000\n",
            "Ran epoch 22 and got train accuracy = 0.552809 and val accuracy = 0.370000\n",
            "Ran epoch 23 and got train accuracy = 0.556929 and val accuracy = 0.366000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 181.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 293.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 204.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 24 and got train accuracy = 0.563296 and val accuracy = 0.370000\n",
            "Ran epoch 25 and got train accuracy = 0.565169 and val accuracy = 0.368000\n",
            "Ran epoch 26 and got train accuracy = 0.571536 and val accuracy = 0.372000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 214.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 27 and got train accuracy = 0.574906 and val accuracy = 0.368000\n",
            "Ran epoch 28 and got train accuracy = 0.580899 and val accuracy = 0.364000\n",
            "Ran epoch 29 and got train accuracy = 0.585768 and val accuracy = 0.368000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 205.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 170.68it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 153.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 30 and got train accuracy = 0.589888 and val accuracy = 0.364000\n",
            "Ran epoch 31 and got train accuracy = 0.595506 and val accuracy = 0.368000\n",
            "Ran epoch 32 and got train accuracy = 0.599625 and val accuracy = 0.368000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 156.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 439.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 158.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 33 and got train accuracy = 0.605243 and val accuracy = 0.368000\n",
            "Ran epoch 34 and got train accuracy = 0.609363 and val accuracy = 0.366000\n",
            "Ran epoch 35 and got train accuracy = 0.610112 and val accuracy = 0.366000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 179.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 163.92it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 174.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 36 and got train accuracy = 0.619850 and val accuracy = 0.370000\n",
            "Ran epoch 37 and got train accuracy = 0.620599 and val accuracy = 0.368000\n",
            "Ran epoch 38 and got train accuracy = 0.624345 and val accuracy = 0.372000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 150.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 169.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 256.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 39 and got train accuracy = 0.624719 and val accuracy = 0.370000\n",
            "Ran epoch 40 and got train accuracy = 0.628464 and val accuracy = 0.374000\n",
            "Ran epoch 41 and got train accuracy = 0.632210 and val accuracy = 0.374000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 182.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 187.52it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 272.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 42 and got train accuracy = 0.637453 and val accuracy = 0.366000\n",
            "Ran epoch 43 and got train accuracy = 0.640075 and val accuracy = 0.370000\n",
            "Ran epoch 44 and got train accuracy = 0.643820 and val accuracy = 0.378000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 178.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 254.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 216.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 45 and got train accuracy = 0.649064 and val accuracy = 0.378000\n",
            "Ran epoch 46 and got train accuracy = 0.655431 and val accuracy = 0.376000\n",
            "Ran epoch 47 and got train accuracy = 0.658427 and val accuracy = 0.378000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 225.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 181.17it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 233.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 48 and got train accuracy = 0.664794 and val accuracy = 0.374000\n",
            "Ran epoch 49 and got train accuracy = 0.666667 and val accuracy = 0.386000\n",
            "Ran epoch 50 and got train accuracy = 0.670412 and val accuracy = 0.380000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 185.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 244.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 213.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 51 and got train accuracy = 0.678277 and val accuracy = 0.366000\n",
            "Ran epoch 52 and got train accuracy = 0.680524 and val accuracy = 0.376000\n",
            "Ran epoch 53 and got train accuracy = 0.685393 and val accuracy = 0.376000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 203.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 190.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 199.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 54 and got train accuracy = 0.690262 and val accuracy = 0.370000\n",
            "Ran epoch 55 and got train accuracy = 0.692884 and val accuracy = 0.380000\n",
            "Ran epoch 56 and got train accuracy = 0.695880 and val accuracy = 0.370000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 220.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 244.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 57 and got train accuracy = 0.699251 and val accuracy = 0.376000\n",
            "Ran epoch 58 and got train accuracy = 0.703371 and val accuracy = 0.378000\n",
            "Ran epoch 59 and got train accuracy = 0.705618 and val accuracy = 0.376000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 192.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 231.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 242.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 60 and got train accuracy = 0.708240 and val accuracy = 0.376000\n",
            "Ran epoch 61 and got train accuracy = 0.710112 and val accuracy = 0.380000\n",
            "Ran epoch 62 and got train accuracy = 0.717603 and val accuracy = 0.370000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 219.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 199.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 107.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 63 and got train accuracy = 0.718352 and val accuracy = 0.380000\n",
            "Ran epoch 64 and got train accuracy = 0.723596 and val accuracy = 0.386000\n",
            "Ran epoch 65 and got train accuracy = 0.727341 and val accuracy = 0.378000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 154.94it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 195.01it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 344.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 66 and got train accuracy = 0.730337 and val accuracy = 0.382000\n",
            "Ran epoch 67 and got train accuracy = 0.731086 and val accuracy = 0.376000\n",
            "Ran epoch 68 and got train accuracy = 0.735581 and val accuracy = 0.376000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 160.23it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 175.19it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 185.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 69 and got train accuracy = 0.737453 and val accuracy = 0.382000\n",
            "Ran epoch 70 and got train accuracy = 0.740824 and val accuracy = 0.382000\n",
            "Ran epoch 71 and got train accuracy = 0.743820 and val accuracy = 0.374000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 169.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 226.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 196.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 72 and got train accuracy = 0.747940 and val accuracy = 0.374000\n",
            "Ran epoch 73 and got train accuracy = 0.749813 and val accuracy = 0.374000\n",
            "Ran epoch 74 and got train accuracy = 0.755056 and val accuracy = 0.374000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 182.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 150.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 166.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 75 and got train accuracy = 0.756929 and val accuracy = 0.376000\n",
            "Ran epoch 76 and got train accuracy = 0.762172 and val accuracy = 0.372000\n",
            "Ran epoch 77 and got train accuracy = 0.761798 and val accuracy = 0.376000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 280.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 212.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 151.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 78 and got train accuracy = 0.766667 and val accuracy = 0.368000\n",
            "Ran epoch 79 and got train accuracy = 0.768539 and val accuracy = 0.364000\n",
            "Ran epoch 80 and got train accuracy = 0.769288 and val accuracy = 0.366000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 194.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 192.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 203.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 81 and got train accuracy = 0.773783 and val accuracy = 0.368000\n",
            "Ran epoch 82 and got train accuracy = 0.771910 and val accuracy = 0.370000\n",
            "Ran epoch 83 and got train accuracy = 0.778277 and val accuracy = 0.376000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 247.51it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 227.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 146.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 84 and got train accuracy = 0.777154 and val accuracy = 0.366000\n",
            "Ran epoch 85 and got train accuracy = 0.783146 and val accuracy = 0.372000\n",
            "Ran epoch 86 and got train accuracy = 0.781648 and val accuracy = 0.370000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 154.75it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 278.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 208.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 87 and got train accuracy = 0.790262 and val accuracy = 0.370000\n",
            "Ran epoch 88 and got train accuracy = 0.786142 and val accuracy = 0.364000\n",
            "Ran epoch 89 and got train accuracy = 0.794757 and val accuracy = 0.362000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 190.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 193.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 196.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 90 and got train accuracy = 0.791386 and val accuracy = 0.356000\n",
            "Ran epoch 91 and got train accuracy = 0.799625 and val accuracy = 0.370000\n",
            "Ran epoch 92 and got train accuracy = 0.799251 and val accuracy = 0.354000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.97it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 192.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 191.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 93 and got train accuracy = 0.803745 and val accuracy = 0.370000\n",
            "Ran epoch 94 and got train accuracy = 0.801124 and val accuracy = 0.364000\n",
            "Ran epoch 95 and got train accuracy = 0.808989 and val accuracy = 0.372000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 209.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 235.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 151.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 96 and got train accuracy = 0.805993 and val accuracy = 0.360000\n",
            "Ran epoch 97 and got train accuracy = 0.815356 and val accuracy = 0.370000\n",
            "Ran epoch 98 and got train accuracy = 0.809363 and val accuracy = 0.366000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 194.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 151.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 99 and got train accuracy = 0.816854 and val accuracy = 0.372000\n",
            "Ran epoch 100 and got train accuracy = 0.810487 and val accuracy = 0.364000\n",
            "Ran epoch 101 and got train accuracy = 0.822472 and val accuracy = 0.366000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 160.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 197.37it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 138.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 102 and got train accuracy = 0.813858 and val accuracy = 0.360000\n",
            "Ran epoch 103 and got train accuracy = 0.821723 and val accuracy = 0.368000\n",
            "Ran epoch 104 and got train accuracy = 0.816105 and val accuracy = 0.358000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 199.78it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 188.86it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 178.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 105 and got train accuracy = 0.826966 and val accuracy = 0.368000\n",
            "Ran epoch 106 and got train accuracy = 0.820974 and val accuracy = 0.360000\n",
            "Ran epoch 107 and got train accuracy = 0.825468 and val accuracy = 0.374000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 185.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 252.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 186.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 108 and got train accuracy = 0.818727 and val accuracy = 0.350000\n",
            "Ran epoch 109 and got train accuracy = 0.828464 and val accuracy = 0.374000\n",
            "Ran epoch 110 and got train accuracy = 0.819476 and val accuracy = 0.344000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 184.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 200.84it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 189.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 111 and got train accuracy = 0.834457 and val accuracy = 0.374000\n",
            "Ran epoch 112 and got train accuracy = 0.822472 and val accuracy = 0.350000\n",
            "Ran epoch 113 and got train accuracy = 0.832959 and val accuracy = 0.374000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 203.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.63it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 206.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 114 and got train accuracy = 0.818352 and val accuracy = 0.340000\n",
            "Ran epoch 115 and got train accuracy = 0.832584 and val accuracy = 0.366000\n",
            "Ran epoch 116 and got train accuracy = 0.822097 and val accuracy = 0.346000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 147.59it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 191.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 334.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 117 and got train accuracy = 0.835955 and val accuracy = 0.364000\n",
            "Ran epoch 118 and got train accuracy = 0.825094 and val accuracy = 0.350000\n",
            "Ran epoch 119 and got train accuracy = 0.840075 and val accuracy = 0.362000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 190.79it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 170.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 210.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 120 and got train accuracy = 0.829213 and val accuracy = 0.350000\n",
            "Ran epoch 121 and got train accuracy = 0.847566 and val accuracy = 0.362000\n",
            "Ran epoch 122 and got train accuracy = 0.840075 and val accuracy = 0.360000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 232.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 200.46it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 195.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 123 and got train accuracy = 0.851311 and val accuracy = 0.364000\n",
            "Ran epoch 124 and got train accuracy = 0.843446 and val accuracy = 0.354000\n",
            "Ran epoch 125 and got train accuracy = 0.854307 and val accuracy = 0.368000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 192.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 178.49it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 169.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 126 and got train accuracy = 0.845693 and val accuracy = 0.362000\n",
            "Ran epoch 127 and got train accuracy = 0.853184 and val accuracy = 0.350000\n",
            "Ran epoch 128 and got train accuracy = 0.850936 and val accuracy = 0.362000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 200.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 238.33it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 204.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 129 and got train accuracy = 0.856929 and val accuracy = 0.346000\n",
            "Ran epoch 130 and got train accuracy = 0.853933 and val accuracy = 0.372000\n",
            "Ran epoch 131 and got train accuracy = 0.865169 and val accuracy = 0.346000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 232.08it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 142.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 132 and got train accuracy = 0.858052 and val accuracy = 0.366000\n",
            "Ran epoch 133 and got train accuracy = 0.866667 and val accuracy = 0.340000\n",
            "Ran epoch 134 and got train accuracy = 0.857303 and val accuracy = 0.380000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 212.53it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 215.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 231.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 135 and got train accuracy = 0.863296 and val accuracy = 0.336000\n",
            "Ran epoch 136 and got train accuracy = 0.857303 and val accuracy = 0.374000\n",
            "Ran epoch 137 and got train accuracy = 0.864045 and val accuracy = 0.342000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 191.32it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 266.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 264.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 138 and got train accuracy = 0.861049 and val accuracy = 0.368000\n",
            "Ran epoch 139 and got train accuracy = 0.870037 and val accuracy = 0.338000\n",
            "Ran epoch 140 and got train accuracy = 0.872659 and val accuracy = 0.360000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 206.24it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 219.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 177.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 141 and got train accuracy = 0.875655 and val accuracy = 0.340000\n",
            "Ran epoch 142 and got train accuracy = 0.873034 and val accuracy = 0.354000\n",
            "Ran epoch 143 and got train accuracy = 0.876404 and val accuracy = 0.340000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 195.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 220.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 189.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 144 and got train accuracy = 0.873034 and val accuracy = 0.348000\n",
            "Ran epoch 145 and got train accuracy = 0.881273 and val accuracy = 0.336000\n",
            "Ran epoch 146 and got train accuracy = 0.881648 and val accuracy = 0.356000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 226.77it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 140.13it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 246.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 147 and got train accuracy = 0.893258 and val accuracy = 0.344000\n",
            "Ran epoch 148 and got train accuracy = 0.887640 and val accuracy = 0.352000\n",
            "Ran epoch 149 and got train accuracy = 0.895131 and val accuracy = 0.342000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 244.15it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 160.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 271.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 150 and got train accuracy = 0.883521 and val accuracy = 0.336000\n",
            "Ran epoch 151 and got train accuracy = 0.894382 and val accuracy = 0.350000\n",
            "Ran epoch 152 and got train accuracy = 0.876779 and val accuracy = 0.340000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.10it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 206.16it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 153 and got train accuracy = 0.892135 and val accuracy = 0.358000\n",
            "Ran epoch 154 and got train accuracy = 0.876404 and val accuracy = 0.332000\n",
            "Ran epoch 155 and got train accuracy = 0.884644 and val accuracy = 0.370000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 193.69it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 195.41it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 241.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 156 and got train accuracy = 0.873783 and val accuracy = 0.316000\n",
            "Ran epoch 157 and got train accuracy = 0.878277 and val accuracy = 0.384000\n",
            "Ran epoch 158 and got train accuracy = 0.861798 and val accuracy = 0.280000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 255.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 217.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 188.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 159 and got train accuracy = 0.864794 and val accuracy = 0.390000\n",
            "Ran epoch 160 and got train accuracy = 0.852434 and val accuracy = 0.284000\n",
            "Ran epoch 161 and got train accuracy = 0.872659 and val accuracy = 0.398000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 220.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 184.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 162 and got train accuracy = 0.871536 and val accuracy = 0.290000\n",
            "Ran epoch 163 and got train accuracy = 0.891386 and val accuracy = 0.406000\n",
            "Ran epoch 164 and got train accuracy = 0.894007 and val accuracy = 0.304000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 175.61it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 234.57it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 159.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 165 and got train accuracy = 0.906742 and val accuracy = 0.410000\n",
            "Ran epoch 166 and got train accuracy = 0.900000 and val accuracy = 0.302000\n",
            "Ran epoch 167 and got train accuracy = 0.913109 and val accuracy = 0.408000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 250.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 271.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 215.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 168 and got train accuracy = 0.910112 and val accuracy = 0.308000\n",
            "Ran epoch 169 and got train accuracy = 0.918727 and val accuracy = 0.392000\n",
            "Ran epoch 170 and got train accuracy = 0.913858 and val accuracy = 0.302000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 134.36it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 380.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 190.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 171 and got train accuracy = 0.920974 and val accuracy = 0.394000\n",
            "Ran epoch 172 and got train accuracy = 0.918352 and val accuracy = 0.300000\n",
            "Ran epoch 173 and got train accuracy = 0.924719 and val accuracy = 0.392000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 220.39it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 383.99it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 166.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 174 and got train accuracy = 0.924719 and val accuracy = 0.302000\n",
            "Ran epoch 175 and got train accuracy = 0.924719 and val accuracy = 0.382000\n",
            "Ran epoch 176 and got train accuracy = 0.922846 and val accuracy = 0.306000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 153.03it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 191.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 177 and got train accuracy = 0.922472 and val accuracy = 0.378000\n",
            "Ran epoch 178 and got train accuracy = 0.916854 and val accuracy = 0.320000\n",
            "Ran epoch 179 and got train accuracy = 0.904120 and val accuracy = 0.362000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 257.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 176.06it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 332.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 180 and got train accuracy = 0.898502 and val accuracy = 0.320000\n",
            "Ran epoch 181 and got train accuracy = 0.867416 and val accuracy = 0.348000\n",
            "Ran epoch 182 and got train accuracy = 0.874157 and val accuracy = 0.328000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 207.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 217.48it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 165.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 183 and got train accuracy = 0.852809 and val accuracy = 0.350000\n",
            "Ran epoch 184 and got train accuracy = 0.881273 and val accuracy = 0.336000\n",
            "Ran epoch 185 and got train accuracy = 0.884270 and val accuracy = 0.342000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 190.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 208.14it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 186.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 186 and got train accuracy = 0.902996 and val accuracy = 0.348000\n",
            "Ran epoch 187 and got train accuracy = 0.905993 and val accuracy = 0.334000\n",
            "Ran epoch 188 and got train accuracy = 0.919476 and val accuracy = 0.354000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 200.60it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 201.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 209.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 189 and got train accuracy = 0.925843 and val accuracy = 0.336000\n",
            "Ran epoch 190 and got train accuracy = 0.937453 and val accuracy = 0.364000\n",
            "Ran epoch 191 and got train accuracy = 0.934082 and val accuracy = 0.332000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 195.87it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 186.89it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 180.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 192 and got train accuracy = 0.938577 and val accuracy = 0.382000\n",
            "Ran epoch 193 and got train accuracy = 0.932584 and val accuracy = 0.330000\n",
            "Ran epoch 194 and got train accuracy = 0.934457 and val accuracy = 0.392000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 197.30it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 198.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 224.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 195 and got train accuracy = 0.922097 and val accuracy = 0.320000\n",
            "Ran epoch 196 and got train accuracy = 0.925094 and val accuracy = 0.384000\n",
            "Ran epoch 197 and got train accuracy = 0.913109 and val accuracy = 0.308000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 260.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ran epoch 198 and got train accuracy = 0.916854 and val accuracy = 0.380000\n",
            "Ran epoch 199 and got train accuracy = 0.904869 and val accuracy = 0.292000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For Q4,\n",
            "Best train accuracy: 0.9385767790262173\n",
            "Best val accuracy: 0.41\n",
            "Lowest Train Loss is 0.3353762067431931\n",
            "Lowest Val Loss is 1.4397112111348938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fx-JPJus9dT",
        "outputId": "0e3d5568-7e30-4fa9-dff7-44cc3eab21ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "num_partition = 5\n",
        "x_test_arrays = np.split(X_TEST, num_partition)\n",
        "y_test_arrays = np.split(np.array(Y_TEST), num_partition)\n",
        "n_images = len (x_test_arrays[0])\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "print ('For Q5,')\n",
        "for i in range(num_partition):\n",
        "    class_predictions, class_loss = predict(NN,x_test_arrays[i], y_test_arrays[i])\n",
        "    accuracy = np.mean(class_predictions==y_test_arrays[i])\n",
        "    print('For Category ' , CATEGORIES[i],' , Got Accuracy' , accuracy)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "y_pos = np.arange(len(CATEGORIES))\n",
        "\n",
        "plt.bar(CATEGORIES, accuracies)\n",
        " \n",
        "plt.xticks(CATEGORIES, CATEGORIES)\n",
        " \n",
        "plt.title(\"CCR\")\n",
        "\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Q5,\n",
            "For Category  daisy  , Got Accuracy 0.44\n",
            "For Category  dandelion  , Got Accuracy 0.69\n",
            "For Category  roses  , Got Accuracy 0.46\n",
            "For Category  sunflowers  , Got Accuracy 0.65\n",
            "For Category  tulips  , Got Accuracy 0.51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'CCR')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6OsCVIje2h",
        "outputId": "496dc347-e492-410c-8d0d-bf85318980a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted_test, test_loss = predict(NN,X_TEST, Y_TEST)\n",
        "accuracy = np.mean(predicted_test==np.array(Y_TEST))\n",
        "    \n",
        "print(\"ACCR = %f\" % accuracy)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACCR = 0.550000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60laB_wQkrS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}